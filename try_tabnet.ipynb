{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import multiprocessing\n",
    "import re\n",
    "import os\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 可用，使用 GPU 进行训练。\n",
      "检测到的CPU核心数为64，设置使用核心数为32\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "        print(\"CUDA 可用，使用 GPU 进行训练。\")\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "        print(\"CUDA 不可用，使用 CPU 进行训练。\")\n",
    "    return device\n",
    "\n",
    "def get_optimal_num_workers():\n",
    "    try:\n",
    "        num_cores = multiprocessing.cpu_count()\n",
    "    except NotImplementedError:\n",
    "        num_cores = 1  # 如果无法检测CPU核心数，默认设置为1\n",
    "    num_workers = max(1, num_cores // 2)\n",
    "    print(f\"检测到的CPU核心数为{num_cores}，设置使用核心数为{num_workers}\")\n",
    "    return num_workers\n",
    "\n",
    "def clean_feature_names(X):\n",
    "    # 函数用于清理特征名称\n",
    "    def clean_name(name):\n",
    "        # 移除或替换特殊字符\n",
    "        name = re.sub(r'[^\\w\\s-]', '_', name)\n",
    "        # 确保名称不以数字开头\n",
    "        if name and name[0].isdigit():\n",
    "            name = 'f_' + name\n",
    "        return name\n",
    "\n",
    "    X.columns = [clean_name(col) for col in X.columns]\n",
    "    return X\n",
    "\n",
    "# 定义函数以自动检测和处理类别特征\n",
    "def process_categorical_features(df, max_unique=10):\n",
    "    \"\"\"\n",
    "    自动检测和处理数据框中的类别变量。\n",
    "\n",
    "    参数：\n",
    "    - df (pd.DataFrame): 输入的数据框。\n",
    "    - max_unique (int): 判定为类别变量的最大唯一值数量。\n",
    "\n",
    "    返回：\n",
    "    - cat_idxs (list of int): 类别特征的索引。\n",
    "    - cat_dims (list of int): 每个类别特征的模态数。\n",
    "    - df (pd.DataFrame): 经过编码后的数据框。\n",
    "    \"\"\"\n",
    "    cat_cols = [col for col in df.columns if df[col].nunique() <= max_unique]\n",
    "    cat_dims = []\n",
    "    cat_idxs = []\n",
    "    encoder_dict = {}\n",
    "\n",
    "    for col in cat_cols:\n",
    "        print(f\"处理类别特征: {col}，唯一值数量: {df[col].nunique()}\")\n",
    "        # 使用 LabelEncoder\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str).fillna('NaN'))\n",
    "        cat_dims.append(len(le.classes_))\n",
    "        cat_idxs.append(df.columns.get_loc(col))\n",
    "\n",
    "    return cat_idxs, cat_dims, df\n",
    "\n",
    "# 定义多分类加权交叉熵损失函数\n",
    "class WeightedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, class_weights=None):\n",
    "        \"\"\"\n",
    "        初始化加权交叉熵损失函数。\n",
    "\n",
    "        参数：\n",
    "        - class_weights (list或np.array或torch.Tensor): 每个类别的权重。\n",
    "        \"\"\"\n",
    "        super(WeightedCrossEntropyLoss, self).__init__()\n",
    "        if class_weights is not None:\n",
    "            # 使用 register_buffer 确保 class_weights 在模型保存和加载时被包含\n",
    "            self.register_buffer('class_weights', torch.tensor(class_weights, dtype=torch.float))\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        \"\"\"\n",
    "        前向传播计算损失。\n",
    "\n",
    "        参数：\n",
    "        - y_pred (torch.Tensor): 模型的预测输出，形状为 (batch_size, num_classes)。\n",
    "        - y_true (torch.Tensor): 真实的标签，形状为 (batch_size,)。\n",
    "        \"\"\"\n",
    "        if self.class_weights is not None:\n",
    "            # 确保 class_weights 在 y_pred 的设备上\n",
    "            return F.cross_entropy(y_pred, y_true, weight=self.class_weights.to(y_pred.device))\n",
    "        else:\n",
    "            return F.cross_entropy(y_pred, y_true)\n",
    "\n",
    "device = get_device()\n",
    "num_workers = get_optimal_num_workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding numeric labels y\n",
      "Extracting X_train, y_train, and group\n",
      "处理类别特征: dimension，唯一值数量: 8\n",
      "处理类别特征: ExactSearch_v_X_，唯一值数量: 2\n",
      "处理类别特征: ExactSearch_X_v_，唯一值数量: 2\n",
      "处理类别特征: ExactSearch_v_Y_，唯一值数量: 2\n",
      "处理类别特征: ExactSearch_Y_v_，唯一值数量: 2\n",
      "处理类别特征: ExactSearch_X_Y_，唯一值数量: 2\n",
      "处理类别特征: PC_v_X_，唯一值数量: 2\n",
      "处理类别特征: PC_X_v_，唯一值数量: 2\n",
      "处理类别特征: PC_v_Y_，唯一值数量: 2\n",
      "处理类别特征: PC_Y_v_，唯一值数量: 2\n",
      "处理类别特征: PC_X_Y_，唯一值数量: 2\n",
      "处理类别特征: FCI_v_X_，唯一值数量: 4\n",
      "处理类别特征: FCI_X_v_，唯一值数量: 4\n",
      "处理类别特征: FCI_v_Y_，唯一值数量: 4\n",
      "处理类别特征: FCI_Y_v_，唯一值数量: 4\n",
      "处理类别特征: FCI_X_Y_，唯一值数量: 4\n",
      "类别特征索引 (cat_idxs): [0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60]\n",
      "类别特征模态数 (cat_dims): [8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "X_y_group_train = pd.read_csv('/hy-tmp/mid_data/X_y_group_train_updated_v12.2_piecewise.csv')\n",
    "\n",
    "print(\"Adding numeric labels y\")\n",
    "le = LabelEncoder()\n",
    "X_y_group_train[\"y\"] = le.fit_transform(X_y_group_train[\"label\"])\n",
    "# 重新排列列\n",
    "X_y_group_train = X_y_group_train[[\"dataset\", \"variable\"] + X_y_group_train.columns.drop([\"dataset\", \"variable\", \"label\", \"y\"]).tolist() + [\"label\", \"y\"]]\n",
    "\n",
    "# 定义要删除的列\n",
    "blacklist = [\n",
    "    \"ttest(v,X)\", \n",
    "    \"pvalue(ttest(v,X))<=0.05\", \n",
    "    \"ttest(v,Y)\", \n",
    "    \"pvalue(ttest(v,Y))<=0.05\", \n",
    "    \"ttest(X,Y)\", \n",
    "    \"pvalue(ttest(X,Y))<=0.05\",\n",
    "    \"square_dimension\", \n",
    "    \"max(PPS(v,others))\"\n",
    "]\n",
    "columns_to_drop = [col for col in blacklist if col in X_y_group_train.columns]\n",
    "X_y_group_train = X_y_group_train.drop(columns=columns_to_drop)\n",
    "\n",
    "# 处理数值列的缺失值\n",
    "numeric_columns = X_y_group_train.select_dtypes(include=[np.number]).columns\n",
    "X_y_group_train[numeric_columns] = X_y_group_train[numeric_columns].fillna(X_y_group_train[numeric_columns].mean())\n",
    "\n",
    "# 清理特征名称\n",
    "X_y_group_train = clean_feature_names(X_y_group_train)\n",
    "\n",
    "print(\"Extracting X_train, y_train, and group\")\n",
    "# 分离数据集ID、特征和标签\n",
    "group_train = X_y_group_train[\"dataset\"]\n",
    "X = X_y_group_train.drop([\"variable\", \"dataset\", \"label\", \"y\"], axis=\"columns\")\n",
    "y = X_y_group_train[\"y\"]\n",
    "\n",
    "# 处理类别特征\n",
    "cat_idxs, cat_dims, X = process_categorical_features(X)\n",
    "print(f\"类别特征索引 (cat_idxs): {cat_idxs}\")\n",
    "print(f\"类别特征模态数 (cat_dims): {cat_dims}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train 唯一值: [0 1 2 3 4 5 6 7]\n",
      "y_test 唯一值: [0 1 2 3 4 5 6 7]\n",
      "类别权重: [1.450715663384428, 0.6722329366386002, 3.281515499425947, 1.975532209012994, 0.9026654876200101, 2.093305990918412, 0.32411040301181593, 2.930285011277425]\n"
     ]
    }
   ],
   "source": [
    "# 分割数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"y_train 唯一值:\", np.unique(y_train))\n",
    "print(\"y_test 唯一值:\", np.unique(y_test))\n",
    "\n",
    "# 计算类别权重（使用每个类别的逆频率）\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights = list(class_weights)  # 转换为列表\n",
    "print(f\"类别权重: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.15835 | train_accuracy: 0.57287 | train_balanced_accuracy: 0.43368 | valid_accuracy: 0.57599 | valid_balanced_accuracy: 0.43795 |  0:00:37s\n",
      "epoch 1  | loss: 1.41943 | train_accuracy: 0.62473 | train_balanced_accuracy: 0.49883 | valid_accuracy: 0.62543 | valid_balanced_accuracy: 0.49887 |  0:01:11s\n",
      "epoch 2  | loss: 1.3432  | train_accuracy: 0.61606 | train_balanced_accuracy: 0.52571 | valid_accuracy: 0.61962 | valid_balanced_accuracy: 0.52746 |  0:01:46s\n",
      "epoch 3  | loss: 1.30303 | train_accuracy: 0.63883 | train_balanced_accuracy: 0.5364  | valid_accuracy: 0.63781 | valid_balanced_accuracy: 0.53622 |  0:02:21s\n",
      "epoch 4  | loss: 1.27541 | train_accuracy: 0.63198 | train_balanced_accuracy: 0.54103 | valid_accuracy: 0.63127 | valid_balanced_accuracy: 0.54189 |  0:02:57s\n",
      "epoch 5  | loss: 1.25565 | train_accuracy: 0.64534 | train_balanced_accuracy: 0.54284 | valid_accuracy: 0.64541 | valid_balanced_accuracy: 0.54362 |  0:03:32s\n",
      "epoch 6  | loss: 1.24015 | train_accuracy: 0.64073 | train_balanced_accuracy: 0.5442  | valid_accuracy: 0.63834 | valid_balanced_accuracy: 0.54201 |  0:04:08s\n",
      "epoch 7  | loss: 1.23358 | train_accuracy: 0.64362 | train_balanced_accuracy: 0.54409 | valid_accuracy: 0.64061 | valid_balanced_accuracy: 0.54003 |  0:04:44s\n",
      "epoch 8  | loss: 1.2151  | train_accuracy: 0.6392  | train_balanced_accuracy: 0.54974 | valid_accuracy: 0.63792 | valid_balanced_accuracy: 0.55002 |  0:05:18s\n",
      "epoch 9  | loss: 1.21098 | train_accuracy: 0.64824 | train_balanced_accuracy: 0.55253 | valid_accuracy: 0.64527 | valid_balanced_accuracy: 0.54991 |  0:05:55s\n",
      "epoch 10 | loss: 1.20269 | train_accuracy: 0.64606 | train_balanced_accuracy: 0.55298 | valid_accuracy: 0.64369 | valid_balanced_accuracy: 0.55185 |  0:06:29s\n",
      "epoch 11 | loss: 1.1897  | train_accuracy: 0.6574  | train_balanced_accuracy: 0.55684 | valid_accuracy: 0.65587 | valid_balanced_accuracy: 0.55609 |  0:07:05s\n",
      "epoch 12 | loss: 1.19223 | train_accuracy: 0.65294 | train_balanced_accuracy: 0.5556  | valid_accuracy: 0.64971 | valid_balanced_accuracy: 0.55219 |  0:07:40s\n",
      "epoch 13 | loss: 1.1793  | train_accuracy: 0.65968 | train_balanced_accuracy: 0.5604  | valid_accuracy: 0.65912 | valid_balanced_accuracy: 0.56004 |  0:08:17s\n",
      "epoch 14 | loss: 1.16382 | train_accuracy: 0.66346 | train_balanced_accuracy: 0.55898 | valid_accuracy: 0.66052 | valid_balanced_accuracy: 0.55813 |  0:08:53s\n",
      "epoch 15 | loss: 1.15851 | train_accuracy: 0.63464 | train_balanced_accuracy: 0.55937 | valid_accuracy: 0.63117 | valid_balanced_accuracy: 0.55659 |  0:09:29s\n",
      "epoch 16 | loss: 1.14762 | train_accuracy: 0.66413 | train_balanced_accuracy: 0.56822 | valid_accuracy: 0.65975 | valid_balanced_accuracy: 0.56181 |  0:10:03s\n",
      "epoch 17 | loss: 1.13823 | train_accuracy: 0.66492 | train_balanced_accuracy: 0.56606 | valid_accuracy: 0.66223 | valid_balanced_accuracy: 0.56411 |  0:10:37s\n",
      "epoch 18 | loss: 1.13441 | train_accuracy: 0.67347 | train_balanced_accuracy: 0.57022 | valid_accuracy: 0.67046 | valid_balanced_accuracy: 0.56363 |  0:11:14s\n",
      "epoch 19 | loss: 1.12229 | train_accuracy: 0.66659 | train_balanced_accuracy: 0.5737  | valid_accuracy: 0.66454 | valid_balanced_accuracy: 0.57227 |  0:11:50s\n",
      "epoch 20 | loss: 1.11842 | train_accuracy: 0.67318 | train_balanced_accuracy: 0.56295 | valid_accuracy: 0.67021 | valid_balanced_accuracy: 0.55687 |  0:12:28s\n",
      "epoch 21 | loss: 1.13548 | train_accuracy: 0.6702  | train_balanced_accuracy: 0.57213 | valid_accuracy: 0.66657 | valid_balanced_accuracy: 0.56259 |  0:13:03s\n",
      "epoch 22 | loss: 1.12273 | train_accuracy: 0.66103 | train_balanced_accuracy: 0.56597 | valid_accuracy: 0.65527 | valid_balanced_accuracy: 0.55529 |  0:13:39s\n",
      "epoch 23 | loss: 1.1311  | train_accuracy: 0.66482 | train_balanced_accuracy: 0.57134 | valid_accuracy: 0.66073 | valid_balanced_accuracy: 0.56513 |  0:14:16s\n",
      "epoch 24 | loss: 1.10643 | train_accuracy: 0.67131 | train_balanced_accuracy: 0.57257 | valid_accuracy: 0.66741 | valid_balanced_accuracy: 0.56277 |  0:14:51s\n",
      "epoch 25 | loss: 1.09631 | train_accuracy: 0.67275 | train_balanced_accuracy: 0.5822  | valid_accuracy: 0.66668 | valid_balanced_accuracy: 0.57431 |  0:15:30s\n",
      "epoch 26 | loss: 1.09268 | train_accuracy: 0.66977 | train_balanced_accuracy: 0.57875 | valid_accuracy: 0.66122 | valid_balanced_accuracy: 0.56579 |  0:16:06s\n",
      "epoch 27 | loss: 1.08651 | train_accuracy: 0.67531 | train_balanced_accuracy: 0.58477 | valid_accuracy: 0.66675 | valid_balanced_accuracy: 0.56932 |  0:16:41s\n",
      "epoch 28 | loss: 1.09139 | train_accuracy: 0.66477 | train_balanced_accuracy: 0.56713 | valid_accuracy: 0.66279 | valid_balanced_accuracy: 0.56239 |  0:17:16s\n",
      "epoch 29 | loss: 1.12959 | train_accuracy: 0.66594 | train_balanced_accuracy: 0.57787 | valid_accuracy: 0.66098 | valid_balanced_accuracy: 0.56929 |  0:17:52s\n",
      "epoch 30 | loss: 1.08943 | train_accuracy: 0.67819 | train_balanced_accuracy: 0.58428 | valid_accuracy: 0.67413 | valid_balanced_accuracy: 0.57275 |  0:18:28s\n",
      "epoch 31 | loss: 1.07301 | train_accuracy: 0.67372 | train_balanced_accuracy: 0.58924 | valid_accuracy: 0.66685 | valid_balanced_accuracy: 0.57644 |  0:19:03s\n",
      "epoch 32 | loss: 1.06461 | train_accuracy: 0.6755  | train_balanced_accuracy: 0.59027 | valid_accuracy: 0.66808 | valid_balanced_accuracy: 0.57351 |  0:19:39s\n",
      "epoch 33 | loss: 1.0568  | train_accuracy: 0.67054 | train_balanced_accuracy: 0.59083 | valid_accuracy: 0.66182 | valid_balanced_accuracy: 0.57154 |  0:20:14s\n",
      "epoch 34 | loss: 1.04975 | train_accuracy: 0.67642 | train_balanced_accuracy: 0.59619 | valid_accuracy: 0.66545 | valid_balanced_accuracy: 0.57461 |  0:20:48s\n",
      "epoch 35 | loss: 1.04281 | train_accuracy: 0.67794 | train_balanced_accuracy: 0.59989 | valid_accuracy: 0.6658  | valid_balanced_accuracy: 0.57514 |  0:21:20s\n",
      "epoch 36 | loss: 1.03354 | train_accuracy: 0.6838  | train_balanced_accuracy: 0.59774 | valid_accuracy: 0.6721  | valid_balanced_accuracy: 0.57627 |  0:21:57s\n",
      "epoch 37 | loss: 1.025   | train_accuracy: 0.67751 | train_balanced_accuracy: 0.60393 | valid_accuracy: 0.66216 | valid_balanced_accuracy: 0.57203 |  0:22:31s\n",
      "epoch 38 | loss: 1.01581 | train_accuracy: 0.68569 | train_balanced_accuracy: 0.60584 | valid_accuracy: 0.66916 | valid_balanced_accuracy: 0.57405 |  0:23:07s\n"
     ]
    }
   ],
   "source": [
    "# 初始化自定义的加权交叉熵损失函数\n",
    "loss_fn = WeightedCrossEntropyLoss(class_weights=class_weights)\n",
    "\n",
    "# 定义 TabNetClassifier\n",
    "clf = TabNetClassifier(\n",
    "    n_d=96,                  # 决策层的宽度（小心过拟合）\n",
    "    n_a=96,                  # 注意力嵌入的宽度（一般与n_d一致）\n",
    "    n_steps=5,               # 决策步骤数（3-10）\n",
    "    gamma=1.5,               # 特征重用系数（值接近 1 会减少层间的特征选择相关性，1.0-2.0）\n",
    "    cat_idxs=cat_idxs,       # 类别特征的索引列表\n",
    "    cat_dims=cat_dims,       # 每个类别特征的模态数（即类别数量）\n",
    "    cat_emb_dim=1,           # 类别特征的嵌入维度\n",
    "    n_independent=2,         # 每个步骤中独立的 Gated Linear Units (GLU) 层的数量（1-5）\n",
    "    n_shared=5,              # 每个步骤中共享的 GLU 层的数量（1-5）\n",
    "    epsilon=1e-5,            # 防止除以零的常数\n",
    "    seed=42,                 # 随机种子\n",
    "    momentum=0.2,           # 批量归一化的动量参数（0.01-0.4）\n",
    "    clip_value=1.8,         # 如果设置为浮点数，将梯度剪裁到该值\n",
    "    lambda_sparse=1e-3,      # 额外的稀疏性损失系数，值越大，模型在特征选择上越稀疏（1e-3-1e-1）\n",
    "    optimizer_fn=torch.optim.Adam,                      # 优化器\n",
    "    optimizer_params=dict(lr=2e-2),                     # 优化器的参数\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,       # 学习率调度器\n",
    "    scheduler_params=dict(step_size=50, gamma=0.9),     # 学习率调度器的参数\n",
    "    mask_type='entmax',   # 特征选择的掩码类型（'sparsemax' 或 'entmax'）\n",
    "    # grouped_features=None,   # 将特征分组，使模型在同一组内共享注意力。这在特征预处理生成相关或依赖特征时尤其有用，例如使用 TF-IDF 或 PCA。特征重要性在同组内将相同。\n",
    "    verbose=1,               # 是否打印训练过程中的信息（0 或 1）\n",
    "    device_name=device,       # 使用 GPU\n",
    ")\n",
    "\n",
    "# 训练模型\n",
    "clf.fit(\n",
    "    X_train=X_train.values,  # 训练集的特征矩阵（np.array）\n",
    "    y_train=y_train.values,  # 训练集的目标标签（np.array，对于多分类任务，标签应为整数编码）\n",
    "    eval_set=[(X_train.values, y_train.values), (X_test.values, y_test.values)],   # 验证集列表\n",
    "    eval_name=['train', 'valid'],                      # 验证集的名称\n",
    "    eval_metric=['accuracy', 'balanced_accuracy'],     # 评估指标列表\n",
    "    max_epochs=2000,         # 最大训练轮数\n",
    "    loss_fn=loss_fn,            # 自定义的加权交叉熵损失函数\n",
    "    patience=10,             # 早停的耐心轮数\n",
    "    batch_size=1024,         # 批量大小\n",
    "    virtual_batch_size=128,  # 用于 Ghost Batch Normalization 的虚拟批次大小（应能被 batch_size 整除）\n",
    "    num_workers=num_workers,           # 用于 torch.utils.data.DataLoader 的工作线程数\n",
    "    drop_last=False,         # 是否在训练过程中丢弃最后一个不完整的批次\n",
    "    callbacks=None,          # 回调函数列表\n",
    "    compute_importance=True,   # 是否计算特征重要性\n",
    ")\n",
    "\n",
    "# 预测\n",
    "y_train_pred = clf.predict(X_train.values)\n",
    "y_test_pred = clf.predict(X_test.values)\n",
    "\n",
    "# 计算平衡准确率\n",
    "train_score = balanced_accuracy_score(y_train, y_train_pred)\n",
    "test_score = balanced_accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"训练集平衡准确率: {train_score:.6f}\")\n",
    "print(f\"测试集平衡准确率: {test_score:.6f}\")\n",
    "\n",
    "# 输出详细的分类报告\n",
    "print(\"\\n测试集分类报告:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
