{
        "cells": [
                {
                        "cell_type": "code",
                        "execution_count": 1,
                        "metadata": {},
                        "outputs": [
                                {
                                        "data": {
                                                "text/plain": [
                                                        "'\\n                       _oo0oo_\\n                      o8888888o\\n                      88\" . \"88\\n                      (| -_- |)\\n                      0\\\\  =  /0\\n                    ___/`---\\'\\\\___\\n                  .\\' \\\\|     |// \\'.\\n                 / \\\\|||  :  |||//                 / _||||| -:- |||||-                |   | \\\\\\\\  - /// |   |\\n               | \\\\_|  \\'\\'\\\\---/\\'\\'  |_/ |\\n               \\\\  .-\\\\__  \\'-\\'  ___/-. /\\n             ___\\'. .\\'  /--.--\\\\  `. .\\'___\\n          .\"\" \\'<  `.___\\\\_<|>_/___.\\' >\\' \"\".\\n         | | :  `- \\\\`.;`\\\\ _ /`;.`/ - ` : | |\\n         \\\\  \\\\ `_.   \\\\_ __\\\\ /__ _/   .-` /  /\\n     =====`-.____`.___ \\\\_____/___.-`___.-\\'=====\\n                       `=---=\\'\\n\\n\\n     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\\n\\n           佛祖保佑     永不宕机     永无BUG\\n'"
                                                ]
                                        },
                                        "execution_count": 1,
                                        "metadata": {},
                                        "output_type": "execute_result"
                                }
                        ],
                        "source": [
                                "'''\n",
                                "                       _oo0oo_\n",
                                "                      o8888888o\n",
                                "                      88\" . \"88\n",
                                "                      (| -_- |)\n",
                                "                      0\\  =  /0\n",
                                "                    ___/`---'\\___\n",
                                "                  .' \\\\|     |// '.\n",
                                "                 / \\\\|||  :  |||// \\\n",
                                "                / _||||| -:- |||||- \\\n",
                                "               |   | \\\\\\  - /// |   |\n",
                                "               | \\_|  ''\\---/''  |_/ |\n",
                                "               \\  .-\\__  '-'  ___/-. /\n",
                                "             ___'. .'  /--.--\\  `. .'___\n",
                                "          .\"\" '<  `.___\\_<|>_/___.' >' \"\".\n",
                                "         | | :  `- \\`.;`\\ _ /`;.`/ - ` : | |\n",
                                "         \\  \\ `_.   \\_ __\\ /__ _/   .-` /  /\n",
                                "     =====`-.____`.___ \\_____/___.-`___.-'=====\n",
                                "                       `=---='\n",
                                "\n",
                                "\n",
                                "     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
                                "\n",
                                "           佛祖保佑     永不宕机     永无BUG\n",
                                "'''"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 2,
                        "metadata": {
                                "ExecuteTime": {
                                        "end_time": "2024-09-21T11:20:39.508775Z",
                                        "start_time": "2024-09-21T11:20:32.677062Z"
                                },
                                "metadata": {}
                        },
                        "outputs": [
                                {
                                        "name": "stderr",
                                        "output_type": "stream",
                                        "text": [
                                                "e:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                                                "  from .autonotebook import tqdm as notebook_tqdm\n",
                                                "2024-10-04 18:21:06,641\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
                                        ]
                                }
                        ],
                        "source": [
                                "import functools\n",
                                "import os\n",
                                "import typing\n",
                                "import random\n",
                                "import joblib\n",
                                "import dcor\n",
                                "import networkx as nx\n",
                                "import numpy as np\n",
                                "import pandas as pd\n",
                                "import pingouin as pg\n",
                                "from tqdm.auto import tqdm\n",
                                "from sklearn.ensemble import RandomForestClassifier\n",
                                "from sklearn.feature_selection import mutual_info_regression\n",
                                "from sklearn.model_selection import GridSearchCV, GroupKFold, cross_val_score\n",
                                "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
                                "from sklearn.linear_model import Ridge, LinearRegression, LassoCV\n",
                                "from pgmpy.estimators import CITests\n",
                                "from scipy.spatial.distance import pdist, squareform\n",
                                "from econml.dml import CausalForestDML\n",
                                "from causallearn.graph.GraphNode import GraphNode\n",
                                "from causallearn.utils.PCUtils.BackgroundKnowledge import BackgroundKnowledge\n",
                                "from causallearn.search.ConstraintBased.PC import pc\n",
                                "from causallearn.search.ScoreBased.ExactSearch import bic_exact_search\n",
                                "from causallearn.search.FCMBased import lingam\n",
                                "from causallearn.search.ConstraintBased.FCI import fci\n",
                                "from causallearn.utils.GraphUtils import GraphUtils\n",
                                "from causallearn.utils.cit import fisherz\n",
                                "from causallearn.utils.PCUtils.BackgroundKnowledge import BackgroundKnowledge\n",
                                "from causallearn.graph.Node import Node\n",
                                "from causallearn.graph.GraphNode import GraphNode"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 3,
                        "metadata": {},
                        "outputs": [],
                        "source": [
                                "import warnings\n",
                                "warnings.filterwarnings('ignore', category=DeprecationWarning)   # 忽略PPS的警告"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 4,
                        "metadata": {
                                "ExecuteTime": {
                                        "end_time": "2024-09-20T02:42:13.047359Z",
                                        "start_time": "2024-09-20T02:42:12.325055Z"
                                },
                                "metadata": {}
                        },
                        "outputs": [
                                {
                                        "name": "stdout",
                                        "output_type": "stream",
                                        "text": [
                                                "loaded inline runner with module: <module '__main__'>\n"
                                        ]
                                }
                        ],
                        "source": [
                                "import crunch\n",
                                "crunch = crunch.load_notebook()"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 5,
                        "metadata": {
                                "ExecuteTime": {
                                        "end_time": "2024-09-18T09:30:54.182971Z",
                                        "start_time": "2024-09-18T09:30:54.145678Z"
                                }
                        },
                        "outputs": [],
                        "source": [
                                "def graph_nodes_representation(graph, nodelist):\n",
                                "    \"\"\"\n",
                                "    Create an alternative representation of a graph which is hashable\n",
                                "    and equivalent graphs have the same hash.\n",
                                "\n",
                                "    Python cannot PROPERLY use nx.Graph/DiGraph as key for\n",
                                "    dictionaries, because two equivalent graphs with just different\n",
                                "    order of the nodes would result in different keys. This is\n",
                                "    undesirable here.\n",
                                "\n",
                                "    So here we transform the graph into an equivalent form that is\n",
                                "    based on a specific nodelist and that is hashable. In this way,\n",
                                "    two equivalent graphs, once transformed, will result in identical\n",
                                "    keys.\n",
                                "\n",
                                "    So we use the following trick: extract the adjacency matrix\n",
                                "    (with nodes in a fixed order) and then make a hashable thing out\n",
                                "    of it, through tuple(array.flatten()):\n",
                                "    \"\"\"\n",
                                "\n",
                                "    # This get the adjacency matrix with nodes in a given order, as\n",
                                "    # numpy array (which is not hashable):\n",
                                "    adjacency_matrix = nx.adjacency_matrix(graph, nodelist=nodelist).todense()\n",
                                "\n",
                                "    # This transforms the numpy array into a hashable object:\n",
                                "    hashable = tuple(adjacency_matrix.flatten())\n",
                                "\n",
                                "    return hashable\n",
                                "\n",
                                "def create_graph_label():\n",
                                "    \"\"\"\n",
                                "    Create a dictionary from graphs to labels, in two formats.\n",
                                "    \"\"\"\n",
                                "    graph_label = {\n",
                                "        nx.DiGraph([(\"X\", \"Y\"), (\"v\", \"X\"), (\"v\", \"Y\")]): \"Confounder\",\n",
                                "        nx.DiGraph([(\"X\", \"Y\"), (\"X\", \"v\"), (\"Y\", \"v\")]): \"Collider\",\n",
                                "        nx.DiGraph([(\"X\", \"Y\"), (\"X\", \"v\"), (\"v\", \"Y\")]): \"Mediator\",\n",
                                "        nx.DiGraph([(\"X\", \"Y\"), (\"v\", \"X\")]):             \"Cause of X\",\n",
                                "        nx.DiGraph([(\"X\", \"Y\"), (\"v\", \"Y\")]):             \"Cause of Y\",\n",
                                "        nx.DiGraph([(\"X\", \"Y\"), (\"X\", \"v\")]):             \"Consequence of X\",\n",
                                "        nx.DiGraph([(\"X\", \"Y\"), (\"Y\", \"v\")]):             \"Consequence of Y\",\n",
                                "        nx.DiGraph({\"X\": [\"Y\"], \"v\": []}):                \"Independent\",\n",
                                "    }\n",
                                "\n",
                                "    nodelist = [\"v\", \"X\", \"Y\"]\n",
                                "\n",
                                "    # This is an equivalent alternative to graph_label but in a form\n",
                                "    # for which two equivalent graphs have the same key:\n",
                                "    adjacency_label = {\n",
                                "        graph_nodes_representation(graph, nodelist): label\n",
                                "        for graph, label in graph_label.items()\n",
                                "    }\n",
                                "\n",
                                "    return graph_label, adjacency_label\n",
                                "\n",
                                "def get_labels(adjacency_matrix, adjacency_label):\n",
                                "    \"\"\"\n",
                                "    Transform an adjacency_matrix (as pd.DataFrame) into a dictionary of variable:label\n",
                                "    \"\"\"\n",
                                "\n",
                                "    result = {}\n",
                                "    for variable in adjacency_matrix.columns.drop([\"X\", \"Y\"]):\n",
                                "        submatrix = adjacency_matrix.loc[[variable, \"X\", \"Y\"], [variable, \"X\", \"Y\"]]  # this is not hashable\n",
                                "        key = tuple(submatrix.values.flatten())  # this is hashable and a compatible with adjacency_label\n",
                                "    \n",
                                "        result[variable] = adjacency_label[key]\n",
                                "\n",
                                "    return result\n",
                                "\n",
                                "graph_label, adjacency_label = create_graph_label()"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 6,
                        "metadata": {},
                        "outputs": [],
                        "source": [
                                "def apply_mapping(df, mapping):\n",
                                "    df_new = df.copy()\n",
                                "    # 创建临时映射以避免冲突\n",
                                "    temp_mapping = {k: f'_temp_{k}' for k in mapping.keys()}\n",
                                "    df_new.rename(columns=temp_mapping, inplace=True)\n",
                                "    if df_new.shape[0] == df_new.shape[1]:  # 如果是方阵，如标签矩阵\n",
                                "        df_new.rename(index=temp_mapping, inplace=True)\n",
                                "    # 应用最终映射\n",
                                "    final_mapping = {f'_temp_{k}': v for k, v in mapping.items()}\n",
                                "    df_new.rename(columns=final_mapping, inplace=True)\n",
                                "    if df_new.shape[0] == df_new.shape[1]:\n",
                                "        df_new.rename(index=final_mapping, inplace=True)\n",
                                "    return df_new\n",
                                "\n",
                                "def check_duplicate_columns(df):\n",
                                "    \"\"\"检查是否存在重复的列名\"\"\"\n",
                                "    return df.columns.duplicated().any()\n",
                                "\n",
                                "def augment_data(X_train, y_train):\n",
                                "    new_X_train = X_train.copy()\n",
                                "    new_y_train = y_train.copy()\n",
                                "    for sample_id in X_train.keys():\n",
                                "        X = X_train[sample_id]\n",
                                "        y = y_train[sample_id]\n",
                                "        variables = list(X.columns)\n",
                                "        dim = len(variables)\n",
                                "        # 提取因果关系对\n",
                                "        edges = []\n",
                                "        for u in y.index:\n",
                                "            for v in y.columns:\n",
                                "                if y.loc[u, v] == 1:\n",
                                "                    edges.append((u, v))\n",
                                "        # 排除涉及 X 和 Y 的边\n",
                                "        edges_no_XY = [(u, v) for (u, v) in edges if u not in ['X', 'Y'] and v not in ['X', 'Y']]\n",
                                "        if dim >= 4:\n",
                                "            edges_to_use = edges_no_XY\n",
                                "            attempts = 0\n",
                                "            success = False\n",
                                "            while attempts < 3 and not success:\n",
                                "                if not edges_to_use:\n",
                                "                    break  # 没有合适的边，跳出循环\n",
                                "                u, v = random.choice(edges_to_use)\n",
                                "                mapping = {'X': u, 'Y': v, u: 'X', v: 'Y'}\n",
                                "                # 应用映射到特征矩阵和标签矩阵\n",
                                "                X_new = apply_mapping(X, mapping)\n",
                                "                y_new = apply_mapping(y, mapping)\n",
                                "                # 检查特征矩阵是否有重复列\n",
                                "                if check_duplicate_columns(X_new):\n",
                                "                    attempts += 1\n",
                                "                    continue  # 重试\n",
                                "                else:\n",
                                "                    # 没有重复列，存储新的数据\n",
                                "                    new_sample_id = '0' + sample_id\n",
                                "                    new_X_train[new_sample_id] = X_new\n",
                                "                    new_y_train[new_sample_id] = y_new\n",
                                "                    success = True\n",
                                "            if not success:\n",
                                "                # 没有找到合适的映射，复制原始数据\n",
                                "                new_sample_id = '0' + sample_id\n",
                                "                new_X_train[new_sample_id] = X.copy()\n",
                                "                new_y_train[new_sample_id] = y.copy()\n",
                                "        else:\n",
                                "            # 对于维度较低的数据，允许涉及 X 和 Y 的边\n",
                                "            edges_to_use = edges\n",
                                "            if not edges_to_use:\n",
                                "                # 没有边，复制原始数据\n",
                                "                new_sample_id = '0' + sample_id\n",
                                "                new_X_train[new_sample_id] = X.copy()\n",
                                "                new_y_train[new_sample_id] = y.copy()\n",
                                "                continue\n",
                                "            u, v = random.choice(edges_to_use)\n",
                                "            mapping = {'X': u, 'Y': v, u: 'X', v: 'Y'}\n",
                                "            # 应用映射到特征矩阵和标签矩阵\n",
                                "            X_new = apply_mapping(X, mapping)\n",
                                "            y_new = apply_mapping(y, mapping)\n",
                                "            # 检查特征矩阵是否有重复列\n",
                                "            if check_duplicate_columns(X_new):\n",
                                "                # 如果有重复列，复制原始数据\n",
                                "                new_sample_id = '0' + sample_id\n",
                                "                new_X_train[new_sample_id] = X.copy()\n",
                                "                new_y_train[new_sample_id] = y.copy()\n",
                                "            else:\n",
                                "                # 没有重复列，存储新的数据\n",
                                "                new_sample_id = '0' + sample_id\n",
                                "                new_X_train[new_sample_id] = X_new\n",
                                "                new_y_train[new_sample_id] = y_new\n",
                                "    return new_X_train, new_y_train"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 7,
                        "metadata": {
                                "ExecuteTime": {
                                        "end_time": "2024-09-20T02:43:04.532840Z",
                                        "start_time": "2024-09-20T02:42:51.402011Z"
                                },
                                "metadata": {}
                        },
                        "outputs": [
                                {
                                        "name": "stdout",
                                        "output_type": "stream",
                                        "text": [
                                                "download data\\X_train.pickle from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/48/X_train.pickle (1523944532 bytes)\n",
                                                "already exists: file length match\n",
                                                "download data\\y_train.pickle from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/48/y_train.pickle (7017735 bytes)\n",
                                                "already exists: file length match\n",
                                                "download data\\X_test.pickle from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/48/X_test_reduced.pickle (122341879 bytes)\n",
                                                "already exists: file length match\n",
                                                "download data\\y_test.pickle from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/48/y_test_reduced.pickle (562930 bytes)\n",
                                                "already exists: file length match\n",
                                                "download data\\example_prediction.parquet from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/48/example_prediction_reduced.parquet (668981 bytes)\n",
                                                "already exists: file length match\n",
                                                "23500 23500 1880\n"
                                        ]
                                }
                        ],
                        "source": [
                                "X_train, y_train, X_test = crunch.load_data()\n",
                                "print(len(X_train), len(y_train), len(X_test))\n",
                                "# X_train, y_train = augment_data(X_train, y_train)"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 8,
                        "metadata": {},
                        "outputs": [],
                        "source": [
                                "##################################################################################\n",
                                "###  Estimating Copula Entropy and Transfer Entropy \n",
                                "###  2024-10-02\n",
                                "###  by Ma Jian (Email: majian03@gmail.com)\n",
                                "###\n",
                                "###  Parameters\n",
                                "###\tx    \t: N * d data, N samples, d dimensions\n",
                                "###\tk    \t: kth nearest neighbour, parameter for kNN entropy estimation. default = 3\n",
                                "###\tdtype\t: distance type ['euclidean', 'chebychev' (i.e Maximum distance)]\n",
                                "###\tlag\t: time lag. default = 1\n",
                                "###\ts0,s1\t: two samples with same dimension\n",
                                "###\tn\t: repeat time of estimation. default = 12\n",
                                "###\tthd\t: threshold for the statistic of two-sample test\n",
                                "###\tmaxp\t: maximal number of change points\n",
                                "###\tminseglen : minimal length of binary segmentation\n",
                                "###\n",
                                "###  References\n",
                                "###  [1] Ma Jian, Sun Zengqi. Mutual information is copula entropy. \n",
                                "###      arXiv:0808.0845, 2008.\n",
                                "###  [2] Kraskov A, Stögbauer H, Grassberger P. Estimating mutual information. \n",
                                "###      Physical review E, 2004, 69(6): 066138.\n",
                                "###  [3] Ma, Jian. Estimating Transfer Entropy via Copula Entropy. \n",
                                "###      arXiv preprint arXiv:1910.04375, 2019.\n",
                                "###  [4] Ma, Jian. Multivariate Normality Test with Copula Entropy.\n",
                                "###      arXiv preprint arXiv:2206.05956, 2022.\n",
                                "###  [5] Ma, Jian. Two-Sample Test with Copula Entropy.\n",
                                "###      arXiv preprint arXiv:2307.07247, 2023.\n",
                                "###  [6] Ma, Jian. Change Point Detection with Copula Entropy based Two-Sample Test.\n",
                                "###      arXiv preprint arXiv:2403.07892, 2024.\n",
                                "##################################################################################\n",
                                "\n",
                                "from scipy.special import digamma\n",
                                "from scipy.stats import rankdata as rank \n",
                                "from scipy.spatial.distance import cdist\n",
                                "from math import gamma, log, pi\n",
                                "from numpy import array, abs, max, hstack, vstack, ones, zeros, cov, matrix, where\n",
                                "from numpy.random import uniform, normal as rnorm\n",
                                "from numpy.linalg import det\n",
                                "from multiprocessing.pool import Pool,ThreadPool\n",
                                "import sys\n",
                                "\n",
                                "##### constructing empirical copula density [1]\n",
                                "def construct_empirical_copula(x):\n",
                                "\t(N,d) = x.shape\t\n",
                                "\txc = zeros([N,d]) \n",
                                "\tfor i in range(0,d):\n",
                                "\t\txc[:,i] = rank(x[:,i]) / N\n",
                                "\t\n",
                                "\treturn xc\n",
                                "\n",
                                "##### Estimating entropy with kNN method [2]\n",
                                "def entknn(x, k = 3, dtype = 'chebychev'):\n",
                                "\t(N,d) = x.shape\n",
                                "\t\n",
                                "\tg1 = digamma(N) - digamma(k)\n",
                                "\t\n",
                                "\tif dtype == 'euclidean':\n",
                                "\t\tcd = pi**(d/2) / 2**d / gamma(1+d/2)\n",
                                "\telse:\t# (chebychev) maximum distance\n",
                                "\t\tcd = 1;\n",
                                "\n",
                                "\tlogd = 0\n",
                                "\tdists = cdist(x, x, dtype)\n",
                                "\tdists.sort()\n",
                                "\tfor i in range(0,N):\n",
                                "\t\tlogd = logd + log( 2 * dists[i,k] ) * d / N\n",
                                "\n",
                                "\treturn (g1 + log(cd) + logd)\n",
                                "\n",
                                "##### 2-step Nonparametric estimation of copula entropy [1]\n",
                                "def copent(x, k = 3, dtype = 'chebychev', log0 = False):\n",
                                "\txarray = array(x)\n",
                                "\n",
                                "\tif log0:\n",
                                "\t\t(N,d) = xarray.shape\n",
                                "\t\tmax1 = max(abs(xarray), axis = 0)\n",
                                "\t\tfor i in range(0,d):\n",
                                "\t\t\tif max1[i] == 0:\n",
                                "\t\t\t\txarray[:,i] = rnorm(0,1,N)\n",
                                "\t\t\telse:\n",
                                "\t\t\t\txarray[:,i] = xarray[:,i] + rnorm(0,1,N) * max1[i] * 0.000005\n",
                                "\n",
                                "\txc = construct_empirical_copula(xarray)\n",
                                "\n",
                                "\ttry:\n",
                                "\t\treturn -entknn(xc, k, dtype)\n",
                                "\texcept ValueError: # log0 error\n",
                                "\t\treturn copent(x, k, dtype, log0 = True)\n",
                                "\n",
                                "\n",
                                "##### conditional independence test [3]\n",
                                "##### to test independence of (x,y) conditioned on z\n",
                                "def ci(x, y, z, k = 3, dtype = 'chebychev'):\n",
                                "\txyz = vstack((x,y,z)).T\n",
                                "\tyz = vstack((y,z)).T\n",
                                "\txz = vstack((x,z)).T\n",
                                "\treturn copent(xyz,k,dtype) - copent(yz,k,dtype) - copent(xz,k,dtype)\n",
                                "\n",
                                "##### estimating transfer entropy from y to x with lag [3]\n",
                                "def transent(x, y, lag = 1, k = 3, dtype = 'chebychev'):\n",
                                "\txlen = len(x)\n",
                                "\tylen = len(y)\n",
                                "\tif (xlen > ylen):\n",
                                "\t\tl = ylen\n",
                                "\telse:\n",
                                "\t\tl = xlen\n",
                                "\tif (l < (lag + k + 1)):\n",
                                "\t\treturn 0\n",
                                "\tx1 = x[0:(l-lag)]\n",
                                "\tx2 = x[lag:l]\n",
                                "\ty = y[0:(l-lag)]\n",
                                "\treturn ci(x2,y,x1,k,dtype)\n",
                                "\n",
                                "##### multivariate normality test [4]\n",
                                "def mvnt(x, k = 3, dtype = 'chebychev'):\n",
                                "\treturn -0.5 * log(det(cov(x.T))) - copent(x,k,dtype)\n",
                                "\n",
                                "##### two-sample test [5]\n",
                                "def tst(s0,s1,n=12, k = 3, dtype = 'chebychev'):\n",
                                "\t(N0,d0) = s0.shape\n",
                                "\t(N1,d1) = s1.shape\n",
                                "\tx = vstack((s0,s1))\n",
                                "\tstat1 = 0\n",
                                "\tfor i in range(0,n):\n",
                                "\t\ty1 = vstack((ones([N0,1]),ones([N1,1])*2)) + uniform(0, 0.0000001,[N0+N1,1])\n",
                                "\t\ty0 = ones([N0+N1,1]) + uniform(0,0.0000001,[N0+N1,1])\n",
                                "\t\tstat1 = stat1 + copent(hstack((x,y1)),k,dtype) - copent(hstack((x,y0)),k,dtype)\n",
                                "\treturn stat1/n\n",
                                "\n",
                                "##### single change point detection [6]\n",
                                "def init(X,N,K,DTYPE):\n",
                                "\tglobal x,n,k,dtype\n",
                                "\tx = X\n",
                                "\tn = N\n",
                                "\tk = K\n",
                                "\tdtype = DTYPE\n",
                                "\n",
                                "def tsti(i):\n",
                                "\ts0 = x[0:(i+1),:]\n",
                                "\ts1 = x[(i+2):,:]\n",
                                "\treturn tst(s0,s1,n,k,dtype)\n",
                                "\t\n",
                                "def cpd(x, thd = 0.13, n = 30, k = 3, dtype = 'chebychev'):\n",
                                "\tx = matrix(x)\n",
                                "\tlen1 = x.shape[0]\n",
                                "\tif len1 == 1:\n",
                                "\t\tlen1 = x.shape[1]\n",
                                "\t\tx = x.T\n",
                                "\tpos = -1\n",
                                "\tmaxstat = 0\n",
                                "\tif sys.platform.startswith(\"win\"): # \"win\"\n",
                                "\t    pool = ThreadPool(initializer = init, initargs=(x,n,k,dtype))\n",
                                "\telse: # \"linux\" or \"darwin\"\n",
                                "\t    pool = Pool(initializer = init, initargs=(x,n,k,dtype))\n",
                                "\tstat1 = [0] + pool.map(tsti,range(len1-2)) + [0]\n",
                                "\tpool.close()\n",
                                "\tif(max(stat1) > thd):\n",
                                "\t\tmaxstat = max(stat1)\n",
                                "\t\tpos = where(stat1 == maxstat)[0][0]+1\n",
                                "\treturn pos, maxstat, stat1\n",
                                "\n",
                                "##### multiple change point detection [6]\n",
                                "def mcpd(x, maxp = 5, thd = 0.13, minseglen = 10, n = 30, k = 3, dtype = 'chebychev'):\n",
                                "\tx = matrix(x)\n",
                                "\tlen1 = x.shape[0]\n",
                                "\tif len1 == 1:\n",
                                "\t\tlen1 = x.shape[1]\n",
                                "\t\tx = x.T\n",
                                "\tmaxstat = []\n",
                                "\tpos = []\n",
                                "\tbisegs = matrix([0,len1-1])\n",
                                "\tfor i in range(0,maxp):\n",
                                "\t\tif i >= bisegs.shape[0]:\n",
                                "\t\t\tbreak\n",
                                "\t\trpos, rmaxstat, _ = cpd(x[bisegs[i,0]:bisegs[i,1],:],thd,n,k,dtype)\n",
                                "\t\tif rpos > -1 :\n",
                                "\t\t\trpos = rpos + bisegs[i,0]\n",
                                "\t\t\tmaxstat.append(rmaxstat)\n",
                                "\t\t\tpos.append(rpos)\n",
                                "\t\t\tif (rpos - bisegs[i,0]) > minseglen :\n",
                                "\t\t\t\tbisegs = vstack((bisegs,[bisegs[i,0],rpos-1]))\n",
                                "\t\t\tif (bisegs[i,1] - rpos +1) > minseglen :\n",
                                "\t\t\t\tbisegs = vstack((bisegs,[rpos,bisegs[i,1]]))\n",
                                "\treturn pos,maxstat"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 9,
                        "metadata": {
                                "ExecuteTime": {
                                        "end_time": "2024-09-18T09:31:23.461861Z",
                                        "start_time": "2024-09-18T09:31:23.368017Z"
                                },
                                "metadata": {}
                        },
                        "outputs": [],
                        "source": [
                                "def pearson_correlation(dataset):\n",
                                "    \"\"\"\n",
                                "    Given a dataset, we compute the correlation-based features for each\n",
                                "    varibale, which are the correlation between that variable with X and Y,\n",
                                "    as well as summary statistics (max, min, mean, std) of all pairs\n",
                                "    of correlations.\n",
                                "    \"\"\"\n",
                                "\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                                "\n",
                                "    df = []\n",
                                "    for variable in variables:\n",
                                "        tmp = dataset.corr().drop([variable], axis=\"columns\").loc[variable].abs()\n",
                                "\n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"corr(v,X)\": dataset[[variable, \"X\"]].corr().loc[variable, \"X\"],\n",
                                "            \"corr(v,Y)\": dataset[[variable, \"Y\"]].corr().loc[variable, \"Y\"],\n",
                                "            \"max(corr(v, others))\": tmp.max(),\n",
                                "            \"min(corr(v, others))\": tmp.min(),\n",
                                "            \"mean(corr(v, others))\": tmp.mean(),\n",
                                "            \"std(corr(v, others))\": tmp.std(),\n",
                                "            \"25%(corr(v, others))\": tmp.quantile(0.25), \n",
                                "            \"75%(corr(v, others))\": tmp.quantile(0.75), \n",
                                "        })\n",
                                "\n",
                                "\n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "\n",
                                "    df[\"corr(X,Y)\"] = dataset[[\"X\", \"Y\"]].corr().loc[\"X\", \"Y\"]\n",
                                "\n",
                                "    # pearsonr is NaN when the variance is 0, so we fill with 0\n",
                                "    df.fillna(0, inplace=True)\n",
                                "\n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                                "\n",
                                "    return df\n",
                                "\n",
                                "def mutual_information(dataset):\n",
                                "    \"\"\"\n",
                                "    Given a dataset, we compute the mutual-information-based features\n",
                                "    for each variable, which are the MI between that variable\n",
                                "    and X and Y, as well as summary statistics (max, min, mean, std) of\n",
                                "    all pairs of MI.\n",
                                "    \"\"\"\n",
                                "\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                                "\n",
                                "    df = []\n",
                                "    for variable in variables:\n",
                                "        tmp = mutual_info_regression(dataset.drop(columns=[variable]), dataset[variable])\n",
                                "        tmp = pd.Series(tmp)  # Convert tmp to a Pandas Series\n",
                                "\n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"MI(v,X)\": mutual_info_regression(dataset[[variable]], dataset[\"X\"], discrete_features=False)[0],\n",
                                "            \"MI(v,Y)\": mutual_info_regression(dataset[[variable]], dataset[\"Y\"], discrete_features=False)[0],\n",
                                "            \"max(MI(v, others))\": tmp.max(),\n",
                                "            \"min(MI(v, others))\": tmp.min(),\n",
                                "            \"mean(MI(v, others))\": tmp.mean(),\n",
                                "            \"std(MI(v, others))\": tmp.std(),\n",
                                "        })\n",
                                "\n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "\n",
                                "    df[\"MI(X,Y)\"] = mutual_info_regression(dataset[[\"X\"]], dataset[\"Y\"], discrete_features=False)[0]\n",
                                "\n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                                "\n",
                                "    return df\n",
                                "\n",
                                "def add_dimension_feature(dataset):\n",
                                "    \"\"\"\n",
                                "    Add a dimension feature to the dataset.\n",
                                "    \"\"\"\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                                "    dimension = len(variables)\n",
                                "    square_dimension = dimension * dimension\n",
                                "    df = pd.DataFrame({\n",
                                "        \"variable\": variables,\n",
                                "        \"dimension\": dimension,\n",
                                "        \"square_dimension\": square_dimension\n",
                                "    })\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "    \n",
                                "    return df\n",
                                "\n",
                                "def spearman_correlation(dataset):\n",
                                "    \"\"\"\n",
                                "    Given a dataset, we compute the Spearman rank correlation-based features for each\n",
                                "    variable, which are the Spearman correlation between that variable with X and Y,\n",
                                "    as well as summary statistics (max, min, mean, std) of all pairs of Spearman correlations.\n",
                                "    \"\"\"\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                                "\n",
                                "    df = []\n",
                                "    for variable in variables:\n",
                                "        tmp = dataset.corr(method='spearman').drop([variable], axis=\"columns\").loc[variable].abs()\n",
                                "\n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"spearman_corr(v,X)\": dataset[[variable, \"X\"]].corr(method='spearman').loc[variable, \"X\"],\n",
                                "            \"spearman_corr(v,Y)\": dataset[[variable, \"Y\"]].corr(method='spearman').loc[variable, \"Y\"],\n",
                                "            \"max(spearman_corr(v, others))\": tmp.max(),\n",
                                "            \"min(spearman_corr(v, others))\": tmp.min(),\n",
                                "            \"mean(spearman_corr(v, others))\": tmp.mean(),\n",
                                "            \"std(spearman_corr(v, others))\": tmp.std(),\n",
                                "            #TODO 分位数\n",
                                "        })\n",
                                "\n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "\n",
                                "    df[\"spearman_corr(X,Y)\"] = dataset[[\"X\", \"Y\"]].corr(method='spearman').loc[\"X\", \"Y\"]\n",
                                "\n",
                                "    # Spearman correlation is NaN when there are ties in rank, so we fill with 0\n",
                                "    df.fillna(0, inplace=True)\n",
                                "\n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                                "\n",
                                "    return df\n",
                                "\n",
                                "def kendall_correlation(dataset):\n",
                                "    \"\"\"\n",
                                "    Given a dataset, we compute the Kendall's tau correlation-based features for each\n",
                                "    variable, which are the Kendall's tau correlation between that variable with X and Y,\n",
                                "    as well as summary statistics (max, min, mean, std) of all pairs of Kendall's tau correlations.\n",
                                "    \"\"\"\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                                "\n",
                                "    df = []\n",
                                "    for variable in variables:\n",
                                "        tmp = dataset.corr(method='kendall').drop([variable], axis=\"columns\").loc[variable].abs()\n",
                                "\n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"kendall_corr(v,X)\": dataset[[variable, \"X\"]].corr(method='kendall').loc[variable, \"X\"],\n",
                                "            \"kendall_corr(v,Y)\": dataset[[variable, \"Y\"]].corr(method='kendall').loc[variable, \"Y\"],\n",
                                "            \"max(kendall_corr(v, others))\": tmp.max(),\n",
                                "            \"min(kendall_corr(v, others))\": tmp.min(),\n",
                                "            \"mean(kendall_corr(v, others))\": tmp.mean(),\n",
                                "            \"std(kendall_corr(v, others))\": tmp.std(),\n",
                                "        })\n",
                                "\n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "\n",
                                "    df[\"kendall_corr(X,Y)\"] = dataset[[\"X\", \"Y\"]].corr(method='kendall').loc[\"X\", \"Y\"]\n",
                                "\n",
                                "    # Kendall's tau correlation can be NaN in some cases, so we fill with 0\n",
                                "    df.fillna(0, inplace=True)\n",
                                "\n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                                "\n",
                                "    return df\n",
                                "\n",
                                "def distance_correlation(dataset):\n",
                                "    \"\"\"\n",
                                "    Given a dataset, we compute the distance correlation-based features for each\n",
                                "    variable, which are the distance correlation between that variable with X and Y,\n",
                                "    as well as summary statistics (max, min, mean, std) of all pairs of distance correlations.\n",
                                "    \"\"\"\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                                "\n",
                                "    df = []\n",
                                "    for variable in variables:\n",
                                "        tmp = []\n",
                                "        # Compute distance correlation between 'variable' and all other variables (excluding itself)\n",
                                "        other_variables = dataset.columns.drop([variable])\n",
                                "        for other_var in other_variables:\n",
                                "            corr = dcor.distance_correlation(dataset[variable], dataset[other_var])\n",
                                "            tmp.append(corr)\n",
                                "        tmp = pd.Series(tmp)  # Convert tmp to a Pandas Series\n",
                                "\n",
                                "        distance_correlation_v_X = dcor.distance_correlation(dataset[variable], dataset[\"X\"])\n",
                                "        distance_correlation_v_Y = dcor.distance_correlation(dataset[variable], dataset[\"Y\"])\n",
                                "        distance_correlation_X_Y = dcor.distance_correlation(dataset[\"X\"], dataset[\"Y\"])\n",
                                "        distance_correlation_v_X_square = distance_correlation_v_X ** 2\n",
                                "        distance_correlation_v_Y_square = distance_correlation_v_Y ** 2\n",
                                "        distance_correlation_X_Y_square = distance_correlation_X_Y ** 2\n",
                                "        \n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"dcor(v,X)\": distance_correlation_v_X,\n",
                                "            \"dcor(v,Y)\": distance_correlation_v_Y,\n",
                                "            \"dcor(v,X)^2\": distance_correlation_v_X_square,\n",
                                "            \"dcor(v,Y)^2\": distance_correlation_v_Y_square,\n",
                                "            \"max(dcor(v, others))\": tmp.max(),\n",
                                "            \"min(dcor(v, others))\": tmp.min(),\n",
                                "            \"mean(dcor(v, others))\": tmp.mean(),\n",
                                "            \"std(dcor(v, others))\": tmp.std(),\n",
                                "            \"25%(dcor(v, others))\": tmp.quantile(0.25),\n",
                                "            \"75%(dcor(v, others))\": tmp.quantile(0.75),\n",
                                "        })\n",
                                "\n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "\n",
                                "    df[\"dcor(X,Y)\"] = distance_correlation_X_Y\n",
                                "    df[\"dcor(X,Y)^2\"] = distance_correlation_X_Y_square\n",
                                "\n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                                "\n",
                                "    return df\n",
                                "\n",
                                "def distance_correlation_different_exponent(dataset):\n",
                                "    \"\"\"\n",
                                "    Given a dataset, we compute the distance correlation-based features for each\n",
                                "    variable, which are the distance correlation between that variable with X and Y,\n",
                                "    with different exponent, as well as summary statistics (max, min, mean, std) of all pairs of distance correlations.\n",
                                "    \"\"\"\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                                "\n",
                                "    df = []\n",
                                "    for variable in variables:\n",
                                "        tmp = []\n",
                                "        # Compute distance correlation between 'variable' and all other variables (excluding itself)\n",
                                "        other_variables = dataset.columns.drop([variable])\n",
                                "        for other_var in other_variables:\n",
                                "            corr = dcor.distance_correlation(dataset[variable], dataset[other_var])\n",
                                "            tmp.append(corr)\n",
                                "        tmp = pd.Series(tmp)  # Convert tmp to a Pandas Series\n",
                                "\n",
                                "        distance_correlation_v_X = dcor.distance_correlation(dataset[variable], dataset[\"X\"], exponent=0.5)\n",
                                "        distance_correlation_v_Y = dcor.distance_correlation(dataset[variable], dataset[\"Y\"], exponent=0.5)\n",
                                "        distance_correlation_X_Y = dcor.distance_correlation(dataset[\"X\"], dataset[\"Y\"], exponent=0.5)\n",
                                "        distance_correlation_v_X_square = distance_correlation_v_X ** 2\n",
                                "        distance_correlation_v_Y_square = distance_correlation_v_Y ** 2\n",
                                "        distance_correlation_X_Y_square = distance_correlation_X_Y ** 2\n",
                                "        \n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"dcor_0.5exp(v,X)\": distance_correlation_v_X,\n",
                                "            \"dcor_0.5exp(v,Y)\": distance_correlation_v_Y,\n",
                                "            \"dcor_0.5exp(v,X)^2\": distance_correlation_v_X_square,\n",
                                "            \"dcor_0.5exp(v,Y)^2\": distance_correlation_v_Y_square,\n",
                                "            \"max(dcor_0.5exp(v, others))\": tmp.max(),\n",
                                "            \"min(dcor_0.5exp(v, others))\": tmp.min(),\n",
                                "            \"mean(dcor_0.5exp(v, others))\": tmp.mean(),\n",
                                "            \"std(dcor_0.5exp(v, others))\": tmp.std(),\n",
                                "            \"25%(dcor_0.5exp(v, others))\": tmp.quantile(0.25),\n",
                                "            \"75%(dcor_0.5exp(v, others))\": tmp.quantile(0.75),\n",
                                "        })\n",
                                "\n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "\n",
                                "    df[\"dcor_0.5exp(X,Y)\"] = distance_correlation_X_Y\n",
                                "    df[\"dcor_0.5exp(X,Y)^2\"] = distance_correlation_X_Y_square\n",
                                "\n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                                "\n",
                                "    return df\n",
                                "\n",
                                "def double_centered_distance_matrix(X):\n",
                                "    \"\"\"Compute the double centered distance matrix for X.\"\"\"\n",
                                "    n = X.shape[0]\n",
                                "    dist_matrix = squareform(pdist(X[:, None]))  # Compute pairwise distances\n",
                                "    row_mean = np.mean(dist_matrix, axis=1, keepdims=True)\n",
                                "    col_mean = np.mean(dist_matrix, axis=0, keepdims=True)\n",
                                "    total_mean = np.mean(dist_matrix)\n",
                                "\n",
                                "    # Double-centering the matrix\n",
                                "    A = dist_matrix - row_mean - col_mean + total_mean\n",
                                "    return A\n",
                                "\n",
                                "def distance_covariance(X, Y):\n",
                                "    \"\"\"Compute distance covariance between X and Y.\"\"\"\n",
                                "    A = double_centered_distance_matrix(X)\n",
                                "    B = double_centered_distance_matrix(Y)\n",
                                "    dcov = np.mean(A * B)\n",
                                "    return dcov\n",
                                "\n",
                                "def partial_distance_covariance(X, Y, Z):\n",
                                "    \"\"\"Compute partial distance covariance between X and Y given Z.\"\"\"\n",
                                "    dcov_XY = distance_covariance(X, Y)\n",
                                "    dcov_XZ = distance_covariance(X, Z)\n",
                                "    dcov_YZ = distance_covariance(Y, Z)\n",
                                "    dcov_ZZ = distance_covariance(Z, Z)\n",
                                "\n",
                                "    # Partial distance covariance formula\n",
                                "    pdcov = dcov_XY - (dcov_XZ * dcov_YZ) / dcov_ZZ\n",
                                "    return pdcov\n",
                                "\n",
                                "def partial_distance_covariance_dataset(dataset):\n",
                                "    \"\"\"\n",
                                "    Given a dataset, we compute the partial distance covariance-based features for each\n",
                                "    variable, which are the partial distance covariance between that variable with X and Y,\n",
                                "    using each as the conditioning variable.\n",
                                "    \"\"\"\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                                "\n",
                                "    df = []\n",
                                "    for variable in variables:\n",
                                "        pdcov_v_X_given_Y = partial_distance_covariance(dataset[variable].values, dataset[\"X\"].values, dataset[\"Y\"].values)\n",
                                "        pdcov_v_Y_given_X = partial_distance_covariance(dataset[variable].values, dataset[\"Y\"].values, dataset[\"X\"].values)\n",
                                "        pdcov_X_Y_given_v = partial_distance_covariance(dataset[\"X\"].values, dataset[\"Y\"].values, dataset[variable].values)\n",
                                "\n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"pdcov(v,X|Y)\": pdcov_v_X_given_Y,\n",
                                "            \"pdcov(v,Y|X)\": pdcov_v_Y_given_X,\n",
                                "            \"pdcov(X,Y|v)\": pdcov_X_Y_given_v,\n",
                                "        })\n",
                                "\n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "\n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\", \"variable\", \"pdcov(v,X|Y)\", \"pdcov(v,Y|X)\", \"pdcov(X,Y|v)\"]]\n",
                                "\n",
                                "    return df\n",
                                "\n",
                                "def Squared_term(dataset, variables):\n",
                                "    for var in variables:\n",
                                "        dataset[f'{var}_squared_term'] = dataset[var] ** 2\n",
                                "    return dataset\n",
                                "    \n",
                                "def Interaction_term(dataset, variables):\n",
                                "    for i in range(len(variables)):\n",
                                "        for j in range(i + 1, len(variables)):\n",
                                "            dataset[f'{variables[i]}_{variables[j]}'] = dataset[variables[i]] * dataset[variables[j]]\n",
                                "    return dataset\n",
                                "\n",
                                "def Cos_Sin_term(dataset, variables):\n",
                                "    for var in variables:\n",
                                "        dataset[f'{var}_cos_term'] = np.cos(dataset[var])\n",
                                "        dataset[f'{var}_sin_term'] = np.sin(dataset[var])\n",
                                "    return dataset\n",
                                "\n",
                                "def linear_regression_feature(dataset):\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"]).tolist()\n",
                                "\n",
                                "    # model1: Fit X, v, v^2, v_i*v_j, v_i*X ~ Y\n",
                                "    model1_features = [\"X\"] + variables\n",
                                "    d1 = Squared_term(dataset[model1_features], model1_features)\n",
                                "    d1 = Interaction_term(d1, model1_features)  # 0.4600-0.4648\n",
                                "    # d1 = Cos_Sin_term(d1, variables)\n",
                                "    model1_features = d1.columns.tolist()\n",
                                "    scaler = StandardScaler()\n",
                                "    d1_scaled = scaler.fit_transform(d1)\n",
                                "    model1 = LinearRegression().fit(d1_scaled, dataset[[\"Y\"]])\n",
                                "    model1_coefs = model1.coef_[0].tolist()\n",
                                "    model1_dict = {name: coef for name, coef in zip(model1_features, model1_coefs)}\n",
                                "    \n",
                                "    # model2: Fit v, v^2, cos(v)/sin(v) ~ X\n",
                                "    model2_features = variables\n",
                                "    d2 = Squared_term(dataset[model2_features], model2_features)\n",
                                "    d2 = Interaction_term(d2, model2_features)  # 0.4648-0.4643\n",
                                "    d2 = Cos_Sin_term(d2, model2_features)\n",
                                "    model2_features = d2.columns.tolist()\n",
                                "    scaler = StandardScaler()\n",
                                "    d2_scaled = scaler.fit_transform(d2)\n",
                                "    model2 = LinearRegression().fit(d2_scaled, dataset[[\"X\"]])\n",
                                "    model2_coefs = model2.coef_[0].tolist()\n",
                                "    model2_dict = {name: coef for name, coef in zip(model2_features, model2_coefs)}\n",
                                "    \n",
                                "    df = []\n",
                                "    for i, variable in enumerate(variables):\n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"v~Y_coefficient\": model1_dict[variable],\n",
                                "            \"v_squared~Y_coefficient\": model1_dict[f\"{variable}_squared_term\"],\n",
                                "            # \"v_cos~Y_coefficient\": model1_dict[f\"{variable}_cos_term\"],  # 掉分\n",
                                "            # \"v_sin~Y_coefficient\": model1_dict[f\"{variable}_sin_term\"],\n",
                                "            \"v~X_coefficient\": model2_dict[variable],\n",
                                "            \"v_squared~X_coefficient\": model2_dict[f\"{variable}_squared_term\"],\n",
                                "            \"v_cos~X_coefficient\": model2_dict[f\"{variable}_cos_term\"], \n",
                                "            \"v_sin~X_coefficient\": model2_dict[f\"{variable}_sin_term\"],\n",
                                "        })\n",
                                "        \n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "    \n",
                                "    df[\"X~Y_coefficient\"] = model1_dict[\"X\"]\n",
                                "    \n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                                "\n",
                                "    return df\n",
                                "\n",
                                "def ridge_regression_feature(dataset):\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"]).tolist()\n",
                                "    # 使用GridSearchCV来选择最佳的alpha值\n",
                                "    param_grid = {'alpha': np.logspace(-6, 6, 13)}\n",
                                "    \n",
                                "    # model1: Fit X, v ~ Y\n",
                                "    model1_features = [\"X\"] + variables\n",
                                "    d1 = Squared_term(dataset[model1_features], model1_features)\n",
                                "    # d1 = Interaction_term(d1, model1_features) # 掉分\n",
                                "    model1_features = d1.columns.tolist()\n",
                                "    scaler1 = StandardScaler()\n",
                                "    d1_scaled = scaler1.fit_transform(d1)\n",
                                "    model1 = GridSearchCV(Ridge(random_state=42), param_grid, cv=5)\n",
                                "    model1.fit(d1_scaled, dataset[\"Y\"])\n",
                                "    model1_coefs = model1.best_estimator_.coef_.tolist()\n",
                                "    model1_dict = {name: coef for name, coef in zip(model1_features, model1_coefs)}\n",
                                "    \n",
                                "    # model2: Fit v ~ X\n",
                                "    model2_features = variables\n",
                                "    d2 = Squared_term(dataset[model2_features], model2_features)\n",
                                "    d2 = Interaction_term(d2, model2_features)\n",
                                "    # d2 = Cos_Sin_term(d2, model2_features)  # 掉分\n",
                                "    model2_features = d2.columns.tolist()\n",
                                "    scaler2 = StandardScaler()\n",
                                "    d2_scaled = scaler2.fit_transform(d2)\n",
                                "    model2 = GridSearchCV(Ridge(random_state=42), param_grid, cv=5)\n",
                                "    model2.fit(d2_scaled, dataset[\"X\"])\n",
                                "    model2_coefs = model2.best_estimator_.coef_.tolist()\n",
                                "    model2_dict = {name: coef for name, coef in zip(model2_features, model2_coefs)}\n",
                                "\n",
                                "    # # 获取最优的 alpha 值\n",
                                "    # best_alpha_model1 = model1.best_params_['alpha']   # 0.4730-0.4727\n",
                                "    # best_alpha_model2 = model2.best_params_['alpha']\n",
                                "    \n",
                                "    df = []\n",
                                "    for i, variable in enumerate(variables):\n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"v~Y_ridge_coefficient\": model1_dict[variable],\n",
                                "            # \"v_squared~Y_ridge_coefficient\": model1_dict[f\"{variable}_squared_term\"],  # 掉分\n",
                                "            \"v~X_ridge_coefficient\": model2_dict[variable],\n",
                                "            # \"v_squared~X_ridge_coefficient\": model2_dict[f\"{variable}_squared_term\"],  # 掉分\n",
                                "            # \"v_cos~X_ridge_coefficient\": model2_dict[f\"{variable}_cos_term\"],  # 掉分\n",
                                "            # \"v_sin~X_ridge_coefficient\": model2_dict[f\"{variable}_sin_term\"],  # 掉分\n",
                                "            # \"v~Y_ridge_alpha\": best_alpha_model1,\n",
                                "            # \"v~X_ridge_alpha\": best_alpha_model2\n",
                                "        })\n",
                                "        \n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "    \n",
                                "    df[\"X~Y_ridge_coefficient\"] = model1_dict[\"X\"]\n",
                                "    \n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                                "\n",
                                "    return df\n",
                                "\n",
                                "def conditional_independence_tests(dataset):  # 太慢了，得三个小时\n",
                                "    \"\"\"\n",
                                "    A mixed-data residualization based conditional independence test[1].\n",
                                "    Uses XGBoost estimator to compute LS residuals[2], and then does an association test (Pillai’s Trace) on the residuals.\n",
                                "    \"\"\"\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"]).tolist()\n",
                                "\n",
                                "    df = []\n",
                                "    for variable in variables:\n",
                                "        # v-X\n",
                                "        coef1, p_value1 = CITests.ci_pillai(X=variable, Y=\"X\", Z=dataset.columns.drop([\"X\", variable]).tolist(), data=dataset, boolean=False)\n",
                                "        # v-Y\n",
                                "        coef2, p_value2 = CITests.ci_pillai(X=variable, Y=\"Y\", Z=dataset.columns.drop([\"Y\", variable]).tolist(), data=dataset, boolean=False)\n",
                                "        # X-v\n",
                                "        coef3, p_value3 = CITests.ci_pillai(X=\"X\", Y=variable, Z=dataset.columns.drop([\"X\", variable]).tolist(), data=dataset, boolean=False)\n",
                                "        # Y-v\n",
                                "        coef4, p_value4 = CITests.ci_pillai(X=\"Y\", Y=variable, Z=dataset.columns.drop([\"Y\", variable]).tolist(), data=dataset, boolean=False)\n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"v~X_ci_pillai_coef\": coef1,\n",
                                "            \"v~X_ci_pillai_p_value\": p_value1,\n",
                                "            \"v~Y_ci_pillai_coef\": coef2,\n",
                                "            \"v~Y_ci_pillai_p_value\": p_value2,\n",
                                "            \"X~v_ci_pillai_coef\": coef3,\n",
                                "            \"X~v_ci_pillai_p_value\": p_value3,\n",
                                "            \"Y~v_ci_pillai_coef\": coef4,\n",
                                "            \"Y~v_ci_pillai_p_value\": p_value4\n",
                                "        })\n",
                                "    \n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "    \n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                                "\n",
                                "    return df\n",
                                "\n",
                                "def conditional_mutual_information(dataset):\n",
                                "    \"\"\"\n",
                                "    Calculate conditional mutual information for each variable with X and Y.\n",
                                "    \"\"\"\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                                "    \n",
                                "    df = []\n",
                                "    for variable in variables:\n",
                                "        # Calculate conditional MI(v, X | Y)\n",
                                "        mi_vx_given_y = mutual_info_regression(dataset[[variable, \"Y\"]], dataset[\"X\"], discrete_features=False)[0] - \\\n",
                                "                        mutual_info_regression(dataset[[\"Y\"]], dataset[\"X\"], discrete_features=False)[0]\n",
                                "        \n",
                                "        # Calculate conditional MI(v, Y | X)\n",
                                "        mi_vy_given_x = mutual_info_regression(dataset[[variable, \"X\"]], dataset[\"Y\"], discrete_features=False)[0] - \\\n",
                                "                        mutual_info_regression(dataset[[\"X\"]], dataset[\"Y\"], discrete_features=False)[0]\n",
                                "        \n",
                                "        # Calculate conditional MI(X, Y | v)\n",
                                "        mi_xy_given_v = mutual_info_regression(dataset[[\"X\", variable]], dataset[\"Y\"], discrete_features=False)[0] - \\\n",
                                "                        mutual_info_regression(dataset[[variable]], dataset[\"Y\"], discrete_features=False)[0]\n",
                                "        \n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"conditional_MI(v,X|Y)\": mi_vx_given_y,\n",
                                "            \"conditional_MI(v,Y|X)\": mi_vy_given_x,\n",
                                "            \"conditional_MI(X,Y|v)\": mi_xy_given_v,\n",
                                "        })\n",
                                "    \n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "    \n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                                "    \n",
                                "    return df\n",
                                "\n",
                                "def partial_correlation(dataset):\n",
                                "    \"\"\"\n",
                                "    Compute partial correlation coefficients for each variable with X and Y,\n",
                                "    controlling for the other variable, as well as the partial correlation\n",
                                "    between X and Y controlling for each variable.\n",
                                "    \"\"\"\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                                "    \n",
                                "    df = []\n",
                                "    for variable in variables:\n",
                                "        # Compute partial correlations\n",
                                "        pcorr_vX_Y = pg.partial_corr(data=dataset, x=variable, y='X', covar='Y')['r'].iloc[0]\n",
                                "        pcorr_vY_X = pg.partial_corr(data=dataset, x=variable, y='Y', covar='X')['r'].iloc[0]\n",
                                "        pcorr_XY_v = pg.partial_corr(data=dataset, x='X', y='Y', covar=variable)['r'].iloc[0]\n",
                                "        \n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"partial_corr(v,X|Y)\": pcorr_vX_Y,\n",
                                "            \"partial_corr(v,Y|X)\": pcorr_vY_X,\n",
                                "            \"partial_corr(X,Y|v)\": pcorr_XY_v,\n",
                                "        })\n",
                                "    \n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "    \n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                                "    \n",
                                "    return df\n",
                                "\n",
                                "\"\"\"因果发现算法的工具函数\"\"\"\n",
                                "def handle_multicollinearity(data, epsilon=1e-7, corr_threshold=0.99):\n",
                                "    \"\"\"\n",
                                "    检查数据中的多重共线性，并在需要时向存在多重共线性的列添加随机扰动。\n",
                                "    \n",
                                "    参数:\n",
                                "    - data (np.ndarray): 输入的数据矩阵，形状为 (样本数, 特征数)。\n",
                                "    - epsilon (float): 添加的随机扰动的尺度，默认值为1e-10。\n",
                                "    - corr_threshold (float): 判断高相关性的阈值，默认值为0.95。\n",
                                "    \n",
                                "    返回:\n",
                                "    - data (np.ndarray): 处理后的数据矩阵。\n",
                                "    \"\"\"\n",
                                "    # 计算相关系数矩阵\n",
                                "    corr_matrix = np.corrcoef(data, rowvar=False)\n",
                                "    n_cols = corr_matrix.shape[0]\n",
                                "\n",
                                "    # 使用集合存储所有涉及多重共线性的列索引，避免重复\n",
                                "    high_corr_indices = set()\n",
                                "    \n",
                                "    # 遍历相关系数矩阵的上三角部分，寻找高相关的列对\n",
                                "    for i in range(n_cols):\n",
                                "        for j in range(i+1, n_cols):\n",
                                "            if np.abs(corr_matrix[i, j]) > corr_threshold:\n",
                                "                high_corr_indices.add(i)\n",
                                "                high_corr_indices.add(j)\n",
                                "    \n",
                                "    if high_corr_indices:\n",
                                "        sorted_indices = sorted(high_corr_indices)\n",
                                "        # print(f\"检测到多重共线性，涉及的列索引: {sorted_indices}。正在添加随机扰动...\")\n",
                                "        \n",
                                "        # 生成与高相关性列对应的随机扰动\n",
                                "        noise = np.random.normal(0, epsilon, (data.shape[0], len(sorted_indices)))\n",
                                "        \n",
                                "        # 将扰动添加到相应的列\n",
                                "        data[:, sorted_indices] += noise\n",
                                "    \n",
                                "    return data\n",
                                "\n",
                                "def convert_bidirectional_to_dag(bidirectional_adj: pd.DataFrame) -> pd.DataFrame:\n",
                                "    \"\"\"\n",
                                "    将双向编码的邻接矩阵转换为单向编码的邻接矩阵（DAG表示）。\n",
                                "    \n",
                                "    在双向编码的邻接矩阵中：\n",
                                "    - [j, i] = 1 且 [i, j] = -1 表示 i → j\n",
                                "    - [j, i] = 1 且 [i, j] = 1 表示 i ↔ j（互为因果）\n",
                                "    - 其他情况 [i, j] = 0 表示无边\n",
                                "    \n",
                                "    转换后，单向编码的邻接矩阵将：\n",
                                "    - [i, j] = 1 表示 i → j\n",
                                "    - [i, j] = 1 且 [j, i] = 1 表示 i ↔ j\n",
                                "    - [i, j] = 0 表示无边\n",
                                "    \n",
                                "    参数:\n",
                                "    - bidirectional_adj (pd.DataFrame): 双向编码的邻接矩阵，使用 1 和 -1 表示有向边。\n",
                                "    \n",
                                "    返回:\n",
                                "    - pd.DataFrame: 单向编码的邻接矩阵（DAG表示）。\n",
                                "    \"\"\"\n",
                                "    # 确保输入是一个方阵\n",
                                "    if bidirectional_adj.shape[0] != bidirectional_adj.shape[1]:\n",
                                "        raise ValueError(\"输入的邻接矩阵必须是方阵（行数等于列数）。\")\n",
                                "    \n",
                                "    # 确保行列索引一致\n",
                                "    if not bidirectional_adj.index.equals(bidirectional_adj.columns):\n",
                                "        raise ValueError(\"邻接矩阵的行索引和列索引必须相同。\")\n",
                                "    \n",
                                "    # 初始化一个全零的邻接矩阵\n",
                                "    single_direction_adj = pd.DataFrame(0, index=bidirectional_adj.index, columns=bidirectional_adj.columns)\n",
                                "    \n",
                                "    # 遍历每一对变量，确定有向边\n",
                                "    for source in bidirectional_adj.columns:\n",
                                "        for target in bidirectional_adj.index:\n",
                                "            if source == target:\n",
                                "                # 根据DAG定义，通常不允许自环，因此设置为0\n",
                                "                single_direction_adj.at[source, target] = 0\n",
                                "                continue\n",
                                "            \n",
                                "            # 检查双向编码的邻接矩阵来确定有向边\n",
                                "            if bidirectional_adj.at[target, source] == 1:\n",
                                "                if bidirectional_adj.at[source, target] == -1:\n",
                                "                    # 表示 source → target\n",
                                "                    single_direction_adj.at[source, target] = 1\n",
                                "                elif bidirectional_adj.at[source, target] == 1:\n",
                                "                    # 表示 source ↔ target（互为因果）\n",
                                "                    single_direction_adj.at[source, target] = 1\n",
                                "                    single_direction_adj.at[target, source] = 1\n",
                                "                # 如果 [source, target] == 0 或其他情况，不设置边\n",
                                "    return single_direction_adj\n",
                                "\n",
                                "def convert_dag_with_strength_to_dag(adj: pd.DataFrame) -> pd.DataFrame:\n",
                                "    \"\"\"\n",
                                "    将表示因果影响强度的邻接矩阵数据框转换为二元邻接矩阵数据框。\n",
                                "    无论存在正向影响还是负向影响，都将其转换为1；不存在影响则为0。\n",
                                "    \n",
                                "    参数:\n",
                                "    - adj (pd.DataFrame): 原始的因果影响强度邻接矩阵，元素可以是正数、负数或0。\n",
                                "    \n",
                                "    返回:\n",
                                "    - pd.DataFrame: 二元邻接矩阵，元素为0或1。\n",
                                "    \"\"\"\n",
                                "    # 确保输入是一个方阵\n",
                                "    if adj.shape[0] != adj.shape[1]:\n",
                                "        raise ValueError(\"输入的邻接矩阵必须是方阵（行数等于列数）。\")\n",
                                "    \n",
                                "    # 确保行列索引一致\n",
                                "    if not adj.index.equals(adj.columns):\n",
                                "        raise ValueError(\"邻接矩阵的行索引和列索引必须相同。\")\n",
                                "    \n",
                                "    # 将所有非零元素转换为1，零元素保持为0\n",
                                "    return adj.ne(0).astype(int)\n",
                                "\n",
                                "\"\"\"因果发现算法\"\"\"\n",
                                "def PC_estimate(dataset, alpha=0.05, indep_test='fisherz', kernel=None, stable=True, \n",
                                "               uc_rule=0, uc_priority=2, verbose=False, show_progress=False):\n",
                                "    \"\"\"\n",
                                "    使用PC算法进行因果发现，并应用先验知识。\n",
                                "\n",
                                "    参数:\n",
                                "    - dataset (pd.DataFrame): 输入的数据框，包含'X'、'Y'和其他协变量。\n",
                                "    - alpha (float): 显著性水平，默认值为0.05。\n",
                                "    - indep_test (str): 独立性检验方法，默认值为'fisherz'。\n",
                                "    - kernel (str): 核函数类型，默认值为'linear'。\n",
                                "    - stable (bool): 是否运行稳定的骨架发现，默认值为True。\n",
                                "    - uc_rule (int): 未屏蔽碰撞点的定向规则，默认值为0。\n",
                                "    - uc_priority (int): 解决未屏蔽碰撞点冲突的优先规则，默认值为2。\n",
                                "    - verbose (bool): 是否打印详细输出，默认值为False。\n",
                                "    - show_progress (bool): 是否显示算法进度，默认值为False。\n",
                                "\n",
                                "    返回:\n",
                                "    - adj_df (pd.DataFrame): 因果图的邻接矩阵，格式为pivot_table。\n",
                                "    \"\"\"\n",
                                "    \n",
                                "    # 1. 将数据框转换为numpy.ndarray\n",
                                "    data = dataset.values\n",
                                "\n",
                                "    # 检验相关系数是否奇异，如果存在多重共线性，对存在多重共线性的变量添加随机扰动\n",
                                "    data = handle_multicollinearity(data)\n",
                                "    \n",
                                "    # 2. 定义先验知识：'X' → 'Y'\n",
                                "    # 创建GraphNode对象\n",
                                "    try:\n",
                                "        node_X = GraphNode('X')\n",
                                "        node_Y = GraphNode('Y')\n",
                                "    except Exception as e:\n",
                                "        raise ValueError(\"确保数据框中包含名为'X'和'Y'的列。\") from e\n",
                                "    \n",
                                "    # 初始化BackgroundKnowledge对象并添加先验知识\n",
                                "    bk = BackgroundKnowledge().add_required_by_node(node_X, node_Y)\n",
                                "\n",
                                "    # 3. 配置核参数\n",
                                "    if indep_test == 'kci':\n",
                                "        if kernel is None:\n",
                                "            kernel = 'linear'\n",
                                "        if kernel == 'linear':\n",
                                "            kernel_kwargs = {\n",
                                "                'kernelX': 'Linear', \n",
                                "                'kernelY': 'Linear', \n",
                                "                'kernelZ': 'Linear', \n",
                                "                'approx': True,           # 使用伽玛近似\n",
                                "                'nullss': 1000,          # 原假设下模拟的样本量\n",
                                "            }\n",
                                "        elif kernel == 'polynomial':\n",
                                "            kernel_kwargs = {\n",
                                "                'kernelX': 'Polynomial', \n",
                                "                'kernelY': 'Polynomial', \n",
                                "                'kernelZ': 'Polynomial', \n",
                                "                'polyd': 3,               # 多项式次数设置为3\n",
                                "                'approx': True,           # 使用伽玛近似\n",
                                "                'nullss': 1000,          # 原假设下模拟的样本量\n",
                                "            }\n",
                                "        elif kernel == 'gaussian':\n",
                                "            kernel_kwargs = {\n",
                                "                'kernelX': 'Gaussian', \n",
                                "                'kernelY': 'Gaussian', \n",
                                "                'kernelZ': 'Gaussian', \n",
                                "                'est_width': 'empirical', # 使用经验宽度\n",
                                "                'approx': True,           # 使用伽玛近似\n",
                                "                'nullss': 1000,          # 原假设下模拟的样本量\n",
                                "            }\n",
                                "        elif kernel == 'mix':\n",
                                "            kernel_kwargs = {\n",
                                "                'kernelX': 'Polynomial', \n",
                                "                'kernelY': 'Polynomial', \n",
                                "                'kernelZ': 'Gaussian',     # Z使用高斯核\n",
                                "                'polyd': 3,                # 多项式次数设置为3\n",
                                "                'est_width': 'median',     # Z的高斯核带宽使用中位数技巧\n",
                                "                'approx': True,            # 使用伽玛近似\n",
                                "                'nullss': 1000,           # 原假设下模拟的样本量\n",
                                "            }\n",
                                "        else:\n",
                                "            raise ValueError(f'Unknown kernel: {kernel}')\n",
                                "    else:\n",
                                "        kernel_kwargs = {}\n",
                                "\n",
                                "    # 4. 运行PC算法，传入先验知识\n",
                                "    cg = pc(data, alpha=alpha, indep_test=indep_test, stable=stable, uc_rule=uc_rule, uc_priority=uc_priority, \n",
                                "            background_knowledge=bk, verbose=verbose, show_progress=show_progress, **kernel_kwargs)\n",
                                "    \n",
                                "    # 5. 提取邻接矩阵\n",
                                "    adj_matrix = cg.G.graph\n",
                                "    # 6. 将邻接矩阵转换为pandas DataFrame，并设置行列索引为原数据框的列名\n",
                                "    adj_df = pd.DataFrame(adj_matrix, index=dataset.columns, columns=dataset.columns)\n",
                                "    \n",
                                "    return adj_df\n",
                                "\n",
                                "def PC_feature(dataset):\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"]).tolist()\n",
                                "\n",
                                "    estimate_adj_df_bidirectional = PC_estimate(dataset)  # 双向的估计因果图\n",
                                "    estimate_adj_df_dag = convert_bidirectional_to_dag(estimate_adj_df_bidirectional)  # 将双向图转换为有向图\n",
                                "\n",
                                "    df = []\n",
                                "    for variable in variables:\n",
                                "        # 检查变量与'X'和'Y'之间的边\n",
                                "        v_to_X = estimate_adj_df_dag.loc[variable, 'X']\n",
                                "        X_to_v = estimate_adj_df_dag.loc['X', variable]\n",
                                "        v_to_Y = estimate_adj_df_dag.loc[variable, 'Y']\n",
                                "        Y_to_v = estimate_adj_df_dag.loc['Y', variable]\n",
                                "        X_to_Y = estimate_adj_df_dag.loc['X', 'Y']\n",
                                "\n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"PC(v,X)\": v_to_X,\n",
                                "            \"PC(X,v)\": X_to_v,\n",
                                "            \"PC(v,Y)\": v_to_Y,\n",
                                "            \"PC(Y,v)\": Y_to_v,\n",
                                "            \"PC(X,Y)\": X_to_Y\n",
                                "        })\n",
                                "\n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "\n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                                "\n",
                                "    return df\n",
                                "\n",
                                "def ExactSearch_estimate(dataset, search_method='astar', use_path_extension=True, \n",
                                "                        use_k_cycle_heuristic=False, k=3, max_parents=None):\n",
                                "    \"\"\"\n",
                                "    使用Exact Search算法进行因果发现。\n",
                                "    \n",
                                "    参数:\n",
                                "    - dataset (pd.DataFrame): 输入的数据框，包含'X'、'Y'和其他协变量。\n",
                                "    - search_method (str): Exact Search方法，'astar'或'dp'。默认值为'astar'。\n",
                                "    - use_path_extension (bool): 是否使用路径扩展。默认值为True。\n",
                                "    - use_k_cycle_heuristic (bool): 是否使用k-cycle冲突启发式。仅适用于'astar'方法。默认值为False。\n",
                                "    - k (int): k-cycle启发式的参数。默认值为3。\n",
                                "    - max_parents (int or None): 节点的最大父节点数量。默认值为None。\n",
                                "    \n",
                                "    返回:\n",
                                "    - adj_df (pd.DataFrame): 因果图的邻接矩阵，格式为DataFrame。\n",
                                "    \"\"\"\n",
                                "    \n",
                                "    # 1. 将数据框转换为numpy.ndarray\n",
                                "    data = dataset.values\n",
                                "\n",
                                "    # 检验相关系数是否奇异，如果存在多重共线性，对存在多重共线性的变量添加随机扰动\n",
                                "    data = handle_multicollinearity(data)\n",
                                "\n",
                                "    # 2. 定义X→Y的超级图\n",
                                "    d = dataset.shape[1]   \n",
                                "    super_graph = np.ones((d, d), dtype=int)  # 初始化为全1，表示所有边默认允许\n",
                                "    columns = dataset.columns.tolist()\n",
                                "    x_idx = columns.index('X')\n",
                                "    y_idx = columns.index('Y')\n",
                                "    super_graph[y_idx][x_idx] = 0     # 禁止'Y'→'X'\n",
                                "    np.fill_diagonal(super_graph, 0)  # 禁止自环：确保对角线为0\n",
                                "    \n",
                                "    # 3. 运行Exact Search算法，使用指定的参数\n",
                                "    dag_est, search_stats = bic_exact_search(X=data, super_graph=super_graph, search_method=search_method,\n",
                                "        use_path_extension=use_path_extension, use_k_cycle_heuristic=use_k_cycle_heuristic,\n",
                                "        k=k, verbose=False, max_parents=max_parents)\n",
                                "    \n",
                                "    # 4. 将邻接矩阵转换为pandas DataFrame，并设置行列索引为原数据框的列名\n",
                                "    adj_df = pd.DataFrame(dag_est, index=dataset.columns, columns=dataset.columns)\n",
                                "    \n",
                                "    return adj_df\n",
                                "\n",
                                "def ExactSearch_feature(dataset):\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"]).tolist()\n",
                                "\n",
                                "    estimate_adj_df = ExactSearch_estimate(dataset)\n",
                                "    estimate_adj_df_dag = estimate_adj_df.astype(int)  # 将双向图转换为有向图\n",
                                "\n",
                                "    df = []\n",
                                "    for variable in variables:\n",
                                "        # 检查变量与'X'和'Y'之间的边\n",
                                "        v_to_X = estimate_adj_df_dag.loc[variable, 'X']\n",
                                "        X_to_v = estimate_adj_df_dag.loc['X', variable]\n",
                                "        v_to_Y = estimate_adj_df_dag.loc[variable, 'Y']\n",
                                "        Y_to_v = estimate_adj_df_dag.loc['Y', variable]\n",
                                "        X_to_Y = estimate_adj_df_dag.loc['X', 'Y']\n",
                                "\n",
                                "        # v_to_others = sum(estimate_adj_df_dag.loc[variable, variables])\n",
                                "        # others_to_v = sum(estimate_adj_df_dag.loc[variables, variable])\n",
                                "\n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"ExactSearch(v,X)\": v_to_X,\n",
                                "            \"ExactSearch(X,v)\": X_to_v,\n",
                                "            \"ExactSearch(v,Y)\": v_to_Y,\n",
                                "            \"ExactSearch(Y,v)\": Y_to_v,\n",
                                "            \"ExactSearch(X,Y)\": X_to_Y\n",
                                "            # \"ExactSearch(v,others)\": v_to_others,\n",
                                "            # \"ExactSearch(others,v)\": others_to_v\n",
                                "        })\n",
                                "\n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "\n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                                "\n",
                                "    return df\n",
                                "\n",
                                "def FCI_estimate(dataset, alpha=0.05, indep_test='fisherz', kernel=None, \n",
                                "               depth=-1, max_path_length=-1, verbose=False, show_progress=False):\n",
                                "    \"\"\"\n",
                                "    使用FCI算法进行因果发现，并应用先验知识。\n",
                                "\n",
                                "    参数:\n",
                                "    - dataset (pd.DataFrame): 输入的数据框，包含'X'、'Y'和其他协变量。\n",
                                "    - alpha (float): 显著性水平，默认值为0.05。\n",
                                "    - indep_test (str): 独立性检验方法，默认值为'fisherz'。\n",
                                "    - kernel (str): 核函数类型，默认值为'linear'。\n",
                                "    - verbose (bool): 是否打印详细输出，默认值为False。\n",
                                "    - show_progress (bool): 是否显示算法进度，默认值为False。\n",
                                "\n",
                                "    返回:\n",
                                "    - adj_df (pd.DataFrame): 因果图的邻接矩阵，格式为pivot_table。\n",
                                "    \"\"\"\n",
                                "    \n",
                                "    # 1. 将数据框转换为numpy.ndarray\n",
                                "    data = dataset.values\n",
                                "\n",
                                "    # 检验相关系数是否奇异，如果存在多重共线性，对存在多重共线性的变量添加随机扰动\n",
                                "    data = handle_multicollinearity(data)\n",
                                "    \n",
                                "    # 2. 定义先验知识：'X' → 'Y'\n",
                                "    # 创建GraphNode对象\n",
                                "    try:\n",
                                "        node_X = GraphNode('X')\n",
                                "        node_Y = GraphNode('Y')\n",
                                "    except Exception as e:\n",
                                "        raise ValueError(\"确保数据框中包含名为'X'和'Y'的列。\") from e\n",
                                "    \n",
                                "    # 初始化BackgroundKnowledge对象并添加先验知识\n",
                                "    bk = BackgroundKnowledge().add_required_by_node(node_X, node_Y)\n",
                                "\n",
                                "    # 3. 配置核参数\n",
                                "    if indep_test == 'kci':\n",
                                "        if kernel is None:\n",
                                "            kernel = 'linear'\n",
                                "        if kernel == 'linear':\n",
                                "            kernel_kwargs = {\n",
                                "                'kernelX': 'Linear', \n",
                                "                'kernelY': 'Linear', \n",
                                "                'kernelZ': 'Linear', \n",
                                "                'approx': True,           # 使用伽玛近似\n",
                                "                'nullss': 1000,          # 原假设下模拟的样本量\n",
                                "            }\n",
                                "        elif kernel == 'polynomial':\n",
                                "            kernel_kwargs = {\n",
                                "                'kernelX': 'Polynomial', \n",
                                "                'kernelY': 'Polynomial', \n",
                                "                'kernelZ': 'Polynomial', \n",
                                "                'polyd': 3,               # 多项式次数设置为3\n",
                                "                'approx': True,           # 使用伽玛近似\n",
                                "                'nullss': 1000,          # 原假设下模拟的样本量\n",
                                "            }\n",
                                "        elif kernel == 'gaussian':\n",
                                "            kernel_kwargs = {\n",
                                "                'kernelX': 'Gaussian', \n",
                                "                'kernelY': 'Gaussian', \n",
                                "                'kernelZ': 'Gaussian', \n",
                                "                'est_width': 'empirical', # 使用经验宽度\n",
                                "                'approx': True,           # 使用伽玛近似\n",
                                "                'nullss': 1000,          # 原假设下模拟的样本量\n",
                                "            }\n",
                                "        elif kernel == 'mix':\n",
                                "            kernel_kwargs = {\n",
                                "                'kernelX': 'Polynomial', \n",
                                "                'kernelY': 'Polynomial', \n",
                                "                'kernelZ': 'Gaussian',     # Z使用高斯核\n",
                                "                'polyd': 3,                # 多项式次数设置为3\n",
                                "                'est_width': 'median',     # Z的高斯核带宽使用中位数技巧\n",
                                "                'approx': True,            # 使用伽玛近似\n",
                                "                'nullss': 1000,           # 原假设下模拟的样本量\n",
                                "            }\n",
                                "        else:\n",
                                "            raise ValueError(f'Unknown kernel: {kernel}')\n",
                                "    else:\n",
                                "        kernel_kwargs = {}\n",
                                "\n",
                                "    # 4. 运行FCI算法，传入先验知识\n",
                                "    try:\n",
                                "        g, edges = fci(data, \n",
                                "                alpha=alpha, \n",
                                "                independence_test_method=indep_test, \n",
                                "                depth=depth,\n",
                                "                max_path_length=max_path_length,\n",
                                "                background_knowledge=bk, \n",
                                "                verbose=verbose, \n",
                                "                show_progress=show_progress,\n",
                                "                **kernel_kwargs\n",
                                "        )\n",
                                "\n",
                                "        # 5. 提取邻接矩阵\n",
                                "        adj_matrix = g.graph\n",
                                "    except Exception as e:\n",
                                "        adj_matrix = np.zeros((data.shape[1], data.shape[1]))\n",
                                "    \n",
                                "    # 6. 将邻接矩阵转换为pandas DataFrame，并设置行列索引为原数据框的列名\n",
                                "    adj_df = pd.DataFrame(adj_matrix, index=dataset.columns, columns=dataset.columns)\n",
                                "    \n",
                                "    return adj_df\n",
                                "\n",
                                "def FCI_feature(dataset):\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"]).tolist()\n",
                                "\n",
                                "    estimate_adj_df_bidirectional = FCI_estimate(dataset)  # PAG\n",
                                "    estimate_adj_df_dag = estimate_adj_df_bidirectional.astype('int')\n",
                                "\n",
                                "    df = []\n",
                                "    for variable in variables:\n",
                                "        # 检查变量与'X'和'Y'之间的边\n",
                                "        v_to_X = estimate_adj_df_dag.loc[variable, 'X']\n",
                                "        X_to_v = estimate_adj_df_dag.loc['X', variable]\n",
                                "        v_to_Y = estimate_adj_df_dag.loc[variable, 'Y']\n",
                                "        Y_to_v = estimate_adj_df_dag.loc['Y', variable]\n",
                                "        X_to_Y = estimate_adj_df_dag.loc['X', 'Y']\n",
                                "\n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"FCI(v,X)\": v_to_X,\n",
                                "            \"FCI(X,v)\": X_to_v,\n",
                                "            \"FCI(v,Y)\": v_to_Y,\n",
                                "            \"FCI(Y,v)\": Y_to_v,\n",
                                "            \"FCI(X,Y)\": X_to_Y\n",
                                "        })\n",
                                "\n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\", \"variable\"] + [col for col in df.columns if col not in [\"dataset\", \"variable\"]]]\n",
                                "\n",
                                "    return df\n",
                                "\n",
                                "\"\"\"DML-有内存泄漏\"\"\"\n",
                                "def DML_estimate(T_, Y_, X_, data):\n",
                                "    # 设置处理变量、结果变量和控制变量\n",
                                "    T = data[T_].values.reshape(-1, 1)\n",
                                "    Y = data[Y_].values.reshape(-1, 1)\n",
                                "    X = data[X_].values\n",
                                "\n",
                                "    # 定义 LassoCV 作为第一阶段模型\n",
                                "    model_t = LassoCV(cv=4, random_state=42, n_jobs=None)\n",
                                "    model_y = LassoCV(cv=4, random_state=42, n_jobs=None)\n",
                                "\n",
                                "    # 初始化 CausalForestDML 使用自定义的估计器，并设置 random_state\n",
                                "    model = CausalForestDML(\n",
                                "        model_t=model_t,  #\"forest\",\n",
                                "        model_y=model_y,  #\"forest\",\n",
                                "        cv=4,\n",
                                "        n_estimators=36,\n",
                                "        n_jobs=None,\n",
                                "        random_state=42,  # 确保随机性的一致性\n",
                                "        inference=True\n",
                                "    )\n",
                                "    model.fit(Y, T, X=X)\n",
                                "\n",
                                "    # 平均边际处理效应的推断结果\n",
                                "    amte_inference = model.ate_inference(X=X)\n",
                                "\n",
                                "    return amte_inference\n",
                                "\n",
                                "def DML_feature(dataset):\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                                "\n",
                                "    df = []\n",
                                "    for variable in variables:\n",
                                "        # 判断v-X的因果效应，设置variables中的其他v和Y为控制变量\n",
                                "        amte_inference1 = DML_estimate(variable, \"X\", [\"Y\"] + list(variables.drop(variable)), dataset)\n",
                                "        # 判断v-Y的因果效应，设置variables中的其他v和X为控制变量\n",
                                "        amte_inference2 = DML_estimate(variable, \"Y\", [\"X\"] + list(variables.drop(variable)), dataset)\n",
                                "        # 判断X-v的因果效应，设置variables中的其他v和Y为控制变量\n",
                                "        amte_inference3 = DML_estimate(\"X\", variable, [\"Y\"] + list(variables.drop(variable)), dataset)\n",
                                "        # 判断Y-v的因果效应，设置variables中的其他v和X为控制变量\n",
                                "        amte_inference4 = DML_estimate(\"Y\", variable, [\"X\"] + list(variables.drop(variable)), dataset)\n",
                                "\n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"v~X_DML_AMTE\": amte_inference1.mean_point,  \n",
                                "            \"v~X_DML_AMTE_zstat\": amte_inference1.zstat(),\n",
                                "            \"v~X_DML_AMTE_pvalue\": amte_inference1.pvalue(),\n",
                                "            \"v~X_DML_std_point\": amte_inference1.std_point,\n",
                                "            \"v~X_DML_stderr_point\": amte_inference1.stderr_point,\n",
                                "\n",
                                "            \"v~Y_DML_AMTE\": amte_inference2.mean_point,\n",
                                "            \"v~Y_DML_AMTE_zstat\": amte_inference2.zstat(),\n",
                                "            \"v~Y_DML_AMTE_pvalue\": amte_inference2.pvalue(),\n",
                                "            \"v~Y_DML_std_point\": amte_inference2.std_point,\n",
                                "            \"v~Y_DML_stderr_point\": amte_inference2.stderr_point,\n",
                                "\n",
                                "            \"X~v_DML_AMTE\": amte_inference3.mean_point,\n",
                                "            \"X~v_DML_AMTE_zstat\": amte_inference3.zstat(),\n",
                                "            \"X~v_DML_AMTE_pvalue\": amte_inference3.pvalue(),\n",
                                "            \"X~v_DML_std_point\": amte_inference3.std_point,\n",
                                "            \"X~v_DML_stderr_point\": amte_inference3.stderr_point,\n",
                                "\n",
                                "            \"Y~v_DML_AMTE\": amte_inference4.mean_point,\n",
                                "            \"Y~v_DML_AMTE_zstat\": amte_inference4.zstat(),\n",
                                "            \"Y~v_DML_AMTE_pvalue\": amte_inference4.pvalue(),\n",
                                "            \"Y~v_DML_std_point\": amte_inference4.std_point,\n",
                                "            \"Y~v_DML_stderr_point\": amte_inference4.stderr_point,\n",
                                "        })\n",
                                "    \n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "    \n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                                "\n",
                                "    return df\n",
                                "\n",
                                "def copula_entropy(dataset):\n",
                                "    \"\"\"\n",
                                "    Given a dataset, we compute the Copula entropy-based features for each\n",
                                "    variable, which are the Copula entropy between that variable with X and Y,\n",
                                "    as well as summary statistics of all pairs of Copula entropies.\n",
                                "    \"\"\"\n",
                                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                                "\n",
                                "    df = []\n",
                                "    for variable in variables:\n",
                                "        # Compute copula entropy between v and X\n",
                                "        ce_v_X = copent(dataset[[variable, \"X\"]].values)\n",
                                "        \n",
                                "        # Compute copula entropy between v and Y\n",
                                "        ce_v_Y = copent(dataset[[variable, \"Y\"]].values)\n",
                                "        \n",
                                "        # # Compute transfer entropy from v to X and X to v\n",
                                "        # te_v_X = transent(dataset[variable].values, dataset[\"X\"].values)\n",
                                "        # te_X_v = transent(dataset[\"X\"].values, dataset[variable].values)\n",
                                "        \n",
                                "        # # Compute transfer entropy from v to Y and Y to v\n",
                                "        # te_v_Y = transent(dataset[variable].values, dataset[\"Y\"].values)\n",
                                "        # te_Y_v = transent(dataset[\"Y\"].values, dataset[variable].values)\n",
                                "        \n",
                                "        \n",
                                "        df.append({\n",
                                "            \"variable\": variable,\n",
                                "            \"copula_entropy(v,X)\": ce_v_X,\n",
                                "            \"copula_entropy(v,Y)\": ce_v_Y,\n",
                                "            # \"transfer_entropy(v->X)\": te_v_X,\n",
                                "            # \"transfer_entropy(X->v)\": te_X_v,\n",
                                "            # \"transfer_entropy(v->Y)\": te_v_Y,\n",
                                "            # \"transfer_entropy(Y->v)\": te_Y_v,\n",
                                "        })\n",
                                "\n",
                                "    df = pd.DataFrame(df)\n",
                                "    df[\"dataset\"] = dataset.name\n",
                                "\n",
                                "    # Compute copula entropy between X and Y\n",
                                "    df[\"copula_entropy(X,Y)\"] = copent(dataset[[\"X\", \"Y\"]].values)\n",
                                "\n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                                "\n",
                                "    return df\n"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 10,
                        "metadata": {
                                "ExecuteTime": {
                                        "end_time": "2024-09-18T09:31:25.402707Z",
                                        "start_time": "2024-09-18T09:31:25.388081Z"
                                },
                                "metadata": {}
                        },
                        "outputs": [],
                        "source": [
                                "def label(adjacency_matrix):\n",
                                "    \"\"\"\n",
                                "    Given a graph as adjacency_matrix, create the class labels of each variable.\n",
                                "    \"\"\"\n",
                                "\n",
                                "    adjacency_graph, adjacency_label = create_graph_label()\n",
                                "    labels = get_labels(adjacency_matrix, adjacency_label)\n",
                                "    variables = adjacency_matrix.columns.drop([\"X\", \"Y\"])\n",
                                "\n",
                                "    df = pd.DataFrame({\n",
                                "        \"variable\": variables,\n",
                                "        \"label\": [labels[variable] for variable in variables],\n",
                                "    })\n",
                                "    df[\"dataset\"] = adjacency_matrix.name\n",
                                "\n",
                                "    # Reorder columns:\n",
                                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                                "\n",
                                "    return df"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 11,
                        "metadata": {
                                "ExecuteTime": {
                                        "end_time": "2024-09-18T09:31:26.636102Z",
                                        "start_time": "2024-09-18T09:31:26.629666Z"
                                },
                                "metadata": {}
                        },
                        "outputs": [],
                        "source": [
                                "def create_some_columns(names_datasets, function):\n",
                                "    \"\"\"\n",
                                "    Apply an embedding function to a list of datasets.\n",
                                "    \"\"\"\n",
                                "\n",
                                "    df = []\n",
                                "    for name, dataset in tqdm(names_datasets.items()):\n",
                                "        dataset = names_datasets[name]\n",
                                "        dataset.name = name\n",
                                "    \n",
                                "        try:\n",
                                "            df_dataset = function(dataset)\n",
                                "        except ValueError as e:\n",
                                "            print(name, e)\n",
                                "            raise NotImplementedError\n",
                                "\n",
                                "        df_dataset[\"dataset\"] = name\n",
                                "        df.append(df_dataset)\n",
                                "\n",
                                "    df = pd.concat(df, axis=\"index\").reset_index(drop=True)\n",
                                "    return df"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 12,
                        "metadata": {
                                "ExecuteTime": {
                                        "end_time": "2024-09-18T09:31:27.391364Z",
                                        "start_time": "2024-09-18T09:31:27.380030Z"
                                },
                                "metadata": {}
                        },
                        "outputs": [],
                        "source": [
                                "def create_some_columns_parallel(names_datasets, function, n_jobs=-1):\n",
                                "    \"\"\"\n",
                                "    Apply an embedding function to a list of datasets.\n",
                                "\n",
                                "    Parallel version.\n",
                                "    \"\"\"\n",
                                "\n",
                                "    def f(name, dataset, function):\n",
                                "        dataset.name = name\n",
                                "        df_dataset = function(dataset)\n",
                                "        df_dataset[\"dataset\"] = name\n",
                                "        return df_dataset\n",
                                "\n",
                                "    df = joblib.Parallel(n_jobs=n_jobs)(\n",
                                "        joblib.delayed(f)(name, dataset, function)\n",
                                "        for name, dataset in tqdm(names_datasets.items())\n",
                                "    )\n",
                                "\n",
                                "    df = pd.concat(df, axis=\"index\").reset_index(drop=True)\n",
                                "    return df"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 13,
                        "metadata": {
                                "ExecuteTime": {
                                        "end_time": "2024-09-18T09:31:28.411964Z",
                                        "start_time": "2024-09-18T09:31:28.402880Z"
                                },
                                "metadata": {}
                        },
                        "outputs": [],
                        "source": [
                                "def create_all_columns(functions_names_datasets, n_jobs=-1, create_dimension_feature = False):\n",
                                "    \"\"\"\n",
                                "    given a dictionary of {function1:names, function2:names,...} apply\n",
                                "    the desired functions to the list of datasets and merge all of them\n",
                                "    in a single X_y_group dataframe.\n",
                                "    \"\"\"\n",
                                "\n",
                                "    columns = []\n",
                                "    if create_dimension_feature:\n",
                                "        dimension_feature = create_some_columns(functions_names_datasets[list(functions_names_datasets.keys())[0]], add_dimension_feature)\n",
                                "        columns.append(dimension_feature)\n",
                                "    \n",
                                "    for function, names_datasets in functions_names_datasets.items():\n",
                                "        print(f\"set: {function.__name__}\")\n",
                                "\n",
                                "        if n_jobs != 1:\n",
                                "            feature_set = create_some_columns_parallel(names_datasets, function, n_jobs=n_jobs)\n",
                                "        else:\n",
                                "            feature_set = create_some_columns(names_datasets, function)\n",
                                "\n",
                                "        columns.append(feature_set)\n",
                                "\n",
                                "    # Merge all feature sets into a single dataframe:\n",
                                "    columns = functools.reduce(\n",
                                "        lambda left, right: pd.merge(left, right, on=[\"dataset\", \"variable\"]),\n",
                                "        columns,\n",
                                "    )\n",
                                "\n",
                                "    return columns"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 18,
                        "metadata": {
                                "ExecuteTime": {
                                        "end_time": "2024-09-18T09:44:41.738202Z",
                                        "start_time": "2024-09-18T09:44:40.143933Z"
                                },
                                "metadata": {}
                        },
                        "outputs": [
                                {
                                        "name": "stdout",
                                        "output_type": "stream",
                                        "text": [
                                                "(142910, 77)\n",
                                                "Index(['dataset', 'variable', 'dimension', 'corr(v,X)', 'corr(v,Y)',\n",
                                                "       'max(corr(v, others))', 'min(corr(v, others))', 'mean(corr(v, others))',\n",
                                                "       'std(corr(v, others))', 'corr(X,Y)', 'ttest(v,X)',\n",
                                                "       'pvalue(ttest(v,X))<=0.05', 'ttest(v,Y)', 'pvalue(ttest(v,Y))<=0.05',\n",
                                                "       'ttest(X,Y)', 'pvalue(ttest(X,Y))<=0.05', 'MI(v,X)', 'MI(v,Y)',\n",
                                                "       'max(MI(v, others))', 'min(MI(v, others))', 'mean(MI(v, others))',\n",
                                                "       'std(MI(v, others))', 'MI(X,Y)', 'label', 'y', 'spearman_corr(v,X)',\n",
                                                "       'spearman_corr(v,Y)', 'spearman_corr(X,Y)', 'kendall_corr(v,X)',\n",
                                                "       'kendall_corr(v,Y)', 'kendall_corr(X,Y)', 'dcor(v,X)', 'dcor(v,Y)',\n",
                                                "       'dcor(X,Y)', 'MI(v,X)^2', 'MI(v,Y)^2', 'MI(X,Y)^2',\n",
                                                "       'max(MI(v, others))^2', 'min(MI(v, others))^2', 'conditional_MI(v,X|Y)',\n",
                                                "       'conditional_MI(v,Y|X)', 'conditional_MI(X,Y|v)', 'square_dimension',\n",
                                                "       'max(spearman_corr(v, others))', 'min(spearman_corr(v, others))',\n",
                                                "       'mean(spearman_corr(v, others))', 'std(spearman_corr(v, others))',\n",
                                                "       'max(kendall_corr(v, others))', 'min(kendall_corr(v, others))',\n",
                                                "       'mean(kendall_corr(v, others))', 'std(kendall_corr(v, others))',\n",
                                                "       'partial_corr(v,X|Y)', 'partial_corr(v,Y|X)', 'partial_corr(X,Y|v)',\n",
                                                "       'v~Y_coefficient', 'v_squared~Y_coefficient', 'v~X_coefficient',\n",
                                                "       'v_squared~X_coefficient', 'v_cos~X_coefficient', 'v_sin~X_coefficient',\n",
                                                "       'X~Y_coefficient', 'v~Y_ridge_coefficient', 'v~X_ridge_coefficient',\n",
                                                "       'X~Y_ridge_coefficient', 'ExactSearch(v,X)', 'ExactSearch(X,v)',\n",
                                                "       'ExactSearch(v,Y)', 'ExactSearch(Y,v)', 'ExactSearch(X,Y)', 'PC(v,X)',\n",
                                                "       'PC(X,v)', 'PC(v,Y)', 'PC(Y,v)', 'PC(X,Y)', 'FCI(v,X)', 'FCI(X,v)',\n",
                                                "       'FCI(v,Y)', 'FCI(Y,v)', 'FCI(X,Y)', 'PPS(v,X)', 'PPS(X,v)', 'PPS(v,Y)',\n",
                                                "       'PPS(Y,v)', 'PPS(X,Y)', 'max(PPS(v,others))', 'mean(PPS(v,others))',\n",
                                                "       'copula_entropy(v,X)', 'copula_entropy(v,Y)', 'copula_entropy(X,Y)'],\n",
                                                "      dtype='object')\n"
                                        ]
                                }
                        ],
                        "source": [
                                "X_y_group_train = pd.read_csv('mid_data/X_y_group_train_updated_v10.2_PPS+copula.csv')\n",
                                "print(X_y_group_train.shape)\n",
                                "print(X_y_group_train.columns)"
                        ]
                },
                {
                        "cell_type": "markdown",
                        "metadata": {},
                        "source": [
                                "55.7\n"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 15,
                        "metadata": {},
                        "outputs": [
                                {
                                        "name": "stdout",
                                        "output_type": "stream",
                                        "text": [
                                                "set: distance_correlation_different_exponent\n"
                                        ]
                                },
                                {
                                        "name": "stderr",
                                        "output_type": "stream",
                                        "text": [
                                                "100%|██████████| 23500/23500 [59:04<00:00,  6.63it/s] \n"
                                        ]
                                },
                                {
                                        "name": "stdout",
                                        "output_type": "stream",
                                        "text": [
                                                "X_y_group_train.shape (142910, 91)\n",
                                                "去重后X_y_group_train.shape (142910, 89)\n"
                                        ]
                                }
                        ],
                        "source": [
                                "names_datasets_train = X_train\n",
                                "names_graphs_train = y_train\n",
                                "X_y_group_train_additional = create_all_columns(\n",
                                "    {\n",
                                "        # conditional_independence_tests: names_datasets_train,\n",
                                "        # partial_distance_covariance_dataset: names_datasets_train,\n",
                                "        # PC_feature: names_datasets_train,\n",
                                "        distance_correlation_different_exponent: names_datasets_train,\n",
                                "    },\n",
                                "    n_jobs=-1,\n",
                                ")\n",
                                "X_y_group_train = pd.concat([X_y_group_train, X_y_group_train_additional], axis=1)\n",
                                "print('X_y_group_train.shape', X_y_group_train.shape)\n",
                                "# 去掉重复的列\n",
                                "X_y_group_train = X_y_group_train.loc[:,~X_y_group_train.columns.duplicated()]\n",
                                "print('去重后X_y_group_train.shape', X_y_group_train.shape)"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 16,
                        "metadata": {},
                        "outputs": [],
                        "source": [
                                "X_y_group_train.to_csv('./mid_data/X_y_group_train_updated_v10.4_distance.csv', index=False)"
                        ]
                },
                {
                        "cell_type": "markdown",
                        "metadata": {},
                        "source": [
                                "set: double_machine_learning\n",
                                "  1%|          | 288/23500 [02:17<2:48:55,  2.29it/s]"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 19,
                        "metadata": {
                                "ExecuteTime": {
                                        "end_time": "2024-09-18T09:34:49.212104Z",
                                        "start_time": "2024-09-18T09:34:48.478623Z"
                                },
                                "metadata": {}
                        },
                        "outputs": [
                                {
                                        "name": "stdout",
                                        "output_type": "stream",
                                        "text": [
                                                "Adding numeric labels y\n"
                                        ]
                                },
                                {
                                        "data": {
                                                "text/html": [
                                                        "<div>\n",
                                                        "<style scoped>\n",
                                                        "    .dataframe tbody tr th:only-of-type {\n",
                                                        "        vertical-align: middle;\n",
                                                        "    }\n",
                                                        "\n",
                                                        "    .dataframe tbody tr th {\n",
                                                        "        vertical-align: top;\n",
                                                        "    }\n",
                                                        "\n",
                                                        "    .dataframe thead th {\n",
                                                        "        text-align: right;\n",
                                                        "    }\n",
                                                        "</style>\n",
                                                        "<table border=\"1\" class=\"dataframe\">\n",
                                                        "  <thead>\n",
                                                        "    <tr style=\"text-align: right;\">\n",
                                                        "      <th></th>\n",
                                                        "      <th>dataset</th>\n",
                                                        "      <th>variable</th>\n",
                                                        "      <th>dimension</th>\n",
                                                        "      <th>corr(v,X)</th>\n",
                                                        "      <th>corr(v,Y)</th>\n",
                                                        "      <th>max(corr(v, others))</th>\n",
                                                        "      <th>min(corr(v, others))</th>\n",
                                                        "      <th>mean(corr(v, others))</th>\n",
                                                        "      <th>std(corr(v, others))</th>\n",
                                                        "      <th>corr(X,Y)</th>\n",
                                                        "      <th>...</th>\n",
                                                        "      <th>PPS(v,Y)</th>\n",
                                                        "      <th>PPS(Y,v)</th>\n",
                                                        "      <th>PPS(X,Y)</th>\n",
                                                        "      <th>max(PPS(v,others))</th>\n",
                                                        "      <th>mean(PPS(v,others))</th>\n",
                                                        "      <th>copula_entropy(v,X)</th>\n",
                                                        "      <th>copula_entropy(v,Y)</th>\n",
                                                        "      <th>copula_entropy(X,Y)</th>\n",
                                                        "      <th>label</th>\n",
                                                        "      <th>y</th>\n",
                                                        "    </tr>\n",
                                                        "  </thead>\n",
                                                        "  <tbody>\n",
                                                        "    <tr>\n",
                                                        "      <th>0</th>\n",
                                                        "      <td>0</td>\n",
                                                        "      <td>0</td>\n",
                                                        "      <td>8</td>\n",
                                                        "      <td>0.169735</td>\n",
                                                        "      <td>-0.113595</td>\n",
                                                        "      <td>0.791467</td>\n",
                                                        "      <td>0.027355</td>\n",
                                                        "      <td>0.282376</td>\n",
                                                        "      <td>0.298969</td>\n",
                                                        "      <td>-0.771058</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>0.000000</td>\n",
                                                        "      <td>0.000000</td>\n",
                                                        "      <td>0.17606</td>\n",
                                                        "      <td>1.0</td>\n",
                                                        "      <td>0.163557</td>\n",
                                                        "      <td>-0.012882</td>\n",
                                                        "      <td>-0.004225</td>\n",
                                                        "      <td>0.378629</td>\n",
                                                        "      <td>Consequence of Y</td>\n",
                                                        "      <td>5</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>1</th>\n",
                                                        "      <td>0</td>\n",
                                                        "      <td>2</td>\n",
                                                        "      <td>8</td>\n",
                                                        "      <td>-0.072334</td>\n",
                                                        "      <td>0.139419</td>\n",
                                                        "      <td>0.230139</td>\n",
                                                        "      <td>0.003233</td>\n",
                                                        "      <td>0.090511</td>\n",
                                                        "      <td>0.082201</td>\n",
                                                        "      <td>-0.771058</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>0.000000</td>\n",
                                                        "      <td>0.000000</td>\n",
                                                        "      <td>0.17606</td>\n",
                                                        "      <td>1.0</td>\n",
                                                        "      <td>0.125000</td>\n",
                                                        "      <td>-0.051096</td>\n",
                                                        "      <td>-0.068986</td>\n",
                                                        "      <td>0.378629</td>\n",
                                                        "      <td>Independent</td>\n",
                                                        "      <td>6</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>2</th>\n",
                                                        "      <td>0</td>\n",
                                                        "      <td>3</td>\n",
                                                        "      <td>8</td>\n",
                                                        "      <td>0.123115</td>\n",
                                                        "      <td>-0.238769</td>\n",
                                                        "      <td>0.781051</td>\n",
                                                        "      <td>0.012225</td>\n",
                                                        "      <td>0.257037</td>\n",
                                                        "      <td>0.288165</td>\n",
                                                        "      <td>-0.771058</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>0.000000</td>\n",
                                                        "      <td>0.000000</td>\n",
                                                        "      <td>0.17606</td>\n",
                                                        "      <td>1.0</td>\n",
                                                        "      <td>0.167538</td>\n",
                                                        "      <td>-0.033237</td>\n",
                                                        "      <td>-0.006796</td>\n",
                                                        "      <td>0.378629</td>\n",
                                                        "      <td>Cause of Y</td>\n",
                                                        "      <td>1</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>3</th>\n",
                                                        "      <td>0</td>\n",
                                                        "      <td>4</td>\n",
                                                        "      <td>8</td>\n",
                                                        "      <td>-0.001935</td>\n",
                                                        "      <td>0.013921</td>\n",
                                                        "      <td>0.147408</td>\n",
                                                        "      <td>0.001935</td>\n",
                                                        "      <td>0.052451</td>\n",
                                                        "      <td>0.053457</td>\n",
                                                        "      <td>-0.771058</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>0.000000</td>\n",
                                                        "      <td>0.000000</td>\n",
                                                        "      <td>0.17606</td>\n",
                                                        "      <td>1.0</td>\n",
                                                        "      <td>0.125000</td>\n",
                                                        "      <td>-0.070794</td>\n",
                                                        "      <td>-0.031723</td>\n",
                                                        "      <td>0.378629</td>\n",
                                                        "      <td>Cause of Y</td>\n",
                                                        "      <td>1</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>4</th>\n",
                                                        "      <td>0</td>\n",
                                                        "      <td>5</td>\n",
                                                        "      <td>8</td>\n",
                                                        "      <td>0.284323</td>\n",
                                                        "      <td>-0.466570</td>\n",
                                                        "      <td>0.791467</td>\n",
                                                        "      <td>0.064815</td>\n",
                                                        "      <td>0.426306</td>\n",
                                                        "      <td>0.250048</td>\n",
                                                        "      <td>-0.771058</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>0.000000</td>\n",
                                                        "      <td>0.000000</td>\n",
                                                        "      <td>0.17606</td>\n",
                                                        "      <td>1.0</td>\n",
                                                        "      <td>0.172948</td>\n",
                                                        "      <td>-0.002582</td>\n",
                                                        "      <td>0.098013</td>\n",
                                                        "      <td>0.378629</td>\n",
                                                        "      <td>Mediator</td>\n",
                                                        "      <td>7</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>...</th>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>142905</th>\n",
                                                        "      <td>46997</td>\n",
                                                        "      <td>6</td>\n",
                                                        "      <td>7</td>\n",
                                                        "      <td>0.014740</td>\n",
                                                        "      <td>0.697089</td>\n",
                                                        "      <td>0.748635</td>\n",
                                                        "      <td>0.013858</td>\n",
                                                        "      <td>0.376630</td>\n",
                                                        "      <td>0.352655</td>\n",
                                                        "      <td>-0.089641</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>0.141348</td>\n",
                                                        "      <td>0.016664</td>\n",
                                                        "      <td>0.00000</td>\n",
                                                        "      <td>1.0</td>\n",
                                                        "      <td>0.242118</td>\n",
                                                        "      <td>-0.077124</td>\n",
                                                        "      <td>0.353355</td>\n",
                                                        "      <td>-0.006484</td>\n",
                                                        "      <td>Cause of Y</td>\n",
                                                        "      <td>1</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>142906</th>\n",
                                                        "      <td>46997</td>\n",
                                                        "      <td>7</td>\n",
                                                        "      <td>7</td>\n",
                                                        "      <td>-0.007397</td>\n",
                                                        "      <td>-0.116481</td>\n",
                                                        "      <td>0.998843</td>\n",
                                                        "      <td>0.007397</td>\n",
                                                        "      <td>0.180741</td>\n",
                                                        "      <td>0.333308</td>\n",
                                                        "      <td>-0.089641</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>0.000000</td>\n",
                                                        "      <td>0.000000</td>\n",
                                                        "      <td>0.00000</td>\n",
                                                        "      <td>1.0</td>\n",
                                                        "      <td>0.277008</td>\n",
                                                        "      <td>-0.025084</td>\n",
                                                        "      <td>-0.009605</td>\n",
                                                        "      <td>-0.006484</td>\n",
                                                        "      <td>Cause of Y</td>\n",
                                                        "      <td>1</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>142907</th>\n",
                                                        "      <td>46997</td>\n",
                                                        "      <td>8</td>\n",
                                                        "      <td>7</td>\n",
                                                        "      <td>-0.011658</td>\n",
                                                        "      <td>0.908029</td>\n",
                                                        "      <td>0.970364</td>\n",
                                                        "      <td>0.011658</td>\n",
                                                        "      <td>0.469777</td>\n",
                                                        "      <td>0.441105</td>\n",
                                                        "      <td>-0.089641</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>0.479848</td>\n",
                                                        "      <td>0.472424</td>\n",
                                                        "      <td>0.00000</td>\n",
                                                        "      <td>1.0</td>\n",
                                                        "      <td>0.321905</td>\n",
                                                        "      <td>-0.082074</td>\n",
                                                        "      <td>0.799514</td>\n",
                                                        "      <td>-0.006484</td>\n",
                                                        "      <td>Cause of Y</td>\n",
                                                        "      <td>1</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>142908</th>\n",
                                                        "      <td>46998</td>\n",
                                                        "      <td>0</td>\n",
                                                        "      <td>2</td>\n",
                                                        "      <td>0.083546</td>\n",
                                                        "      <td>-0.019665</td>\n",
                                                        "      <td>0.083546</td>\n",
                                                        "      <td>0.016856</td>\n",
                                                        "      <td>0.040022</td>\n",
                                                        "      <td>0.037719</td>\n",
                                                        "      <td>0.036862</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>0.000000</td>\n",
                                                        "      <td>0.000000</td>\n",
                                                        "      <td>0.00000</td>\n",
                                                        "      <td>1.0</td>\n",
                                                        "      <td>0.500000</td>\n",
                                                        "      <td>-0.003214</td>\n",
                                                        "      <td>-0.064767</td>\n",
                                                        "      <td>-0.074228</td>\n",
                                                        "      <td>Consequence of X</td>\n",
                                                        "      <td>4</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>142909</th>\n",
                                                        "      <td>46998</td>\n",
                                                        "      <td>3</td>\n",
                                                        "      <td>2</td>\n",
                                                        "      <td>-0.201922</td>\n",
                                                        "      <td>0.666742</td>\n",
                                                        "      <td>0.666742</td>\n",
                                                        "      <td>0.016856</td>\n",
                                                        "      <td>0.295173</td>\n",
                                                        "      <td>0.334828</td>\n",
                                                        "      <td>0.036862</td>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>0.045920</td>\n",
                                                        "      <td>0.034884</td>\n",
                                                        "      <td>0.00000</td>\n",
                                                        "      <td>1.0</td>\n",
                                                        "      <td>0.500000</td>\n",
                                                        "      <td>0.016316</td>\n",
                                                        "      <td>0.253164</td>\n",
                                                        "      <td>-0.074228</td>\n",
                                                        "      <td>Collider</td>\n",
                                                        "      <td>2</td>\n",
                                                        "    </tr>\n",
                                                        "  </tbody>\n",
                                                        "</table>\n",
                                                        "<p>142910 rows × 83 columns</p>\n",
                                                        "</div>"
                                                ],
                                                "text/plain": [
                                                        "        dataset  variable  dimension  corr(v,X)  corr(v,Y)  \\\n",
                                                        "0             0         0          8   0.169735  -0.113595   \n",
                                                        "1             0         2          8  -0.072334   0.139419   \n",
                                                        "2             0         3          8   0.123115  -0.238769   \n",
                                                        "3             0         4          8  -0.001935   0.013921   \n",
                                                        "4             0         5          8   0.284323  -0.466570   \n",
                                                        "...         ...       ...        ...        ...        ...   \n",
                                                        "142905    46997         6          7   0.014740   0.697089   \n",
                                                        "142906    46997         7          7  -0.007397  -0.116481   \n",
                                                        "142907    46997         8          7  -0.011658   0.908029   \n",
                                                        "142908    46998         0          2   0.083546  -0.019665   \n",
                                                        "142909    46998         3          2  -0.201922   0.666742   \n",
                                                        "\n",
                                                        "        max(corr(v, others))  min(corr(v, others))  mean(corr(v, others))  \\\n",
                                                        "0                   0.791467              0.027355               0.282376   \n",
                                                        "1                   0.230139              0.003233               0.090511   \n",
                                                        "2                   0.781051              0.012225               0.257037   \n",
                                                        "3                   0.147408              0.001935               0.052451   \n",
                                                        "4                   0.791467              0.064815               0.426306   \n",
                                                        "...                      ...                   ...                    ...   \n",
                                                        "142905              0.748635              0.013858               0.376630   \n",
                                                        "142906              0.998843              0.007397               0.180741   \n",
                                                        "142907              0.970364              0.011658               0.469777   \n",
                                                        "142908              0.083546              0.016856               0.040022   \n",
                                                        "142909              0.666742              0.016856               0.295173   \n",
                                                        "\n",
                                                        "        std(corr(v, others))  corr(X,Y)  ...  PPS(v,Y)  PPS(Y,v)  PPS(X,Y)  \\\n",
                                                        "0                   0.298969  -0.771058  ...  0.000000  0.000000   0.17606   \n",
                                                        "1                   0.082201  -0.771058  ...  0.000000  0.000000   0.17606   \n",
                                                        "2                   0.288165  -0.771058  ...  0.000000  0.000000   0.17606   \n",
                                                        "3                   0.053457  -0.771058  ...  0.000000  0.000000   0.17606   \n",
                                                        "4                   0.250048  -0.771058  ...  0.000000  0.000000   0.17606   \n",
                                                        "...                      ...        ...  ...       ...       ...       ...   \n",
                                                        "142905              0.352655  -0.089641  ...  0.141348  0.016664   0.00000   \n",
                                                        "142906              0.333308  -0.089641  ...  0.000000  0.000000   0.00000   \n",
                                                        "142907              0.441105  -0.089641  ...  0.479848  0.472424   0.00000   \n",
                                                        "142908              0.037719   0.036862  ...  0.000000  0.000000   0.00000   \n",
                                                        "142909              0.334828   0.036862  ...  0.045920  0.034884   0.00000   \n",
                                                        "\n",
                                                        "        max(PPS(v,others))  mean(PPS(v,others))  copula_entropy(v,X)  \\\n",
                                                        "0                      1.0             0.163557            -0.012882   \n",
                                                        "1                      1.0             0.125000            -0.051096   \n",
                                                        "2                      1.0             0.167538            -0.033237   \n",
                                                        "3                      1.0             0.125000            -0.070794   \n",
                                                        "4                      1.0             0.172948            -0.002582   \n",
                                                        "...                    ...                  ...                  ...   \n",
                                                        "142905                 1.0             0.242118            -0.077124   \n",
                                                        "142906                 1.0             0.277008            -0.025084   \n",
                                                        "142907                 1.0             0.321905            -0.082074   \n",
                                                        "142908                 1.0             0.500000            -0.003214   \n",
                                                        "142909                 1.0             0.500000             0.016316   \n",
                                                        "\n",
                                                        "        copula_entropy(v,Y)  copula_entropy(X,Y)             label  y  \n",
                                                        "0                 -0.004225             0.378629  Consequence of Y  5  \n",
                                                        "1                 -0.068986             0.378629       Independent  6  \n",
                                                        "2                 -0.006796             0.378629        Cause of Y  1  \n",
                                                        "3                 -0.031723             0.378629        Cause of Y  1  \n",
                                                        "4                  0.098013             0.378629          Mediator  7  \n",
                                                        "...                     ...                  ...               ... ..  \n",
                                                        "142905             0.353355            -0.006484        Cause of Y  1  \n",
                                                        "142906            -0.009605            -0.006484        Cause of Y  1  \n",
                                                        "142907             0.799514            -0.006484        Cause of Y  1  \n",
                                                        "142908            -0.064767            -0.074228  Consequence of X  4  \n",
                                                        "142909             0.253164            -0.074228          Collider  2  \n",
                                                        "\n",
                                                        "[142910 rows x 83 columns]"
                                                ]
                                        },
                                        "metadata": {},
                                        "output_type": "display_data"
                                },
                                {
                                        "name": "stdout",
                                        "output_type": "stream",
                                        "text": [
                                                "Extracting X_train, y_train, and group\n"
                                        ]
                                }
                        ],
                        "source": [
                                "print(\"Adding numeric labels y\")\n",
                                "le = LabelEncoder()\n",
                                "X_y_group_train[\"y\"] = le.fit_transform(X_y_group_train[\"label\"])\n",
                                "# reordering columns:\n",
                                "X_y_group_train = X_y_group_train[[\"dataset\", \"variable\"] + X_y_group_train.columns.drop([\"dataset\", \"variable\", \"label\", \"y\"]).tolist() + [\"label\", \"y\"]]\n",
                                "\n",
                                "numeric_columns = X_y_group_train.select_dtypes(include=[np.number]).columns\n",
                                "X_y_group_train[numeric_columns] = X_y_group_train[numeric_columns].fillna(X_y_group_train[numeric_columns].mean())\n",
                                "\n",
                                "blacklist = [\"ttest(v,X)\", \"pvalue(ttest(v,X))<=0.05\", \"ttest(v,Y)\", \"pvalue(ttest(v,Y))<=0.05\", \"ttest(X,Y)\", \"pvalue(ttest(X,Y))<=0.05\", \"max(energy_dist(v, others))\", \"min(energy_dist(v, others))\",\"mean(energy_dist(v, others))\", \"std(energy_dist(v, others))\", \"25%(energy_dist(v, others))\", \"75%(energy_dist(v, others))\"]\n",
                                "columns_to_drop = [col for col in blacklist if col in X_y_group_train.columns]\n",
                                "X_y_group_train = X_y_group_train.drop(columns=columns_to_drop)\n",
                                "\n",
                                "display(X_y_group_train)\n",
                                "\n",
                                "print(\"Extracting X_train, y_train, and group\")\n",
                                "X_train = X_y_group_train.drop([\"variable\", \"dataset\", \"label\", \"y\"], axis=\"columns\")\n",
                                "y_train = X_y_group_train[\"y\"]\n",
                                "group_train = X_y_group_train[\"dataset\"]"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 20,
                        "metadata": {
                                "ExecuteTime": {
                                        "end_time": "2024-09-18T09:40:09.797137Z",
                                        "start_time": "2024-09-18T09:39:33.165697Z"
                                },
                                "metadata": {}
                        },
                        "outputs": [
                                {
                                        "data": {
                                                "text/html": [
                                                        "<style>#sk-container-id-6 {\n",
                                                        "  /* Definition of color scheme common for light and dark mode */\n",
                                                        "  --sklearn-color-text: black;\n",
                                                        "  --sklearn-color-line: gray;\n",
                                                        "  /* Definition of color scheme for unfitted estimators */\n",
                                                        "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
                                                        "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
                                                        "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
                                                        "  --sklearn-color-unfitted-level-3: chocolate;\n",
                                                        "  /* Definition of color scheme for fitted estimators */\n",
                                                        "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
                                                        "  --sklearn-color-fitted-level-1: #d4ebff;\n",
                                                        "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
                                                        "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
                                                        "\n",
                                                        "  /* Specific color for light theme */\n",
                                                        "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                                                        "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
                                                        "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                                                        "  --sklearn-color-icon: #696969;\n",
                                                        "\n",
                                                        "  @media (prefers-color-scheme: dark) {\n",
                                                        "    /* Redefinition of color scheme for dark theme */\n",
                                                        "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                                                        "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
                                                        "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                                                        "    --sklearn-color-icon: #878787;\n",
                                                        "  }\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 {\n",
                                                        "  color: var(--sklearn-color-text);\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 pre {\n",
                                                        "  padding: 0;\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 input.sk-hidden--visually {\n",
                                                        "  border: 0;\n",
                                                        "  clip: rect(1px 1px 1px 1px);\n",
                                                        "  clip: rect(1px, 1px, 1px, 1px);\n",
                                                        "  height: 1px;\n",
                                                        "  margin: -1px;\n",
                                                        "  overflow: hidden;\n",
                                                        "  padding: 0;\n",
                                                        "  position: absolute;\n",
                                                        "  width: 1px;\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-dashed-wrapped {\n",
                                                        "  border: 1px dashed var(--sklearn-color-line);\n",
                                                        "  margin: 0 0.4em 0.5em 0.4em;\n",
                                                        "  box-sizing: border-box;\n",
                                                        "  padding-bottom: 0.4em;\n",
                                                        "  background-color: var(--sklearn-color-background);\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-container {\n",
                                                        "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
                                                        "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
                                                        "     so we also need the `!important` here to be able to override the\n",
                                                        "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
                                                        "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
                                                        "  display: inline-block !important;\n",
                                                        "  position: relative;\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-text-repr-fallback {\n",
                                                        "  display: none;\n",
                                                        "}\n",
                                                        "\n",
                                                        "div.sk-parallel-item,\n",
                                                        "div.sk-serial,\n",
                                                        "div.sk-item {\n",
                                                        "  /* draw centered vertical line to link estimators */\n",
                                                        "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
                                                        "  background-size: 2px 100%;\n",
                                                        "  background-repeat: no-repeat;\n",
                                                        "  background-position: center center;\n",
                                                        "}\n",
                                                        "\n",
                                                        "/* Parallel-specific style estimator block */\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-parallel-item::after {\n",
                                                        "  content: \"\";\n",
                                                        "  width: 100%;\n",
                                                        "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
                                                        "  flex-grow: 1;\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-parallel {\n",
                                                        "  display: flex;\n",
                                                        "  align-items: stretch;\n",
                                                        "  justify-content: center;\n",
                                                        "  background-color: var(--sklearn-color-background);\n",
                                                        "  position: relative;\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-parallel-item {\n",
                                                        "  display: flex;\n",
                                                        "  flex-direction: column;\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
                                                        "  align-self: flex-end;\n",
                                                        "  width: 50%;\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
                                                        "  align-self: flex-start;\n",
                                                        "  width: 50%;\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
                                                        "  width: 0;\n",
                                                        "}\n",
                                                        "\n",
                                                        "/* Serial-specific style estimator block */\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-serial {\n",
                                                        "  display: flex;\n",
                                                        "  flex-direction: column;\n",
                                                        "  align-items: center;\n",
                                                        "  background-color: var(--sklearn-color-background);\n",
                                                        "  padding-right: 1em;\n",
                                                        "  padding-left: 1em;\n",
                                                        "}\n",
                                                        "\n",
                                                        "\n",
                                                        "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
                                                        "clickable and can be expanded/collapsed.\n",
                                                        "- Pipeline and ColumnTransformer use this feature and define the default style\n",
                                                        "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
                                                        "*/\n",
                                                        "\n",
                                                        "/* Pipeline and ColumnTransformer style (default) */\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-toggleable {\n",
                                                        "  /* Default theme specific background. It is overwritten whether we have a\n",
                                                        "  specific estimator or a Pipeline/ColumnTransformer */\n",
                                                        "  background-color: var(--sklearn-color-background);\n",
                                                        "}\n",
                                                        "\n",
                                                        "/* Toggleable label */\n",
                                                        "#sk-container-id-6 label.sk-toggleable__label {\n",
                                                        "  cursor: pointer;\n",
                                                        "  display: block;\n",
                                                        "  width: 100%;\n",
                                                        "  margin-bottom: 0;\n",
                                                        "  padding: 0.5em;\n",
                                                        "  box-sizing: border-box;\n",
                                                        "  text-align: center;\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
                                                        "  /* Arrow on the left of the label */\n",
                                                        "  content: \"▸\";\n",
                                                        "  float: left;\n",
                                                        "  margin-right: 0.25em;\n",
                                                        "  color: var(--sklearn-color-icon);\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
                                                        "  color: var(--sklearn-color-text);\n",
                                                        "}\n",
                                                        "\n",
                                                        "/* Toggleable content - dropdown */\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-toggleable__content {\n",
                                                        "  max-height: 0;\n",
                                                        "  max-width: 0;\n",
                                                        "  overflow: hidden;\n",
                                                        "  text-align: left;\n",
                                                        "  /* unfitted */\n",
                                                        "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
                                                        "  /* fitted */\n",
                                                        "  background-color: var(--sklearn-color-fitted-level-0);\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-toggleable__content pre {\n",
                                                        "  margin: 0.2em;\n",
                                                        "  border-radius: 0.25em;\n",
                                                        "  color: var(--sklearn-color-text);\n",
                                                        "  /* unfitted */\n",
                                                        "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
                                                        "  /* unfitted */\n",
                                                        "  background-color: var(--sklearn-color-fitted-level-0);\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
                                                        "  /* Expand drop-down */\n",
                                                        "  max-height: 200px;\n",
                                                        "  max-width: 100%;\n",
                                                        "  overflow: auto;\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
                                                        "  content: \"▾\";\n",
                                                        "}\n",
                                                        "\n",
                                                        "/* Pipeline/ColumnTransformer-specific style */\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                                                        "  color: var(--sklearn-color-text);\n",
                                                        "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                                                        "  background-color: var(--sklearn-color-fitted-level-2);\n",
                                                        "}\n",
                                                        "\n",
                                                        "/* Estimator-specific style */\n",
                                                        "\n",
                                                        "/* Colorize estimator box */\n",
                                                        "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                                                        "  /* unfitted */\n",
                                                        "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                                                        "  /* fitted */\n",
                                                        "  background-color: var(--sklearn-color-fitted-level-2);\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
                                                        "#sk-container-id-6 div.sk-label label {\n",
                                                        "  /* The background is the default theme color */\n",
                                                        "  color: var(--sklearn-color-text-on-default-background);\n",
                                                        "}\n",
                                                        "\n",
                                                        "/* On hover, darken the color of the background */\n",
                                                        "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
                                                        "  color: var(--sklearn-color-text);\n",
                                                        "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                                                        "}\n",
                                                        "\n",
                                                        "/* Label box, darken color on hover, fitted */\n",
                                                        "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
                                                        "  color: var(--sklearn-color-text);\n",
                                                        "  background-color: var(--sklearn-color-fitted-level-2);\n",
                                                        "}\n",
                                                        "\n",
                                                        "/* Estimator label */\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-label label {\n",
                                                        "  font-family: monospace;\n",
                                                        "  font-weight: bold;\n",
                                                        "  display: inline-block;\n",
                                                        "  line-height: 1.2em;\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-label-container {\n",
                                                        "  text-align: center;\n",
                                                        "}\n",
                                                        "\n",
                                                        "/* Estimator-specific */\n",
                                                        "#sk-container-id-6 div.sk-estimator {\n",
                                                        "  font-family: monospace;\n",
                                                        "  border: 1px dotted var(--sklearn-color-border-box);\n",
                                                        "  border-radius: 0.25em;\n",
                                                        "  box-sizing: border-box;\n",
                                                        "  margin-bottom: 0.5em;\n",
                                                        "  /* unfitted */\n",
                                                        "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-estimator.fitted {\n",
                                                        "  /* fitted */\n",
                                                        "  background-color: var(--sklearn-color-fitted-level-0);\n",
                                                        "}\n",
                                                        "\n",
                                                        "/* on hover */\n",
                                                        "#sk-container-id-6 div.sk-estimator:hover {\n",
                                                        "  /* unfitted */\n",
                                                        "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
                                                        "  /* fitted */\n",
                                                        "  background-color: var(--sklearn-color-fitted-level-2);\n",
                                                        "}\n",
                                                        "\n",
                                                        "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
                                                        "\n",
                                                        "/* Common style for \"i\" and \"?\" */\n",
                                                        "\n",
                                                        ".sk-estimator-doc-link,\n",
                                                        "a:link.sk-estimator-doc-link,\n",
                                                        "a:visited.sk-estimator-doc-link {\n",
                                                        "  float: right;\n",
                                                        "  font-size: smaller;\n",
                                                        "  line-height: 1em;\n",
                                                        "  font-family: monospace;\n",
                                                        "  background-color: var(--sklearn-color-background);\n",
                                                        "  border-radius: 1em;\n",
                                                        "  height: 1em;\n",
                                                        "  width: 1em;\n",
                                                        "  text-decoration: none !important;\n",
                                                        "  margin-left: 1ex;\n",
                                                        "  /* unfitted */\n",
                                                        "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                                                        "  color: var(--sklearn-color-unfitted-level-1);\n",
                                                        "}\n",
                                                        "\n",
                                                        ".sk-estimator-doc-link.fitted,\n",
                                                        "a:link.sk-estimator-doc-link.fitted,\n",
                                                        "a:visited.sk-estimator-doc-link.fitted {\n",
                                                        "  /* fitted */\n",
                                                        "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                                                        "  color: var(--sklearn-color-fitted-level-1);\n",
                                                        "}\n",
                                                        "\n",
                                                        "/* On hover */\n",
                                                        "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
                                                        ".sk-estimator-doc-link:hover,\n",
                                                        "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
                                                        ".sk-estimator-doc-link:hover {\n",
                                                        "  /* unfitted */\n",
                                                        "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                                                        "  color: var(--sklearn-color-background);\n",
                                                        "  text-decoration: none;\n",
                                                        "}\n",
                                                        "\n",
                                                        "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
                                                        ".sk-estimator-doc-link.fitted:hover,\n",
                                                        "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
                                                        ".sk-estimator-doc-link.fitted:hover {\n",
                                                        "  /* fitted */\n",
                                                        "  background-color: var(--sklearn-color-fitted-level-3);\n",
                                                        "  color: var(--sklearn-color-background);\n",
                                                        "  text-decoration: none;\n",
                                                        "}\n",
                                                        "\n",
                                                        "/* Span, style for the box shown on hovering the info icon */\n",
                                                        ".sk-estimator-doc-link span {\n",
                                                        "  display: none;\n",
                                                        "  z-index: 9999;\n",
                                                        "  position: relative;\n",
                                                        "  font-weight: normal;\n",
                                                        "  right: .2ex;\n",
                                                        "  padding: .5ex;\n",
                                                        "  margin: .5ex;\n",
                                                        "  width: min-content;\n",
                                                        "  min-width: 20ex;\n",
                                                        "  max-width: 50ex;\n",
                                                        "  color: var(--sklearn-color-text);\n",
                                                        "  box-shadow: 2pt 2pt 4pt #999;\n",
                                                        "  /* unfitted */\n",
                                                        "  background: var(--sklearn-color-unfitted-level-0);\n",
                                                        "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
                                                        "}\n",
                                                        "\n",
                                                        ".sk-estimator-doc-link.fitted span {\n",
                                                        "  /* fitted */\n",
                                                        "  background: var(--sklearn-color-fitted-level-0);\n",
                                                        "  border: var(--sklearn-color-fitted-level-3);\n",
                                                        "}\n",
                                                        "\n",
                                                        ".sk-estimator-doc-link:hover span {\n",
                                                        "  display: block;\n",
                                                        "}\n",
                                                        "\n",
                                                        "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
                                                        "\n",
                                                        "#sk-container-id-6 a.estimator_doc_link {\n",
                                                        "  float: right;\n",
                                                        "  font-size: 1rem;\n",
                                                        "  line-height: 1em;\n",
                                                        "  font-family: monospace;\n",
                                                        "  background-color: var(--sklearn-color-background);\n",
                                                        "  border-radius: 1rem;\n",
                                                        "  height: 1rem;\n",
                                                        "  width: 1rem;\n",
                                                        "  text-decoration: none;\n",
                                                        "  /* unfitted */\n",
                                                        "  color: var(--sklearn-color-unfitted-level-1);\n",
                                                        "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
                                                        "  /* fitted */\n",
                                                        "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                                                        "  color: var(--sklearn-color-fitted-level-1);\n",
                                                        "}\n",
                                                        "\n",
                                                        "/* On hover */\n",
                                                        "#sk-container-id-6 a.estimator_doc_link:hover {\n",
                                                        "  /* unfitted */\n",
                                                        "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                                                        "  color: var(--sklearn-color-background);\n",
                                                        "  text-decoration: none;\n",
                                                        "}\n",
                                                        "\n",
                                                        "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
                                                        "  /* fitted */\n",
                                                        "  background-color: var(--sklearn-color-fitted-level-3);\n",
                                                        "}\n",
                                                        "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=13, n_jobs=-1,\n",
                                                        "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=13, n_jobs=-1,\n",
                                                        "                       random_state=42)</pre></div> </div></div></div></div>"
                                                ],
                                                "text/plain": [
                                                        "RandomForestClassifier(class_weight='balanced', max_depth=13, n_jobs=-1,\n",
                                                        "                       random_state=42)"
                                                ]
                                        },
                                        "metadata": {},
                                        "output_type": "display_data"
                                },
                                {
                                        "name": "stdout",
                                        "output_type": "stream",
                                        "text": [
                                                "multiclass balanced accuracy: mean=0.5525555257581795\n"
                                        ]
                                }
                        ],
                        "source": [
                                "model = RandomForestClassifier(\n",
                                "    n_estimators=100,\n",
                                "    max_depth=13,\n",
                                "    n_jobs=-1,\n",
                                "    class_weight=\"balanced\",\n",
                                "    random_state=42\n",
                                ")\n",
                                "display(model)\n",
                                "\n",
                                "cv = GroupKFold(n_splits=4)\n",
                                "results = cross_val_score(\n",
                                "    model,\n",
                                "    X_train,\n",
                                "    y_train,\n",
                                "    groups=group_train,\n",
                                "    cv=cv,\n",
                                "    verbose=True,\n",
                                "    scoring=\"balanced_accuracy\"\n",
                                ")\n",
                                "\n",
                                "print(f\"multiclass balanced accuracy: mean={results.mean()}\")"
                        ]
                },
                {
                        "cell_type": "markdown",
                        "metadata": {},
                        "source": [
                                "before:0.489\n",
                                "after: 0.488, 差别不大...\n",
                                "\n",
                                "0.488120992009518"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 19,
                        "metadata": {},
                        "outputs": [
                                {
                                        "data": {
                                                "image/png": "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",
                                                "text/plain": [
                                                        "<Figure size 1200x600 with 1 Axes>"
                                                ]
                                        },
                                        "metadata": {},
                                        "output_type": "display_data"
                                },
                                {
                                        "name": "stdout",
                                        "output_type": "stream",
                                        "text": [
                                                "Accuracies for each dimension:\n",
                                                "Dimension 1: Accuracy = 0.4977\n",
                                                "Dimension 2: Accuracy = 0.3858\n",
                                                "Dimension 3: Accuracy = 0.4414\n",
                                                "Dimension 4: Accuracy = 0.4782\n",
                                                "Dimension 5: Accuracy = 0.5203\n",
                                                "Dimension 6: Accuracy = 0.5708\n",
                                                "Dimension 7: Accuracy = 0.6620\n",
                                                "Dimension 8: Accuracy = 0.7200\n",
                                                "\n",
                                                "Overall Accuracy: 0.6523\n",
                                                "\n",
                                                "Top 20 most important features:\n",
                                                "               feature  importance\n",
                                                "61    ExactSearch(v,Y)    0.060382\n",
                                                "62    ExactSearch(Y,v)    0.049777\n",
                                                "60    ExactSearch(X,v)    0.043095\n",
                                                "69  dcor_0.5exp(v,X)^2    0.040067\n",
                                                "21           dcor(v,X)    0.038792\n",
                                                "..                 ...         ...\n",
                                                "17  spearman_corr(X,Y)    0.004567\n",
                                                "7            corr(X,Y)    0.004495\n",
                                                "20   kendall_corr(X,Y)    0.004284\n",
                                                "63    ExactSearch(X,Y)    0.001114\n",
                                                "58             PC(X,Y)    0.000831\n",
                                                "\n",
                                                "[79 rows x 2 columns]\n",
                                                "\n",
                                                "Model and feature importances have been saved.\n"
                                        ]
                                }
                        ],
                        "source": [
                                "from sklearn.model_selection import train_test_split\n",
                                "from sklearn.metrics import accuracy_score\n",
                                "import matplotlib.pyplot as plt\n",
                                "\n",
                                "\n",
                                "X = X_train\n",
                                "y = y_train\n",
                                "# Assuming X and y are your features and target variables\n",
                                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                                "\n",
                                "model = RandomForestClassifier(\n",
                                "    n_estimators=100,\n",
                                "    max_depth=13,\n",
                                "    n_jobs=-1,\n",
                                "    class_weight=\"balanced\",\n",
                                "    random_state=42\n",
                                ")\n",
                                "# Fit the model\n",
                                "model.fit(X_train, y_train)\n",
                                "\n",
                                "# Get predictions\n",
                                "y_pred = model.predict(X_test)\n",
                                "\n",
                                "\n",
                                "# Calculate accuracy for each dimension\n",
                                "dimensions = sorted(X_test['dimension'].unique())\n",
                                "accuracies = []\n",
                                "\n",
                                "for dim in dimensions:\n",
                                "    mask = X_test['dimension'] == dim\n",
                                "    y_true_dim = y_test[mask]\n",
                                "    y_pred_dim = y_pred[mask]\n",
                                "    acc = accuracy_score(y_true_dim, y_pred_dim)\n",
                                "    accuracies.append(acc)\n",
                                "\n",
                                "# Visualize the results\n",
                                "plt.figure(figsize=(12, 6))\n",
                                "plt.plot(dimensions, accuracies, marker='o')\n",
                                "plt.xlabel('Dimension')\n",
                                "plt.ylabel('Accuracy')\n",
                                "plt.title('Model Accuracy vs Dimension')\n",
                                "plt.grid(True)\n",
                                "plt.xticks(dimensions)  # Ensure all dimensions are shown on x-axis\n",
                                "plt.tight_layout()\n",
                                "plt.show()\n",
                                "\n",
                                "# Print accuracies\n",
                                "print(\"Accuracies for each dimension:\")\n",
                                "for dim, acc in zip(dimensions, accuracies):\n",
                                "    print(f\"Dimension {dim}: Accuracy = {acc:.4f}\")\n",
                                "\n",
                                "# Calculate and print overall accuracy\n",
                                "overall_accuracy = accuracy_score(y_test, y_pred)\n",
                                "print(f\"\\nOverall Accuracy: {overall_accuracy:.4f}\")\n",
                                "\n",
                                "# Get feature importances\n",
                                "importances = model.feature_importances_\n",
                                "feature_importances = pd.DataFrame({'feature': X_train.columns, 'importance': importances})\n",
                                "feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
                                "\n",
                                "# Display top 20 most important features\n",
                                "print(\"\\nTop 20 most important features:\")\n",
                                "print(feature_importances)\n",
                                "\n",
                                "\n",
                                "print(\"\\nModel and feature importances have been saved.\")"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": 20,
                        "metadata": {},
                        "outputs": [
                                {
                                        "data": {
                                                "text/html": [
                                                        "<div>\n",
                                                        "<style scoped>\n",
                                                        "    .dataframe tbody tr th:only-of-type {\n",
                                                        "        vertical-align: middle;\n",
                                                        "    }\n",
                                                        "\n",
                                                        "    .dataframe tbody tr th {\n",
                                                        "        vertical-align: top;\n",
                                                        "    }\n",
                                                        "\n",
                                                        "    .dataframe thead th {\n",
                                                        "        text-align: right;\n",
                                                        "    }\n",
                                                        "</style>\n",
                                                        "<table border=\"1\" class=\"dataframe\">\n",
                                                        "  <thead>\n",
                                                        "    <tr style=\"text-align: right;\">\n",
                                                        "      <th></th>\n",
                                                        "      <th>feature</th>\n",
                                                        "      <th>importance</th>\n",
                                                        "    </tr>\n",
                                                        "  </thead>\n",
                                                        "  <tbody>\n",
                                                        "    <tr>\n",
                                                        "      <th>61</th>\n",
                                                        "      <td>ExactSearch(v,Y)</td>\n",
                                                        "      <td>0.060382</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>62</th>\n",
                                                        "      <td>ExactSearch(Y,v)</td>\n",
                                                        "      <td>0.049777</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>60</th>\n",
                                                        "      <td>ExactSearch(X,v)</td>\n",
                                                        "      <td>0.043095</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>69</th>\n",
                                                        "      <td>dcor_0.5exp(v,X)^2</td>\n",
                                                        "      <td>0.040067</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>21</th>\n",
                                                        "      <td>dcor(v,X)</td>\n",
                                                        "      <td>0.038792</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>...</th>\n",
                                                        "      <td>...</td>\n",
                                                        "      <td>...</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>17</th>\n",
                                                        "      <td>spearman_corr(X,Y)</td>\n",
                                                        "      <td>0.004567</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>7</th>\n",
                                                        "      <td>corr(X,Y)</td>\n",
                                                        "      <td>0.004495</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>20</th>\n",
                                                        "      <td>kendall_corr(X,Y)</td>\n",
                                                        "      <td>0.004284</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>63</th>\n",
                                                        "      <td>ExactSearch(X,Y)</td>\n",
                                                        "      <td>0.001114</td>\n",
                                                        "    </tr>\n",
                                                        "    <tr>\n",
                                                        "      <th>58</th>\n",
                                                        "      <td>PC(X,Y)</td>\n",
                                                        "      <td>0.000831</td>\n",
                                                        "    </tr>\n",
                                                        "  </tbody>\n",
                                                        "</table>\n",
                                                        "<p>79 rows × 2 columns</p>\n",
                                                        "</div>"
                                                ],
                                                "text/plain": [
                                                        "               feature  importance\n",
                                                        "61    ExactSearch(v,Y)    0.060382\n",
                                                        "62    ExactSearch(Y,v)    0.049777\n",
                                                        "60    ExactSearch(X,v)    0.043095\n",
                                                        "69  dcor_0.5exp(v,X)^2    0.040067\n",
                                                        "21           dcor(v,X)    0.038792\n",
                                                        "..                 ...         ...\n",
                                                        "17  spearman_corr(X,Y)    0.004567\n",
                                                        "7            corr(X,Y)    0.004495\n",
                                                        "20   kendall_corr(X,Y)    0.004284\n",
                                                        "63    ExactSearch(X,Y)    0.001114\n",
                                                        "58             PC(X,Y)    0.000831\n",
                                                        "\n",
                                                        "[79 rows x 2 columns]"
                                                ]
                                        },
                                        "execution_count": 20,
                                        "metadata": {},
                                        "output_type": "execute_result"
                                }
                        ],
                        "source": [
                                "feature_importances"
                        ]
                },
                {
                        "cell_type": "code",
                        "execution_count": null,
                        "metadata": {},
                        "outputs": [],
                        "source": []
                }
        ],
        "metadata": {
                "kernelspec": {
                        "display_name": "casual",
                        "language": "python",
                        "name": "python3"
                },
                "language_info": {
                        "codemirror_mode": {
                                "name": "ipython",
                                "version": 3
                        },
                        "file_extension": ".py",
                        "mimetype": "text/x-python",
                        "name": "python",
                        "nbconvert_exporter": "python",
                        "pygments_lexer": "ipython3",
                        "version": "3.10.14"
                }
        },
        "nbformat": 4,
        "nbformat_minor": 2
}
