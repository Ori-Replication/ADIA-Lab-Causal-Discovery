{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2024-09-18T09:30:47.677313Z",
                    "start_time": "2024-09-18T09:30:16.279502Z"
                },
                "metadata": {}
            },
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "e:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import functools\n",
                "import os\n",
                "import typing\n",
                "import random\n",
                "import joblib\n",
                "import networkx as nx\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import dcor\n",
                "from scipy.stats import pearsonr, ttest_rel\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.feature_selection import mutual_info_regression\n",
                "from sklearn.metrics import balanced_accuracy_score, silhouette_score\n",
                "from sklearn.model_selection import GridSearchCV, GroupKFold, cross_val_score\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.linear_model import Ridge, LinearRegression\n",
                "from sklearn.cluster import DBSCAN\n",
                "from sklearn.feature_selection import mutual_info_regression\n",
                "from sklearn.metrics.pairwise import rbf_kernel\n",
                "from sklearn.utils import check_random_state\n",
                "from sklearn.preprocessing import MinMaxScaler\n",
                "from sklearn.feature_selection import mutual_info_regression\n",
                "from sklearn.preprocessing import KBinsDiscretizer\n",
                "from scipy.special import softmax\n",
                "from scipy.stats import chi2_contingency, ks_2samp\n",
                "from scipy.spatial.distance import pdist, squareform\n",
                "from tqdm.auto import tqdm\n",
                "from scipy import stats\n",
                "from scipy.stats import entropy\n",
                "import statsmodels.api as sm\n",
                "import pingouin as pg\n",
                "from scipy.spatial.distance import pdist, squareform"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2024-09-20T02:42:13.047359Z",
                    "start_time": "2024-09-20T02:42:12.325055Z"
                },
                "metadata": {}
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "loaded inline runner with module: <module '__main__'>\n"
                    ]
                }
            ],
            "source": [
                "import crunch\n",
                "crunch = crunch.load_notebook()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2024-09-18T09:30:54.182971Z",
                    "start_time": "2024-09-18T09:30:54.145678Z"
                }
            },
            "outputs": [],
            "source": [
                "def graph_nodes_representation(graph, nodelist):\n",
                "    \"\"\"\n",
                "    Create an alternative representation of a graph which is hashable\n",
                "    and equivalent graphs have the same hash.\n",
                "\n",
                "    Python cannot PROPERLY use nx.Graph/DiGraph as key for\n",
                "    dictionaries, because two equivalent graphs with just different\n",
                "    order of the nodes would result in different keys. This is\n",
                "    undesirable here.\n",
                "\n",
                "    So here we transform the graph into an equivalent form that is\n",
                "    based on a specific nodelist and that is hashable. In this way,\n",
                "    two equivalent graphs, once transformed, will result in identical\n",
                "    keys.\n",
                "\n",
                "    So we use the following trick: extract the adjacency matrix\n",
                "    (with nodes in a fixed order) and then make a hashable thing out\n",
                "    of it, through tuple(array.flatten()):\n",
                "    \"\"\"\n",
                "\n",
                "    # This get the adjacency matrix with nodes in a given order, as\n",
                "    # numpy array (which is not hashable):\n",
                "    adjacency_matrix = nx.adjacency_matrix(graph, nodelist=nodelist).todense()\n",
                "\n",
                "    # This transforms the numpy array into a hashable object:\n",
                "    hashable = tuple(adjacency_matrix.flatten())\n",
                "\n",
                "    return hashable\n",
                "\n",
                "def create_graph_label():\n",
                "    \"\"\"\n",
                "    Create a dictionary from graphs to labels, in two formats.\n",
                "    \"\"\"\n",
                "    graph_label = {\n",
                "        nx.DiGraph([(\"X\", \"Y\"), (\"v\", \"X\"), (\"v\", \"Y\")]): \"Confounder\",\n",
                "        nx.DiGraph([(\"X\", \"Y\"), (\"X\", \"v\"), (\"Y\", \"v\")]): \"Collider\",\n",
                "        nx.DiGraph([(\"X\", \"Y\"), (\"X\", \"v\"), (\"v\", \"Y\")]): \"Mediator\",\n",
                "        nx.DiGraph([(\"X\", \"Y\"), (\"v\", \"X\")]):             \"Cause of X\",\n",
                "        nx.DiGraph([(\"X\", \"Y\"), (\"v\", \"Y\")]):             \"Cause of Y\",\n",
                "        nx.DiGraph([(\"X\", \"Y\"), (\"X\", \"v\")]):             \"Consequence of X\",\n",
                "        nx.DiGraph([(\"X\", \"Y\"), (\"Y\", \"v\")]):             \"Consequence of Y\",\n",
                "        nx.DiGraph({\"X\": [\"Y\"], \"v\": []}):                \"Independent\",\n",
                "    }\n",
                "\n",
                "    nodelist = [\"v\", \"X\", \"Y\"]\n",
                "\n",
                "    # This is an equivalent alternative to graph_label but in a form\n",
                "    # for which two equivalent graphs have the same key:\n",
                "    adjacency_label = {\n",
                "        graph_nodes_representation(graph, nodelist): label\n",
                "        for graph, label in graph_label.items()\n",
                "    }\n",
                "\n",
                "    return graph_label, adjacency_label\n",
                "\n",
                "def get_labels(adjacency_matrix, adjacency_label):\n",
                "    \"\"\"\n",
                "    Transform an adjacency_matrix (as pd.DataFrame) into a dictionary of variable:label\n",
                "    \"\"\"\n",
                "\n",
                "    result = {}\n",
                "    for variable in adjacency_matrix.columns.drop([\"X\", \"Y\"]):\n",
                "        submatrix = adjacency_matrix.loc[[variable, \"X\", \"Y\"], [variable, \"X\", \"Y\"]]  # this is not hashable\n",
                "        key = tuple(submatrix.values.flatten())  # this is hashable and a compatible with adjacency_label\n",
                "    \n",
                "        result[variable] = adjacency_label[key]\n",
                "\n",
                "    return result\n",
                "\n",
                "graph_label, adjacency_label = create_graph_label()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "def apply_mapping(df, mapping):\n",
                "    df_new = df.copy()\n",
                "    # 创建临时映射以避免冲突\n",
                "    temp_mapping = {k: f'_temp_{k}' for k in mapping.keys()}\n",
                "    df_new.rename(columns=temp_mapping, inplace=True)\n",
                "    if df_new.shape[0] == df_new.shape[1]:  # 如果是方阵，如标签矩阵\n",
                "        df_new.rename(index=temp_mapping, inplace=True)\n",
                "    # 应用最终映射\n",
                "    final_mapping = {f'_temp_{k}': v for k, v in mapping.items()}\n",
                "    df_new.rename(columns=final_mapping, inplace=True)\n",
                "    if df_new.shape[0] == df_new.shape[1]:\n",
                "        df_new.rename(index=final_mapping, inplace=True)\n",
                "    return df_new\n",
                "\n",
                "def check_duplicate_columns(df):\n",
                "    \"\"\"检查是否存在重复的列名\"\"\"\n",
                "    duplicate_columns = df.columns[df.columns.duplicated()]\n",
                "    if len(duplicate_columns) > 0:\n",
                "        return True\n",
                "    return False\n",
                "\n",
                "def augment_data(X_train, y_train):\n",
                "    new_X_train = X_train.copy()\n",
                "    new_y_train = y_train.copy()\n",
                "    for sample_id in X_train.keys():\n",
                "        X = X_train[sample_id]\n",
                "        y = y_train[sample_id]\n",
                "        variables = list(X.columns)\n",
                "        dim = len(variables)\n",
                "        # 提取因果关系对\n",
                "        edges = []\n",
                "        for u in y.index:\n",
                "            for v in y.columns:\n",
                "                if y.loc[u, v] == 1:\n",
                "                    edges.append((u, v))\n",
                "        # 排除涉及 X 和 Y 的边\n",
                "        edges_no_XY = [(u, v) for (u, v) in edges if u not in ['X', 'Y'] and v not in ['X', 'Y']]\n",
                "        if dim >= 4:\n",
                "            edges_to_use = edges_no_XY\n",
                "            if not edges_to_use:\n",
                "                # print(f\"Sample {sample_id}: No suitable edges found, skipping augmentation.\")\n",
                "                continue  # 没有合适的边，跳过\n",
                "            attempts = 0\n",
                "            success = False\n",
                "            while attempts < 3 and not success:\n",
                "                u, v = random.choice(edges_to_use)\n",
                "                mapping = {'X': u, 'Y': v, u: 'X', v: 'Y'}\n",
                "                # 应用映射到特征矩阵和标签矩阵\n",
                "                X_new = apply_mapping(X, mapping)\n",
                "                y_new = apply_mapping(y, mapping)\n",
                "                # 检查特征矩阵是否有重复列\n",
                "                if check_duplicate_columns(X_new):\n",
                "                    attempts += 1\n",
                "                    print(f\"Sample {sample_id}: Attempt {attempts} - Duplicate columns detected, retrying.\")\n",
                "                    continue  # 重试\n",
                "                else:\n",
                "                    # 没有重复列，存储新的数据\n",
                "                    new_sample_id = '0' + sample_id\n",
                "                    new_X_train[new_sample_id] = X_new\n",
                "                    new_y_train[new_sample_id] = y_new\n",
                "                    success = True\n",
                "            if not success:\n",
                "                # print(f\"Sample {sample_id}: Failed to augment after 3 attempts, skipping.\")\n",
                "                continue\n",
                "        else:\n",
                "            # 对于维度较低的数据，允许涉及 X 和 Y 的边\n",
                "            edges_to_use = edges\n",
                "            if not edges_to_use:\n",
                "                # print(f\"Sample {sample_id}: No edges found, skipping augmentation.\")\n",
                "                continue  # 没有边，跳过\n",
                "            u, v = random.choice(edges_to_use)\n",
                "            mapping = {'X': u, 'Y': v, u: 'X', v: 'Y'}\n",
                "            # 应用映射到特征矩阵和标签矩阵\n",
                "            X_new = apply_mapping(X, mapping)\n",
                "            y_new = apply_mapping(y, mapping)\n",
                "            # 检查特征矩阵是否有重复列\n",
                "            if check_duplicate_columns(X_new):\n",
                "                # print(f\"Sample {sample_id}: Duplicate columns detected, skipping augmentation.\")\n",
                "                continue  # 跳过增强\n",
                "            else:\n",
                "                # 没有重复列，存储新的数据\n",
                "                new_sample_id = '0' + sample_id\n",
                "                new_X_train[new_sample_id] = X_new\n",
                "                new_y_train[new_sample_id] = y_new\n",
                "    return new_X_train, new_y_train"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2024-09-20T02:43:04.532840Z",
                    "start_time": "2024-09-20T02:42:51.402011Z"
                },
                "metadata": {}
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "download data\\X_train.pickle from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/48/X_train.pickle (1523944532 bytes)\n",
                        "already exists: file length match\n",
                        "download data\\y_train.pickle from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/48/y_train.pickle (7017735 bytes)\n",
                        "already exists: file length match\n",
                        "download data\\X_test.pickle from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/48/X_test_reduced.pickle (122341879 bytes)\n",
                        "already exists: file length match\n",
                        "download data\\y_test.pickle from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/48/y_test_reduced.pickle (562930 bytes)\n",
                        "already exists: file length match\n",
                        "download data\\example_prediction.parquet from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/48/example_prediction_reduced.parquet (668981 bytes)\n",
                        "already exists: file length match\n"
                    ]
                }
            ],
            "source": [
                "X_train, y_train, X_test = crunch.load_data()\n",
                "X_train, y_train = augment_data(X_train, y_train)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2024-09-18T09:31:23.461861Z",
                    "start_time": "2024-09-18T09:31:23.368017Z"
                },
                "metadata": {}
            },
            "outputs": [],
            "source": [
                "def pearson_correlation(dataset):\n",
                "    \"\"\"\n",
                "    Given a dataset, we compute the correlation-based features for each\n",
                "    varibale, which are the correlation between that variable with X and Y,\n",
                "    as well as summary statistics (max, min, mean, std) of all pairs\n",
                "    of correlations.\n",
                "    \"\"\"\n",
                "\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                "\n",
                "    df = []\n",
                "    for variable in variables:\n",
                "        tmp = dataset.corr().drop([variable], axis=\"columns\").loc[variable].abs()\n",
                "\n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            \"corr(v,X)\": dataset[[variable, \"X\"]].corr().loc[variable, \"X\"],\n",
                "            \"corr(v,Y)\": dataset[[variable, \"Y\"]].corr().loc[variable, \"Y\"],\n",
                "            \"max(corr(v, others))\": tmp.max(),\n",
                "            \"min(corr(v, others))\": tmp.min(),\n",
                "            \"mean(corr(v, others))\": tmp.mean(),\n",
                "            \"std(corr(v, others))\": tmp.std(),\n",
                "            \"25%(corr(v, others))\": tmp.quantile(0.25), \n",
                "            \"75%(corr(v, others))\": tmp.quantile(0.75), \n",
                "        })\n",
                "\n",
                "\n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "\n",
                "    df[\"corr(X,Y)\"] = dataset[[\"X\", \"Y\"]].corr().loc[\"X\", \"Y\"]\n",
                "\n",
                "    # pearsonr is NaN when the variance is 0, so we fill with 0\n",
                "    df.fillna(0, inplace=True)\n",
                "\n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "\n",
                "    return df\n",
                "\n",
                "def ttest(dataset, pvalue_threshold=0.05):\n",
                "    \"\"\"\n",
                "    Given a dataset, this function computes the t-test between the\n",
                "    values each variable v and X, Y. The t value and the result of the\n",
                "    t-test with a given pvalue_threshold, are used to create features\n",
                "    to describe/embed v, as well as the t-test result between the\n",
                "    values of X and Y.\n",
                "    \"\"\"\n",
                "\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                "\n",
                "    df = []\n",
                "    for variable in variables:\n",
                "        ttest_vX = ttest_rel(dataset[variable], dataset[\"X\"])\n",
                "        ttest_vY = ttest_rel(dataset[variable], dataset[\"Y\"])\n",
                "\n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            \"ttest(v,X)\": ttest_vX.statistic,\n",
                "            f\"pvalue(ttest(v,X))<={pvalue_threshold}\": (ttest_vX.pvalue <= pvalue_threshold).astype(float),\n",
                "            \"ttest(v,Y)\": ttest_vY.statistic,\n",
                "            f\"pvalue(ttest(v,Y))<={pvalue_threshold}\": (ttest_vY.pvalue <= pvalue_threshold).astype(float),\n",
                "        })\n",
                "\n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "\n",
                "    ttest_XY = ttest_rel(dataset[\"X\"], dataset[\"Y\"])\n",
                "    df[\"ttest(X,Y)\"] = ttest_XY.statistic\n",
                "    df[f\"pvalue(ttest(X,Y))<={pvalue_threshold}\"] = (ttest_XY.pvalue <= pvalue_threshold).astype(float)\n",
                "\n",
                "    # some the ttest returns NaN when the variance is 0, so we fill with 0:\n",
                "    df.fillna(0, inplace=True)\n",
                "\n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "\n",
                "    return df\n",
                "\n",
                "def mutual_information(dataset):\n",
                "    \"\"\"\n",
                "    Given a dataset, we compute the mutual-information-based features\n",
                "    for each varibale, which are the correlation between that variable\n",
                "    X and Y, as well as summary statistics (max, min, mean, std) of\n",
                "    all pairs of correlations.\n",
                "    \"\"\"\n",
                "\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                "\n",
                "    df = []\n",
                "    for variable in variables:\n",
                "        tmp = mutual_info_regression(dataset.drop(columns=[variable]), dataset[variable])\n",
                "\n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            \"MI(v,X)\": mutual_info_regression(dataset[[variable]], dataset[\"X\"], discrete_features=False)[0],\n",
                "            \"MI(v,Y)\": mutual_info_regression(dataset[[variable]], dataset[\"Y\"], discrete_features=False)[0],\n",
                "            \"max(MI(v, others))\": tmp.max(),\n",
                "            \"min(MI(v, others))\": tmp.min(),\n",
                "            \"mean(MI(v, others))\": tmp.mean(),\n",
                "            \"std(MI(v, others))\": tmp.std(),\n",
                "        })\n",
                "\n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "\n",
                "    df[\"MI(X,Y)\"] = mutual_info_regression(dataset[[\"X\"]], dataset[\"Y\"], discrete_features=False)[0]\n",
                "\n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "\n",
                "    return df\n",
                "\n",
                "def add_dimension_feature(dataset):\n",
                "    \"\"\"\n",
                "    Add a dimension feature to the dataset.\n",
                "    \"\"\"\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                "    dimension = len(variables)\n",
                "    square_dimension = dimension * dimension\n",
                "    df = pd.DataFrame({\n",
                "        \"variable\": variables,\n",
                "        \"dimension\": dimension,\n",
                "        \"square_dimension\": square_dimension\n",
                "    })\n",
                "    df[\"dataset\"] = dataset.name\n",
                "    \n",
                "    return df\n",
                "\n",
                "def spearman_correlation(dataset):\n",
                "    \"\"\"\n",
                "    Given a dataset, we compute the Spearman rank correlation-based features for each\n",
                "    variable, which are the Spearman correlation between that variable with X and Y,\n",
                "    as well as summary statistics (max, min, mean, std) of all pairs of Spearman correlations.\n",
                "    \"\"\"\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                "\n",
                "    df = []\n",
                "    for variable in variables:\n",
                "        tmp = dataset.corr(method='spearman').drop([variable], axis=\"columns\").loc[variable].abs()\n",
                "\n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            \"spearman_corr(v,X)\": dataset[[variable, \"X\"]].corr(method='spearman').loc[variable, \"X\"],\n",
                "            \"spearman_corr(v,Y)\": dataset[[variable, \"Y\"]].corr(method='spearman').loc[variable, \"Y\"],\n",
                "            \"max(spearman_corr(v, others))\": tmp.max(),\n",
                "            \"min(spearman_corr(v, others))\": tmp.min(),\n",
                "            \"mean(spearman_corr(v, others))\": tmp.mean(),\n",
                "            \"std(spearman_corr(v, others))\": tmp.std(),\n",
                "        })\n",
                "\n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "\n",
                "    df[\"spearman_corr(X,Y)\"] = dataset[[\"X\", \"Y\"]].corr(method='spearman').loc[\"X\", \"Y\"]\n",
                "\n",
                "    # Spearman correlation is NaN when there are ties in rank, so we fill with 0\n",
                "    df.fillna(0, inplace=True)\n",
                "\n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "\n",
                "    return df\n",
                "\n",
                "def kendall_correlation(dataset):\n",
                "    \"\"\"\n",
                "    Given a dataset, we compute the Kendall's tau correlation-based features for each\n",
                "    variable, which are the Kendall's tau correlation between that variable with X and Y,\n",
                "    as well as summary statistics (max, min, mean, std) of all pairs of Kendall's tau correlations.\n",
                "    \"\"\"\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                "\n",
                "    df = []\n",
                "    for variable in variables:\n",
                "        tmp = dataset.corr(method='kendall').drop([variable], axis=\"columns\").loc[variable].abs()\n",
                "\n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            \"kendall_corr(v,X)\": dataset[[variable, \"X\"]].corr(method='kendall').loc[variable, \"X\"],\n",
                "            \"kendall_corr(v,Y)\": dataset[[variable, \"Y\"]].corr(method='kendall').loc[variable, \"Y\"],\n",
                "            \"max(kendall_corr(v, others))\": tmp.max(),\n",
                "            \"min(kendall_corr(v, others))\": tmp.min(),\n",
                "            \"mean(kendall_corr(v, others))\": tmp.mean(),\n",
                "            \"std(kendall_corr(v, others))\": tmp.std(),\n",
                "        })\n",
                "\n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "\n",
                "    df[\"kendall_corr(X,Y)\"] = dataset[[\"X\", \"Y\"]].corr(method='kendall').loc[\"X\", \"Y\"]\n",
                "\n",
                "    # Kendall's tau correlation can be NaN in some cases, so we fill with 0\n",
                "    df.fillna(0, inplace=True)\n",
                "\n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "\n",
                "    return df\n",
                "\n",
                "def distance_correlation(dataset):\n",
                "    \"\"\"\n",
                "    Given a dataset, we compute the distance correlation-based features for each\n",
                "    variable, which are the distance correlation between that variable with X and Y,\n",
                "    as well as the distance correlation between X and Y.\n",
                "    \"\"\"\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                "\n",
                "    df = []\n",
                "    for variable in variables:\n",
                "        # todo:尝试不同的exponent（欧氏距离的系数）\n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            \"dcor(v,X)\": dcor.distance_correlation(dataset[variable], dataset[\"X\"]),\n",
                "            \"dcor(v,Y)\": dcor.distance_correlation(dataset[variable], dataset[\"Y\"]),\n",
                "        })\n",
                "\n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "\n",
                "    df[\"dcor(X,Y)\"] = dcor.distance_correlation(dataset[\"X\"], dataset[\"Y\"])\n",
                "\n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "\n",
                "    return df\n",
                "\n",
                "def custom_distance_correlation(dataset):\n",
                "    \"\"\"\n",
                "    Compute distance correlation with custom distance metrics.\n",
                "    \n",
                "    Parameters:\n",
                "    - dataset: pandas DataFrame\n",
                "    \n",
                "    Returns:\n",
                "    - pandas DataFrame with distance correlation features\n",
                "    \"\"\"\n",
                "    metric = 'chebyshev'  # You can change this to 'euclidean', 'manhattan', or 'minkowski'\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                "    \n",
                "    def compute_distance_correlation(x, y):\n",
                "        # Convert Series to numpy arrays and reshape\n",
                "        x_array = x.values.reshape(-1, 1)\n",
                "        y_array = y.values.reshape(-1, 1)\n",
                "        \n",
                "        x_dist = squareform(pdist(x_array, metric=metric))\n",
                "        y_dist = squareform(pdist(y_array, metric=metric))\n",
                "        return dcor.distance_correlation_sqr(x_dist, y_dist)\n",
                "    \n",
                "    df = []\n",
                "    for variable in variables:\n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            f\"dcor_{metric}(v,X)\": compute_distance_correlation(dataset[variable], dataset[\"X\"]),\n",
                "            f\"dcor_{metric}(v,Y)\": compute_distance_correlation(dataset[variable], dataset[\"Y\"]),\n",
                "        })\n",
                "    \n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "    \n",
                "    df[f\"dcor_{metric}(X,Y)\"] = compute_distance_correlation(dataset[\"X\"], dataset[\"Y\"])\n",
                "    \n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\", \"variable\"] + [colname for colname in df.columns if colname not in [\"dataset\", \"variable\"]]]\n",
                "    \n",
                "    return df\n",
                "\n",
                "def linear_regression_feature(dataset):\n",
                "    def Squared_term(dataset, variables):\n",
                "        for var in variables:\n",
                "            dataset[f'{var}_squared_term'] = dataset[var] ** 2\n",
                "        return dataset\n",
                "    \n",
                "    def Interaction_term(dataset, variables):\n",
                "        for i in range(len(variables)):\n",
                "            for j in range(i + 1, len(variables)):\n",
                "                dataset[f'{variables[i]}_{variables[j]}'] = dataset[variables[i]] * dataset[variables[j]]\n",
                "        return dataset\n",
                "\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"]).tolist()\n",
                "\n",
                "    # model1: Fit X, v, v^2, v_i*v_j, v_i*X ~ Y\n",
                "    model1_features = [\"X\"] + variables\n",
                "    d1 = Squared_term(dataset[model1_features], variables)\n",
                "    d1 = Interaction_term(d1, model1_features)  # 0.4600-0.4648\n",
                "    model1_features = d1.columns.tolist()\n",
                "    scaler = StandardScaler()\n",
                "    d1_scaled = scaler.fit_transform(d1)\n",
                "    model1 = LinearRegression().fit(d1_scaled, dataset[[\"Y\"]])\n",
                "    model1_coefs = model1.coef_[0].tolist()\n",
                "    model1_dict = {name: coef for name, coef in zip(model1_features, model1_coefs)}\n",
                "    \n",
                "    # model2: Fit v, v^2 ~ X\n",
                "    model2_features = variables\n",
                "    d2 = Squared_term(dataset[model2_features], variables)\n",
                "    # d2 = Interaction_term(d2, variables)  # 0.4648-0.4643\n",
                "    model2_features = d2.columns.tolist()\n",
                "    scaler = StandardScaler()\n",
                "    d2_scaled = scaler.fit_transform(d2)\n",
                "    model2 = LinearRegression().fit(d2_scaled, dataset[[\"X\"]])\n",
                "    model2_coefs = model2.coef_[0].tolist()\n",
                "    model2_dict = {name: coef for name, coef in zip(model2_features, model2_coefs)}\n",
                "    \n",
                "    df = []\n",
                "    for i, variable in enumerate(variables):\n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            \"v~Y_coefficient\": model1_dict[variable],\n",
                "            \"v_squared~Y_coefficient\": model1_dict[f\"{variable}_squared_term\"],\n",
                "            \"v~X_coefficient\": model2_dict[variable],\n",
                "            \"v_squared~X_coefficient\": model2_dict[f\"{variable}_squared_term\"],\n",
                "        })\n",
                "        \n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "    \n",
                "    df[\"X~Y_coefficient\"] = model1_dict[\"X\"]\n",
                "    \n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "\n",
                "    return df\n",
                "\n",
                "def ridge_regression_feature(dataset):\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"]).tolist()\n",
                "    # 使用GridSearchCV来选择最佳的alpha值\n",
                "    param_grid = {'alpha': np.logspace(-6, 6, 13)}\n",
                "    \n",
                "    # model1: Fit X, v ~ Y\n",
                "    model1_features = [\"X\"] + variables\n",
                "    scaler1 = StandardScaler()\n",
                "    d1_scaled = scaler1.fit_transform(dataset[model1_features])\n",
                "    model1 = GridSearchCV(Ridge(random_state=42), param_grid, cv=5)\n",
                "    model1.fit(d1_scaled, dataset[\"Y\"])\n",
                "    model1_coefs = model1.best_estimator_.coef_.tolist()\n",
                "    model1_dict = {name: coef for name, coef in zip(model1_features, model1_coefs)}\n",
                "    \n",
                "    # model2: Fit v ~ X\n",
                "    model2_features = variables\n",
                "    scaler2 = StandardScaler()\n",
                "    d2_scaled = scaler2.fit_transform(dataset[model2_features])\n",
                "    model2 = GridSearchCV(Ridge(random_state=42), param_grid, cv=5)\n",
                "    model2.fit(d2_scaled, dataset[\"X\"])\n",
                "    model2_coefs = model2.best_estimator_.coef_.tolist()\n",
                "    model2_dict = {name: coef for name, coef in zip(model2_features, model2_coefs)}\n",
                "\n",
                "    # # 获取最优的 alpha 值\n",
                "    # best_alpha_model1 = model1.best_params_['alpha']   # 0.4730-0.4727\n",
                "    # best_alpha_model2 = model2.best_params_['alpha']\n",
                "    \n",
                "    df = []\n",
                "    for i, variable in enumerate(variables):\n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            \"v~Y_ridge_coefficient\": model1_dict[variable],\n",
                "            \"v~X_ridge_coefficient\": model2_dict[variable],\n",
                "            # \"v~Y_ridge_alpha\": best_alpha_model1,\n",
                "            # \"v~X_ridge_alpha\": best_alpha_model2\n",
                "        })\n",
                "        \n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "    \n",
                "    df[\"X~Y_ridge_coefficient\"] = model1_dict[\"X\"]\n",
                "    \n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "\n",
                "    return df\n",
                "\n",
                "def cluster_features(dataset):\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"]).tolist()\n",
                "    scaler = StandardScaler()\n",
                "    d_scaled = pd.DataFrame(scaler.fit_transform(dataset), columns=dataset.columns)\n",
                "\n",
                "    results = []\n",
                "    eps_values = [0.3]  # , 0.5, 0.7\n",
                "    \n",
                "    for variable in variables:\n",
                "        cluster_counts = []\n",
                "        noise_counts = []\n",
                "        avg_cluster_sizes = []\n",
                "        density_variations = []\n",
                "        feature_importances = []\n",
                "        silhouette_scores = []\n",
                "        \n",
                "        for eps in eps_values:\n",
                "            cluster_df = d_scaled[[variable, \"X\", \"Y\"]].copy()\n",
                "            dbscan = DBSCAN(eps=eps, min_samples=5)\n",
                "            cluster_df[\"cluster\"] = dbscan.fit_predict(cluster_df)\n",
                "            \n",
                "            # 基本统计\n",
                "            cluster_count = len(set(cluster_df[\"cluster\"])) - (1 if -1 in cluster_df[\"cluster\"] else 0)\n",
                "            noise_count = (cluster_df[\"cluster\"] == -1).sum()\n",
                "            cluster_counts.append(cluster_count)\n",
                "            noise_counts.append(noise_count)\n",
                "            \n",
                "            # 密度分析\n",
                "            cluster_sizes = cluster_df[cluster_df[\"cluster\"] != -1][\"cluster\"].value_counts()\n",
                "            avg_cluster_size = cluster_sizes.mean() if not cluster_sizes.empty else 0\n",
                "            density_variation = cluster_sizes.std() / avg_cluster_size if avg_cluster_size > 0 else 0\n",
                "            avg_cluster_sizes.append(avg_cluster_size)\n",
                "            density_variations.append(density_variation)\n",
                "            \n",
                "            # 特征重要性\n",
                "            if cluster_count > 1:  # 确保有多个簇\n",
                "                feature_importance = abs(np.corrcoef(cluster_df[variable], cluster_df[\"cluster\"]))[0, 1]\n",
                "            else:\n",
                "                feature_importance = 0\n",
                "            feature_importances.append(feature_importance)\n",
                "            \n",
                "            # 轮廓系数\n",
                "            non_noise_mask = cluster_df[\"cluster\"] != -1\n",
                "            if len(set(cluster_df.loc[non_noise_mask, \"cluster\"])) > 1:\n",
                "                sil_score = silhouette_score(cluster_df.loc[non_noise_mask, [variable, \"X\", \"Y\"]], \n",
                "                                             cluster_df.loc[non_noise_mask, \"cluster\"], \n",
                "                                             metric=\"euclidean\")\n",
                "            else:\n",
                "                sil_score = 0\n",
                "            silhouette_scores.append(sil_score)\n",
                "        \n",
                "        result = {\n",
                "            \"variable\": variable\n",
                "        }\n",
                "        for i, eps in enumerate(eps_values):\n",
                "            result.update({\n",
                "                f\"cluster_count_{eps}\": cluster_counts[i],             # 0.4730-0.4736\n",
                "                f\"noise_count_{eps}\": noise_counts[i],                 # 0.4736-0.4740\n",
                "                # f\"avg_cluster_size_{eps}\": avg_cluster_sizes[i],     # 0.4740-0.4735\n",
                "                f\"density_variation_{eps}\": density_variations[i],     # 0.4740-0.4741\n",
                "                # f\"feature_importance_{eps}\": feature_importances[i], # 0.4741-0.4736\n",
                "                # f\"silhouette_score_{eps}\": silhouette_scores[i]      # 0.4741-0.4723\n",
                "            })\n",
                "        results.append(result)\n",
                "\n",
                "    df = pd.DataFrame(results)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "\n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "\n",
                "    return df\n",
                "\n",
                "def conditional_mutual_information(dataset):\n",
                "    \"\"\"\n",
                "    Calculate conditional mutual information for each variable with X and Y.\n",
                "    \"\"\"\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                "    \n",
                "    df = []\n",
                "    for variable in variables:\n",
                "        # Calculate conditional MI(v, X | Y)\n",
                "        mi_vx_given_y = mutual_info_regression(dataset[[variable, \"Y\"]], dataset[\"X\"], discrete_features=False)[0] - \\\n",
                "                        mutual_info_regression(dataset[[\"Y\"]], dataset[\"X\"], discrete_features=False)[0]\n",
                "        \n",
                "        # Calculate conditional MI(v, Y | X)\n",
                "        mi_vy_given_x = mutual_info_regression(dataset[[variable, \"X\"]], dataset[\"Y\"], discrete_features=False)[0] - \\\n",
                "                        mutual_info_regression(dataset[[\"X\"]], dataset[\"Y\"], discrete_features=False)[0]\n",
                "        \n",
                "        # Calculate conditional MI(X, Y | v)\n",
                "        mi_xy_given_v = mutual_info_regression(dataset[[\"X\", variable]], dataset[\"Y\"], discrete_features=False)[0] - \\\n",
                "                        mutual_info_regression(dataset[[variable]], dataset[\"Y\"], discrete_features=False)[0]\n",
                "        \n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            \"conditional_MI(v,X|Y)\": mi_vx_given_y,\n",
                "            \"conditional_MI(v,Y|X)\": mi_vy_given_x,\n",
                "            \"conditional_MI(X,Y|v)\": mi_xy_given_v,\n",
                "        })\n",
                "    \n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "    \n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "    \n",
                "    return df\n",
                "\n",
                "def partial_correlation(dataset):\n",
                "    \"\"\"\n",
                "    Compute partial correlation coefficients for each variable with X and Y,\n",
                "    controlling for the other variable, as well as the partial correlation\n",
                "    between X and Y controlling for each variable.\n",
                "    \"\"\"\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                "    \n",
                "    df = []\n",
                "    for variable in variables:\n",
                "        # Compute partial correlations\n",
                "        pcorr_vX_Y = pg.partial_corr(data=dataset, x=variable, y='X', covar='Y')['r'].iloc[0]\n",
                "        pcorr_vY_X = pg.partial_corr(data=dataset, x=variable, y='Y', covar='X')['r'].iloc[0]\n",
                "        pcorr_XY_v = pg.partial_corr(data=dataset, x='X', y='Y', covar=variable)['r'].iloc[0]\n",
                "        \n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            \"partial_corr(v,X|Y)\": pcorr_vX_Y,\n",
                "            \"partial_corr(v,Y|X)\": pcorr_vY_X,\n",
                "            \"partial_corr(X,Y|v)\": pcorr_XY_v,\n",
                "        })\n",
                "    \n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "    \n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "    \n",
                "    return df\n",
                "\n",
                "def entropy_features(dataset):\n",
                "    \"\"\"\n",
                "    Calculate entropy and conditional entropy features for each variable.\n",
                "    \"\"\"\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                "    \n",
                "    df = []\n",
                "    for variable in variables:\n",
                "        \n",
                "        # Calculate conditional entropies\n",
                "        joint_vX, _, _ = np.histogram2d(dataset[variable], dataset[\"X\"], bins=20)\n",
                "        joint_vY, _, _ = np.histogram2d(dataset[variable], dataset[\"Y\"], bins=20)\n",
                "        \n",
                "        # Normalize the joint distributions\n",
                "        joint_vX = joint_vX / joint_vX.sum()\n",
                "        joint_vY = joint_vY / joint_vY.sum()\n",
                "        \n",
                "        # Calculate marginal distributions\n",
                "        p_v_X = joint_vX.sum(axis=1)\n",
                "        p_v_Y = joint_vY.sum(axis=1)\n",
                "        \n",
                "        # Calculate conditional entropies\n",
                "        cond_entropy_X_v = np.sum(p_v_X * entropy(joint_vX.T, axis=0))\n",
                "        cond_entropy_Y_v = np.sum(p_v_Y * entropy(joint_vY.T, axis=0))\n",
                "        \n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            \"conditional_entropy(X|v)\": cond_entropy_X_v,\n",
                "            \"conditional_entropy(Y|v)\": cond_entropy_Y_v,\n",
                "        })\n",
                "    \n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "    \n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "    \n",
                "    return df\n",
                "\n",
                "def hilbert_schmidt_independence(dataset):\n",
                "    \"\"\"\n",
                "    Compute the Hilbert-Schmidt Independence Criterion (HSIC) between variables.\n",
                "    Features:\n",
                "        - hsic(v, X)\n",
                "        - hsic(v, Y)\n",
                "        - hsic(X, Y)\n",
                "    \"\"\"\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                "    \n",
                "    df = []\n",
                "    for variable in variables:\n",
                "        hsic_vX = hsic(dataset[variable].values, dataset[\"X\"].values)\n",
                "        hsic_vY = hsic(dataset[variable].values, dataset[\"Y\"].values)\n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            \"hsic(v,X)\": hsic_vX,\n",
                "            \"hsic(v,Y)\": hsic_vY,\n",
                "        })\n",
                "    \n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "    \n",
                "    hsic_XY = hsic(dataset[\"X\"].values, dataset[\"Y\"].values)\n",
                "    df[\"hsic(X,Y)\"] = hsic_XY\n",
                "    \n",
                "    # Reorder columns\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "    \n",
                "    return df\n",
                "\n",
                "def hsic(x, y, sigma=None):\n",
                "    \"\"\"\n",
                "    Compute the HSIC between two variables x and y.\n",
                "    x and y are numpy arrays of shape (n_samples,)\n",
                "    \"\"\"\n",
                "    n = x.shape[0]\n",
                "    x = x.reshape((n, -1))\n",
                "    y = y.reshape((n, -1))\n",
                "    \n",
                "    if sigma is None:\n",
                "        sigma = np.std(np.concatenate((x, y), axis=0))\n",
                "        if sigma == 0:\n",
                "            sigma = 1.0\n",
                "\n",
                "    # Compute the Gram matrices using RBF kernel\n",
                "    K = rbf_kernel(x, gamma=1.0/(2*sigma**2))\n",
                "    L = rbf_kernel(y, gamma=1.0/(2*sigma**2))\n",
                "    \n",
                "    # Center the Gram matrices\n",
                "    H = np.eye(n) - np.ones((n, n))/n\n",
                "    Kc = H @ K @ H\n",
                "    Lc = H @ L @ H\n",
                "    \n",
                "    # Compute HSIC\n",
                "    hsic_value = (1/(n-1)**2) * np.trace(Kc @ Lc)\n",
                "    return hsic_value\n",
                "\n",
                "def statistical_tests(dataset):\n",
                "    \"\"\"\n",
                "    Compute p-values from statistical tests for each variable with X and Y.\n",
                "    \"\"\"\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                "    \n",
                "    df = []\n",
                "    for variable in variables:\n",
                "        # Chi-square test\n",
                "        chi2_vX = chi2_contingency(pd.crosstab(dataset[variable], dataset[\"X\"]))[1]\n",
                "        chi2_vY = chi2_contingency(pd.crosstab(dataset[variable], dataset[\"Y\"]))[1]\n",
                "        \n",
                "        # Kolmogorov-Smirnov test\n",
                "        ks_vX = ks_2samp(dataset[variable], dataset[\"X\"])[1]\n",
                "        ks_vY = ks_2samp(dataset[variable], dataset[\"Y\"])[1]\n",
                "        \n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            \"pvalue(chi2_test(v,X))\": chi2_vX,\n",
                "            \"pvalue(chi2_test(v,Y))\": chi2_vY,\n",
                "            \"pvalue(ks_test(v,X))\": ks_vX,\n",
                "            \"pvalue(ks_test(v,Y))\": ks_vY,\n",
                "        })\n",
                "    \n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "    \n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "    \n",
                "    return df\n",
                "\n",
                "def cross_entropy_features(dataset):\n",
                "    \"\"\"\n",
                "    Compute cross-entropy based features for each variable with X and Y.\n",
                "    \"\"\"\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                "    \n",
                "    def compute_cross_entropy(p, q):\n",
                "        # Ensure p and q are probability distributions\n",
                "        p = softmax(p)\n",
                "        q = softmax(q)\n",
                "        return -np.sum(p * np.log(q + 1e-10))\n",
                "    \n",
                "    df = []\n",
                "    for variable in variables:\n",
                "        # Normalize the data to [0, 1] range\n",
                "        scaler = MinMaxScaler()\n",
                "        v_normalized = scaler.fit_transform(dataset[[variable]]).flatten()\n",
                "        X_normalized = scaler.fit_transform(dataset[[\"X\"]]).flatten()\n",
                "        Y_normalized = scaler.fit_transform(dataset[[\"Y\"]]).flatten()\n",
                "        \n",
                "        cross_entropy_vX = compute_cross_entropy(v_normalized, X_normalized)\n",
                "        cross_entropy_vY = compute_cross_entropy(v_normalized, Y_normalized)\n",
                "        \n",
                "        # Compute cross-entropy with other variables\n",
                "        other_vars = [col for col in variables]\n",
                "        cross_entropies = []\n",
                "        for other_var in other_vars:\n",
                "            other_normalized = scaler.fit_transform(dataset[[other_var]]).flatten()\n",
                "            cross_entropies.append(compute_cross_entropy(v_normalized, other_normalized))\n",
                "        \n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            \"cross_entropy(v,X)\": cross_entropy_vX,\n",
                "            \"cross_entropy(v,Y)\": cross_entropy_vY,\n",
                "            \"max(cross_entropy(v,others))\": max(cross_entropies),\n",
                "            \"min(cross_entropy(v,others))\": min(cross_entropies),\n",
                "            \"mean(cross_entropy(v,others))\": np.mean(cross_entropies),\n",
                "            \"std(cross_entropy(v,others))\": np.std(cross_entropies),\n",
                "        })\n",
                "    \n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "    \n",
                "    # Compute cross-entropy between X and Y\n",
                "    X_normalized = scaler.fit_transform(dataset[[\"X\"]]).flatten()\n",
                "    Y_normalized = scaler.fit_transform(dataset[[\"Y\"]]).flatten()\n",
                "    df[\"cross_entropy(X,Y)\"] = compute_cross_entropy(X_normalized, Y_normalized)\n",
                "    \n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "    \n",
                "    return df\n",
                "\n",
                "def multi_mutual_information(dataset):\n",
                "    \"\"\"\n",
                "    Compute multi-variable mutual information for each variable with X and Y.\n",
                "    \"\"\"\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                "    \n",
                "    def compute_multi_mi(X, Y, Z):\n",
                "        # Discretize continuous variables\n",
                "        kbd = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
                "        X_disc = kbd.fit_transform(X.reshape(-1, 1))\n",
                "        Y_disc = kbd.fit_transform(Y.reshape(-1, 1))\n",
                "        Z_disc = kbd.fit_transform(Z.reshape(-1, 1))\n",
                "        \n",
                "        # Compute joint and marginal entropies\n",
                "        XYZ = np.c_[X_disc, Y_disc, Z_disc]\n",
                "        XY = np.c_[X_disc, Y_disc]\n",
                "        XZ = np.c_[X_disc, Z_disc]\n",
                "        YZ = np.c_[Y_disc, Z_disc]\n",
                "        \n",
                "        H_XYZ = mutual_info_regression(XYZ, XYZ[:, 0])[0]\n",
                "        H_XY = mutual_info_regression(XY, XY[:, 0])[0]\n",
                "        H_XZ = mutual_info_regression(XZ, XZ[:, 0])[0]\n",
                "        H_YZ = mutual_info_regression(YZ, YZ[:, 0])[0]\n",
                "        H_X = mutual_info_regression(X_disc, X_disc[:, 0])[0]\n",
                "        H_Y = mutual_info_regression(Y_disc, Y_disc[:, 0])[0]\n",
                "        H_Z = mutual_info_regression(Z_disc, Z_disc[:, 0])[0]\n",
                "        \n",
                "        # Compute multi-variable mutual information\n",
                "        return H_X + H_Y + H_Z - H_XY - H_XZ - H_YZ + H_XYZ\n",
                "    \n",
                "    df = []\n",
                "    for variable in variables:\n",
                "        multi_mi = compute_multi_mi(dataset[variable].values, dataset[\"X\"].values, dataset[\"Y\"].values)\n",
                "        \n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            \"multi_mutual_information(v,X,Y)\": multi_mi,\n",
                "        })\n",
                "    \n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "    \n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "    \n",
                "    return df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2024-09-18T09:31:25.402707Z",
                    "start_time": "2024-09-18T09:31:25.388081Z"
                },
                "metadata": {}
            },
            "outputs": [],
            "source": [
                "def label(adjacency_matrix):\n",
                "    \"\"\"\n",
                "    Given a graph as adjacency_matrix, create the class labels of each variable.\n",
                "    \"\"\"\n",
                "\n",
                "    adjacency_graph, adjacency_label = create_graph_label()\n",
                "    labels = get_labels(adjacency_matrix, adjacency_label)\n",
                "    variables = adjacency_matrix.columns.drop([\"X\", \"Y\"])\n",
                "\n",
                "    df = pd.DataFrame({\n",
                "        \"variable\": variables,\n",
                "        \"label\": [labels[variable] for variable in variables],\n",
                "    })\n",
                "    df[\"dataset\"] = adjacency_matrix.name\n",
                "\n",
                "    # Reorder columns:\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "\n",
                "    return df\n",
                "\n",
                "def hilbert_schmidt_independence_rff(dataset, n_components=100, random_state=None):\n",
                "    \"\"\"\n",
                "    Compute the Hilbert-Schmidt Independence Criterion (HSIC) between variables\n",
                "    using Random Fourier Features for efficiency.\n",
                "    \n",
                "    Parameters:\n",
                "    - dataset: pandas DataFrame containing the data.\n",
                "    - n_components: int, number of random Fourier features.\n",
                "    - random_state: int or None, for reproducibility.\n",
                "    \n",
                "    Returns:\n",
                "    - df: pandas DataFrame with HSIC features.\n",
                "    \"\"\"\n",
                "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
                "    rng = check_random_state(random_state)\n",
                "    \n",
                "    # Prepare the random weights and biases for RFF\n",
                "    sigma = np.std(dataset.values)\n",
                "    if sigma == 0:\n",
                "        sigma = 1.0\n",
                "    gamma = 1.0 / (2 * sigma ** 2)\n",
                "    \n",
                "    def compute_rff(X):\n",
                "        n_samples = X.shape[0]\n",
                "        X = X.reshape(n_samples, -1)\n",
                "        W = rng.normal(scale=np.sqrt(2 * gamma), size=(X.shape[1], n_components))\n",
                "        b = rng.uniform(0, 2 * np.pi, size=n_components)\n",
                "        Z = np.sqrt(2.0 / n_components) * np.cos(X @ W + b)\n",
                "        return Z\n",
                "\n",
                "    # Compute RFF for X and Y once\n",
                "    Z_X = compute_rff(dataset[\"X\"].values)\n",
                "    Z_Y = compute_rff(dataset[\"Y\"].values)\n",
                "    \n",
                "    # Center the RFF features\n",
                "    Z_X -= Z_X.mean(axis=0)\n",
                "    Z_Y -= Z_Y.mean(axis=0)\n",
                "    \n",
                "    df = []\n",
                "    for variable in variables:\n",
                "        Z_v = compute_rff(dataset[variable].values)\n",
                "        Z_v -= Z_v.mean(axis=0)\n",
                "        \n",
                "        # Compute HSIC approximations\n",
                "        hsic_vX = np.sum(Z_v * Z_X) / (dataset.shape[0] - 1)\n",
                "        hsic_vY = np.sum(Z_v * Z_Y) / (dataset.shape[0] - 1)\n",
                "        \n",
                "        df.append({\n",
                "            \"variable\": variable,\n",
                "            \"hsic(v,X)\": hsic_vX,\n",
                "            \"hsic(v,Y)\": hsic_vY,\n",
                "        })\n",
                "    \n",
                "    df = pd.DataFrame(df)\n",
                "    df[\"dataset\"] = dataset.name\n",
                "    \n",
                "    # Compute HSIC between X and Y\n",
                "    hsic_XY = np.sum(Z_X * Z_Y) / (dataset.shape[0] - 1)\n",
                "    df[\"hsic(X,Y)\"] = hsic_XY\n",
                "    \n",
                "    # Reorder columns\n",
                "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
                "    \n",
                "    return df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2024-09-18T09:31:26.636102Z",
                    "start_time": "2024-09-18T09:31:26.629666Z"
                },
                "metadata": {}
            },
            "outputs": [],
            "source": [
                "def create_some_columns(names_datasets, function):\n",
                "    \"\"\"\n",
                "    Apply an embedding function to a list of datasets.\n",
                "    \"\"\"\n",
                "\n",
                "    df = []\n",
                "    for name, dataset in tqdm(names_datasets.items()):\n",
                "        dataset = names_datasets[name]\n",
                "        dataset.name = name\n",
                "    \n",
                "        try:\n",
                "            df_dataset = function(dataset)\n",
                "        except ValueError as e:\n",
                "            print(name, e)\n",
                "            raise NotImplementedError\n",
                "\n",
                "        df_dataset[\"dataset\"] = name\n",
                "        df.append(df_dataset)\n",
                "\n",
                "    df = pd.concat(df, axis=\"index\").reset_index(drop=True)\n",
                "    return df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2024-09-18T09:31:27.391364Z",
                    "start_time": "2024-09-18T09:31:27.380030Z"
                },
                "metadata": {}
            },
            "outputs": [],
            "source": [
                "def create_some_columns_parallel(names_datasets, function, n_jobs=-1):\n",
                "    \"\"\"\n",
                "    Apply an embedding function to a list of datasets.\n",
                "\n",
                "    Parallel version.\n",
                "    \"\"\"\n",
                "\n",
                "    def f(name, dataset, function):\n",
                "        dataset.name = name\n",
                "        df_dataset = function(dataset)\n",
                "        df_dataset[\"dataset\"] = name\n",
                "        return df_dataset\n",
                "\n",
                "    df = joblib.Parallel(n_jobs=n_jobs)(\n",
                "        joblib.delayed(f)(name, dataset, function)\n",
                "        for name, dataset in tqdm(names_datasets.items())\n",
                "    )\n",
                "\n",
                "    df = pd.concat(df, axis=\"index\").reset_index(drop=True)\n",
                "    return df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2024-09-18T09:31:28.411964Z",
                    "start_time": "2024-09-18T09:31:28.402880Z"
                },
                "metadata": {}
            },
            "outputs": [],
            "source": [
                "def create_all_columns(functions_names_datasets, n_jobs=-1, create_dimension_feature = False):\n",
                "    \"\"\"\n",
                "    given a dictionary of {function1:names, function2:names,...} apply\n",
                "    the desired functions to the list of datasets and merge all of them\n",
                "    in a single X_y_group dataframe.\n",
                "    \"\"\"\n",
                "\n",
                "    columns = []\n",
                "    if create_dimension_feature:\n",
                "        dimension_feature = create_some_columns(functions_names_datasets[list(functions_names_datasets.keys())[0]], add_dimension_feature)\n",
                "        columns.append(dimension_feature)\n",
                "    \n",
                "    for function, names_datasets in functions_names_datasets.items():\n",
                "        print(f\"set: {function.__name__}\")\n",
                "\n",
                "        if n_jobs != 1:\n",
                "            feature_set = create_some_columns_parallel(names_datasets, function, n_jobs=n_jobs)\n",
                "        else:\n",
                "            feature_set = create_some_columns(names_datasets, function)\n",
                "\n",
                "        columns.append(feature_set)\n",
                "\n",
                "    # Merge all feature sets into a single dataframe:\n",
                "    columns = functools.reduce(\n",
                "        lambda left, right: pd.merge(left, right, on=[\"dataset\", \"variable\"]),\n",
                "        columns,\n",
                "    )\n",
                "\n",
                "    return columns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/46275 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 46275/46275 [00:26<00:00, 1771.04it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "set: pearson_correlation\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 46275/46275 [02:09<00:00, 357.21it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "set: mutual_information\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 46275/46275 [39:29<00:00, 19.53it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "set: label\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 46275/46275 [00:55<00:00, 828.12it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "set: spearman_correlation\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 46275/46275 [02:07<00:00, 363.27it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "set: kendall_correlation\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 46275/46275 [08:37<00:00, 89.34it/s] \n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "set: distance_correlation\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 32/46275 [01:38<39:26:56,  3.07s/it]e:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
                        "  warnings.warn(\n",
                        "e:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
                        "  warnings.warn(\n",
                        "e:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
                        "  warnings.warn(\n",
                        "e:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
                        "  warnings.warn(\n",
                        "  0%|          | 48/46275 [01:42<24:15:30,  1.89s/it]e:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
                        "  warnings.warn(\n",
                        "e:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
                        "  warnings.warn(\n",
                        "e:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
                        "  warnings.warn(\n",
                        "100%|██████████| 46275/46275 [05:07<00:00, 150.45it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "set: conditional_mutual_information\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  4%|▍         | 1856/46275 [01:30<36:12, 20.44it/s]e:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
                        "  warnings.warn(\n",
                        "  6%|▌         | 2624/46275 [02:09<35:28, 20.51it/s]e:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
                        "  warnings.warn(\n",
                        "100%|██████████| 46275/46275 [38:29<00:00, 20.04it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "set: partial_correlation\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 46275/46275 [05:24<00:00, 142.75it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "set: linear_regression_feature\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 46275/46275 [02:37<00:00, 293.67it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "set: ridge_regression_feature\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 46275/46275 [28:45<00:00, 26.82it/s]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "set: cluster_features\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 46275/46275 [16:13<00:00, 47.52it/s]\n"
                    ]
                }
            ],
            "source": [
                "names_datasets_train = X_train\n",
                "names_graphs_train = y_train\n",
                "X_y_group_train = create_all_columns(\n",
                "    {\n",
                "        pearson_correlation: names_datasets_train,\n",
                "        mutual_information: names_datasets_train, \n",
                "        label: names_graphs_train,\n",
                "        spearman_correlation: names_datasets_train,\n",
                "        kendall_correlation: names_datasets_train,\n",
                "        distance_correlation: names_datasets_train,\n",
                "        conditional_mutual_information: names_datasets_train,\n",
                "        partial_correlation: names_datasets_train,\n",
                "        linear_regression_feature: names_datasets_train,\n",
                "        ridge_regression_feature: names_datasets_train,\n",
                "        cluster_features: names_datasets_train,\n",
                "    },\n",
                "    n_jobs=-1,\n",
                "    create_dimension_feature=True,\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "# names_datasets_train = X_train\n",
                "# names_graphs_train = y_train\n",
                "# X_y_group_train_additional = create_all_columns(\n",
                "#     {\n",
                "#         spearman_correlation: names_datasets_train,\n",
                "#         kendall_correlation: names_datasets_train,\n",
                "#         distance_correlation: names_datasets_train,\n",
                "#         conditional_mutual_information: names_datasets_train,\n",
                "#         linear_regression_feature: names_datasets_train,\n",
                "#     },\n",
                "#     n_jobs=-1,\n",
                "# )\n",
                "\n",
                "\n",
                "# X_y_group_train = pd.concat([X_y_group_train, X_y_group_train_additional], axis=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# 去掉重复的列\n",
                "X_y_group_train = X_y_group_train.loc[:,~X_y_group_train.columns.duplicated()]\n",
                "X_y_group_train['MI(v,X)^2'] = X_y_group_train['MI(v,X)'] ** 2\n",
                "X_y_group_train['MI(v,Y)^2'] = X_y_group_train['MI(v,Y)'] ** 2\n",
                "X_y_group_train['MI(X,Y)^2'] = X_y_group_train['MI(X,Y)'] ** 2\n",
                "X_y_group_train['max(MI(v, others))^2'] = X_y_group_train['max(MI(v, others))'] ** 2\n",
                "X_y_group_train['min(MI(v, others))^2'] = X_y_group_train['min(MI(v, others))'] ** 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {
                "metadata": {}
            },
            "outputs": [],
            "source": [
                "X_y_group_train.to_csv('./mid_data/X_y_group_train_updated_aug_v10.csv', index=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "X_y_group_train = pd.read_csv('./mid_data/X_y_group_train_updated_aug_v10.csv')\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2024-09-18T09:34:49.212104Z",
                    "start_time": "2024-09-18T09:34:48.478623Z"
                },
                "metadata": {}
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Adding numeric labels y\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>dataset</th>\n",
                            "      <th>variable</th>\n",
                            "      <th>dimension</th>\n",
                            "      <th>square_dimension</th>\n",
                            "      <th>corr(v,X)</th>\n",
                            "      <th>corr(v,Y)</th>\n",
                            "      <th>max(corr(v, others))</th>\n",
                            "      <th>min(corr(v, others))</th>\n",
                            "      <th>mean(corr(v, others))</th>\n",
                            "      <th>std(corr(v, others))</th>\n",
                            "      <th>...</th>\n",
                            "      <th>cluster_count_0.3</th>\n",
                            "      <th>noise_count_0.3</th>\n",
                            "      <th>density_variation_0.3</th>\n",
                            "      <th>MI(v,X)^2</th>\n",
                            "      <th>MI(v,Y)^2</th>\n",
                            "      <th>MI(X,Y)^2</th>\n",
                            "      <th>max(MI(v, others))^2</th>\n",
                            "      <th>min(MI(v, others))^2</th>\n",
                            "      <th>label</th>\n",
                            "      <th>y</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>8</td>\n",
                            "      <td>64</td>\n",
                            "      <td>0.169735</td>\n",
                            "      <td>-0.113595</td>\n",
                            "      <td>0.791467</td>\n",
                            "      <td>0.027355</td>\n",
                            "      <td>0.282376</td>\n",
                            "      <td>0.298969</td>\n",
                            "      <td>...</td>\n",
                            "      <td>13</td>\n",
                            "      <td>196</td>\n",
                            "      <td>1.664905</td>\n",
                            "      <td>0.002690</td>\n",
                            "      <td>0.003807</td>\n",
                            "      <td>0.194275</td>\n",
                            "      <td>0.277897</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>Consequence of Y</td>\n",
                            "      <td>5</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>8</td>\n",
                            "      <td>64</td>\n",
                            "      <td>-0.072334</td>\n",
                            "      <td>0.139419</td>\n",
                            "      <td>0.230139</td>\n",
                            "      <td>0.003233</td>\n",
                            "      <td>0.090511</td>\n",
                            "      <td>0.082201</td>\n",
                            "      <td>...</td>\n",
                            "      <td>16</td>\n",
                            "      <td>213</td>\n",
                            "      <td>3.273170</td>\n",
                            "      <td>0.000255</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.194275</td>\n",
                            "      <td>0.003711</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>Independent</td>\n",
                            "      <td>6</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>0</td>\n",
                            "      <td>3</td>\n",
                            "      <td>8</td>\n",
                            "      <td>64</td>\n",
                            "      <td>0.123115</td>\n",
                            "      <td>-0.238769</td>\n",
                            "      <td>0.781051</td>\n",
                            "      <td>0.012225</td>\n",
                            "      <td>0.257037</td>\n",
                            "      <td>0.288165</td>\n",
                            "      <td>...</td>\n",
                            "      <td>17</td>\n",
                            "      <td>202</td>\n",
                            "      <td>2.332452</td>\n",
                            "      <td>0.000990</td>\n",
                            "      <td>0.003352</td>\n",
                            "      <td>0.194275</td>\n",
                            "      <td>0.258012</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>Cause of Y</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>0</td>\n",
                            "      <td>4</td>\n",
                            "      <td>8</td>\n",
                            "      <td>64</td>\n",
                            "      <td>-0.001935</td>\n",
                            "      <td>0.013921</td>\n",
                            "      <td>0.147408</td>\n",
                            "      <td>0.001935</td>\n",
                            "      <td>0.052451</td>\n",
                            "      <td>0.053457</td>\n",
                            "      <td>...</td>\n",
                            "      <td>23</td>\n",
                            "      <td>173</td>\n",
                            "      <td>2.464711</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000814</td>\n",
                            "      <td>0.194275</td>\n",
                            "      <td>0.003268</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>Cause of Y</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>0</td>\n",
                            "      <td>5</td>\n",
                            "      <td>8</td>\n",
                            "      <td>64</td>\n",
                            "      <td>0.284323</td>\n",
                            "      <td>-0.466570</td>\n",
                            "      <td>0.791467</td>\n",
                            "      <td>0.064815</td>\n",
                            "      <td>0.426306</td>\n",
                            "      <td>0.250048</td>\n",
                            "      <td>...</td>\n",
                            "      <td>14</td>\n",
                            "      <td>186</td>\n",
                            "      <td>3.054884</td>\n",
                            "      <td>0.003862</td>\n",
                            "      <td>0.025945</td>\n",
                            "      <td>0.194275</td>\n",
                            "      <td>0.278425</td>\n",
                            "      <td>0.000801</td>\n",
                            "      <td>Mediator</td>\n",
                            "      <td>7</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>...</th>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>284513</th>\n",
                            "      <td>46997</td>\n",
                            "      <td>2</td>\n",
                            "      <td>7</td>\n",
                            "      <td>49</td>\n",
                            "      <td>0.031413</td>\n",
                            "      <td>-0.013858</td>\n",
                            "      <td>0.363840</td>\n",
                            "      <td>0.013858</td>\n",
                            "      <td>0.067153</td>\n",
                            "      <td>0.120108</td>\n",
                            "      <td>...</td>\n",
                            "      <td>14</td>\n",
                            "      <td>235</td>\n",
                            "      <td>2.634607</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.000056</td>\n",
                            "      <td>0.381338</td>\n",
                            "      <td>0.009629</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>Independent</td>\n",
                            "      <td>6</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>284514</th>\n",
                            "      <td>46997</td>\n",
                            "      <td>3</td>\n",
                            "      <td>7</td>\n",
                            "      <td>49</td>\n",
                            "      <td>0.010469</td>\n",
                            "      <td>0.719588</td>\n",
                            "      <td>0.970364</td>\n",
                            "      <td>0.010381</td>\n",
                            "      <td>0.433942</td>\n",
                            "      <td>0.455522</td>\n",
                            "      <td>...</td>\n",
                            "      <td>5</td>\n",
                            "      <td>29</td>\n",
                            "      <td>1.934091</td>\n",
                            "      <td>0.000096</td>\n",
                            "      <td>0.296889</td>\n",
                            "      <td>0.381338</td>\n",
                            "      <td>1.834585</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>Consequence of X</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>284515</th>\n",
                            "      <td>46997</td>\n",
                            "      <td>6</td>\n",
                            "      <td>7</td>\n",
                            "      <td>49</td>\n",
                            "      <td>-0.116481</td>\n",
                            "      <td>0.697089</td>\n",
                            "      <td>0.908029</td>\n",
                            "      <td>0.089641</td>\n",
                            "      <td>0.496939</td>\n",
                            "      <td>0.362995</td>\n",
                            "      <td>...</td>\n",
                            "      <td>9</td>\n",
                            "      <td>96</td>\n",
                            "      <td>2.126500</td>\n",
                            "      <td>0.003345</td>\n",
                            "      <td>0.171072</td>\n",
                            "      <td>0.381338</td>\n",
                            "      <td>0.751515</td>\n",
                            "      <td>0.000109</td>\n",
                            "      <td>Collider</td>\n",
                            "      <td>2</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>284516</th>\n",
                            "      <td>46997</td>\n",
                            "      <td>5</td>\n",
                            "      <td>7</td>\n",
                            "      <td>49</td>\n",
                            "      <td>-0.096150</td>\n",
                            "      <td>0.653482</td>\n",
                            "      <td>0.882476</td>\n",
                            "      <td>0.023450</td>\n",
                            "      <td>0.430939</td>\n",
                            "      <td>0.402927</td>\n",
                            "      <td>...</td>\n",
                            "      <td>8</td>\n",
                            "      <td>123</td>\n",
                            "      <td>2.466383</td>\n",
                            "      <td>0.000597</td>\n",
                            "      <td>0.138596</td>\n",
                            "      <td>0.381338</td>\n",
                            "      <td>0.639251</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>Independent</td>\n",
                            "      <td>6</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>284517</th>\n",
                            "      <td>46997</td>\n",
                            "      <td>8</td>\n",
                            "      <td>7</td>\n",
                            "      <td>49</td>\n",
                            "      <td>-0.102693</td>\n",
                            "      <td>0.748635</td>\n",
                            "      <td>0.970364</td>\n",
                            "      <td>0.011658</td>\n",
                            "      <td>0.469777</td>\n",
                            "      <td>0.441105</td>\n",
                            "      <td>...</td>\n",
                            "      <td>2</td>\n",
                            "      <td>1</td>\n",
                            "      <td>NaN</td>\n",
                            "      <td>0.000058</td>\n",
                            "      <td>0.362751</td>\n",
                            "      <td>0.381338</td>\n",
                            "      <td>1.838560</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>Cause of Y</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>284518 rows × 61 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "        dataset  variable  dimension  square_dimension  corr(v,X)  corr(v,Y)  \\\n",
                            "0             0         0          8                64   0.169735  -0.113595   \n",
                            "1             0         2          8                64  -0.072334   0.139419   \n",
                            "2             0         3          8                64   0.123115  -0.238769   \n",
                            "3             0         4          8                64  -0.001935   0.013921   \n",
                            "4             0         5          8                64   0.284323  -0.466570   \n",
                            "...         ...       ...        ...               ...        ...        ...   \n",
                            "284513    46997         2          7                49   0.031413  -0.013858   \n",
                            "284514    46997         3          7                49   0.010469   0.719588   \n",
                            "284515    46997         6          7                49  -0.116481   0.697089   \n",
                            "284516    46997         5          7                49  -0.096150   0.653482   \n",
                            "284517    46997         8          7                49  -0.102693   0.748635   \n",
                            "\n",
                            "        max(corr(v, others))  min(corr(v, others))  mean(corr(v, others))  \\\n",
                            "0                   0.791467              0.027355               0.282376   \n",
                            "1                   0.230139              0.003233               0.090511   \n",
                            "2                   0.781051              0.012225               0.257037   \n",
                            "3                   0.147408              0.001935               0.052451   \n",
                            "4                   0.791467              0.064815               0.426306   \n",
                            "...                      ...                   ...                    ...   \n",
                            "284513              0.363840              0.013858               0.067153   \n",
                            "284514              0.970364              0.010381               0.433942   \n",
                            "284515              0.908029              0.089641               0.496939   \n",
                            "284516              0.882476              0.023450               0.430939   \n",
                            "284517              0.970364              0.011658               0.469777   \n",
                            "\n",
                            "        std(corr(v, others))  ...  cluster_count_0.3  noise_count_0.3  \\\n",
                            "0                   0.298969  ...                 13              196   \n",
                            "1                   0.082201  ...                 16              213   \n",
                            "2                   0.288165  ...                 17              202   \n",
                            "3                   0.053457  ...                 23              173   \n",
                            "4                   0.250048  ...                 14              186   \n",
                            "...                      ...  ...                ...              ...   \n",
                            "284513              0.120108  ...                 14              235   \n",
                            "284514              0.455522  ...                  5               29   \n",
                            "284515              0.362995  ...                  9               96   \n",
                            "284516              0.402927  ...                  8              123   \n",
                            "284517              0.441105  ...                  2                1   \n",
                            "\n",
                            "        density_variation_0.3  MI(v,X)^2  MI(v,Y)^2  MI(X,Y)^2  \\\n",
                            "0                    1.664905   0.002690   0.003807   0.194275   \n",
                            "1                    3.273170   0.000255   0.000000   0.194275   \n",
                            "2                    2.332452   0.000990   0.003352   0.194275   \n",
                            "3                    2.464711   0.000000   0.000814   0.194275   \n",
                            "4                    3.054884   0.003862   0.025945   0.194275   \n",
                            "...                       ...        ...        ...        ...   \n",
                            "284513               2.634607   0.000000   0.000056   0.381338   \n",
                            "284514               1.934091   0.000096   0.296889   0.381338   \n",
                            "284515               2.126500   0.003345   0.171072   0.381338   \n",
                            "284516               2.466383   0.000597   0.138596   0.381338   \n",
                            "284517                    NaN   0.000058   0.362751   0.381338   \n",
                            "\n",
                            "        max(MI(v, others))^2  min(MI(v, others))^2             label  y  \n",
                            "0                   0.277897              0.000000  Consequence of Y  5  \n",
                            "1                   0.003711              0.000000       Independent  6  \n",
                            "2                   0.258012              0.000000        Cause of Y  1  \n",
                            "3                   0.003268              0.000000        Cause of Y  1  \n",
                            "4                   0.278425              0.000801          Mediator  7  \n",
                            "...                      ...                   ...               ... ..  \n",
                            "284513              0.009629              0.000000       Independent  6  \n",
                            "284514              1.834585              0.000000  Consequence of X  4  \n",
                            "284515              0.751515              0.000109          Collider  2  \n",
                            "284516              0.639251              0.000000       Independent  6  \n",
                            "284517              1.838560              0.000000        Cause of Y  1  \n",
                            "\n",
                            "[284518 rows x 61 columns]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracting X_train, y_train, and group\n"
                    ]
                }
            ],
            "source": [
                "\n",
                "print(\"Adding numeric labels y\")\n",
                "le = LabelEncoder()\n",
                "X_y_group_train[\"y\"] = le.fit_transform(X_y_group_train[\"label\"])\n",
                "# reordering columns:\n",
                "X_y_group_train = X_y_group_train[[\"dataset\", \"variable\"] + X_y_group_train.columns.drop([\"dataset\", \"variable\", \"label\", \"y\"]).tolist() + [\"label\", \"y\"]]\n",
                "\n",
                "\n",
                "blacklist = [\"ttest(v,X)\", \"pvalue(ttest(v,X))<=0.05\", \"ttest(v,Y)\", \"pvalue(ttest(v,Y))<=0.05\", \"ttest(X,Y)\", \"pvalue(ttest(X,Y))<=0.05\"]\n",
                "columns_to_drop = [col for col in blacklist if col in X_y_group_train.columns]\n",
                "X_y_group_train = X_y_group_train.drop(columns=columns_to_drop)\n",
                "\n",
                "display(X_y_group_train)\n",
                "\n",
                "print(\"Extracting X_train, y_train, and group\")\n",
                "X_train = X_y_group_train.drop([\"variable\", \"dataset\", \"label\", \"y\"], axis=\"columns\")\n",
                "y_train = X_y_group_train[\"y\"]\n",
                "group_train = X_y_group_train[\"dataset\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Validation Balanced Accuracy: 0.4871\n",
                        "Final model trained on all data and saved.\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "\n",
                "# 1. 分离原始数据集和增强数据集\n",
                "# 如果 dataset 列是数值类型，我们可以直接比较长度\n",
                "if np.issubdtype(X_y_group_train['dataset'].dtype, np.number):\n",
                "    original_data = X_y_group_train[X_y_group_train['dataset'].astype(str).str.len() == 5]\n",
                "    augmented_data = X_y_group_train[X_y_group_train['dataset'].astype(str).str.len() > 5]\n",
                "else:\n",
                "    # 如果是其他类型，我们可以尝试转换为字符串\n",
                "    original_data = X_y_group_train[X_y_group_train['dataset'].astype(str).str.len() == 5]\n",
                "    augmented_data = X_y_group_train[X_y_group_train['dataset'].astype(str).str.len() > 5]\n",
                "\n",
                "# 2. 划分原始数据集为训练集和验证集\n",
                "original_train, original_val = train_test_split(original_data, test_size=0.2, random_state=42, stratify=original_data['label'])\n",
                "\n",
                "# 3. 将增强数据添加到训练集\n",
                "train_data = pd.concat([original_train, augmented_data])\n",
                "\n",
                "# 4. 准备特征和标签\n",
                "X_train = train_data.drop(['variable', 'dataset', 'label', 'y'], axis=1)\n",
                "y_train = train_data['y']\n",
                "\n",
                "X_val = original_val.drop(['variable', 'dataset', 'label', 'y'], axis=1)\n",
                "y_val = original_val['y']\n",
                "\n",
                "# 5. 训练随机森林模型\n",
                "rf_model = RandomForestClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=13,\n",
                "    n_jobs=-1,\n",
                "    class_weight=\"balanced\",\n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "rf_model.fit(X_train, y_train)\n",
                "\n",
                "# 6. 在验证集上评估模型\n",
                "y_val_pred = rf_model.predict(X_val)\n",
                "val_accuracy = balanced_accuracy_score(y_val, y_val_pred)\n",
                "\n",
                "print(f\"Validation Balanced Accuracy: {val_accuracy:.4f}\")\n",
                "\n",
                "# 7. 如果需要，可以在全部数据上重新训练模型\n",
                "rf_model_final = RandomForestClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=13,\n",
                "    n_jobs=-1,\n",
                "    class_weight=\"balanced\",\n",
                "    random_state=42\n",
                ")\n",
                "\n",
                "X_all = X_y_group_train.drop(['variable', 'dataset', 'label', 'y'], axis=1)\n",
                "y_all = X_y_group_train['y']\n",
                "\n",
                "rf_model_final.fit(X_all, y_all)\n",
                "\n",
                "# 8. 保存最终模型\n",
                "import joblib\n",
                "joblib.dump(rf_model_final, 'random_forest_model_final.joblib')\n",
                "\n",
                "print(\"Final model trained on all data and saved.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2024-09-18T09:40:09.797137Z",
                    "start_time": "2024-09-18T09:39:33.165697Z"
                },
                "metadata": {}
            },
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-1 {\n",
                            "  /* Definition of color scheme common for light and dark mode */\n",
                            "  --sklearn-color-text: black;\n",
                            "  --sklearn-color-line: gray;\n",
                            "  /* Definition of color scheme for unfitted estimators */\n",
                            "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
                            "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
                            "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
                            "  --sklearn-color-unfitted-level-3: chocolate;\n",
                            "  /* Definition of color scheme for fitted estimators */\n",
                            "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
                            "  --sklearn-color-fitted-level-1: #d4ebff;\n",
                            "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
                            "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
                            "\n",
                            "  /* Specific color for light theme */\n",
                            "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                            "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
                            "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                            "  --sklearn-color-icon: #696969;\n",
                            "\n",
                            "  @media (prefers-color-scheme: dark) {\n",
                            "    /* Redefinition of color scheme for dark theme */\n",
                            "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                            "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
                            "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                            "    --sklearn-color-icon: #878787;\n",
                            "  }\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 pre {\n",
                            "  padding: 0;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 input.sk-hidden--visually {\n",
                            "  border: 0;\n",
                            "  clip: rect(1px 1px 1px 1px);\n",
                            "  clip: rect(1px, 1px, 1px, 1px);\n",
                            "  height: 1px;\n",
                            "  margin: -1px;\n",
                            "  overflow: hidden;\n",
                            "  padding: 0;\n",
                            "  position: absolute;\n",
                            "  width: 1px;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-dashed-wrapped {\n",
                            "  border: 1px dashed var(--sklearn-color-line);\n",
                            "  margin: 0 0.4em 0.5em 0.4em;\n",
                            "  box-sizing: border-box;\n",
                            "  padding-bottom: 0.4em;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-container {\n",
                            "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
                            "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
                            "     so we also need the `!important` here to be able to override the\n",
                            "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
                            "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
                            "  display: inline-block !important;\n",
                            "  position: relative;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-text-repr-fallback {\n",
                            "  display: none;\n",
                            "}\n",
                            "\n",
                            "div.sk-parallel-item,\n",
                            "div.sk-serial,\n",
                            "div.sk-item {\n",
                            "  /* draw centered vertical line to link estimators */\n",
                            "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
                            "  background-size: 2px 100%;\n",
                            "  background-repeat: no-repeat;\n",
                            "  background-position: center center;\n",
                            "}\n",
                            "\n",
                            "/* Parallel-specific style estimator block */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item::after {\n",
                            "  content: \"\";\n",
                            "  width: 100%;\n",
                            "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
                            "  flex-grow: 1;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel {\n",
                            "  display: flex;\n",
                            "  align-items: stretch;\n",
                            "  justify-content: center;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  position: relative;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
                            "  align-self: flex-end;\n",
                            "  width: 50%;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
                            "  align-self: flex-start;\n",
                            "  width: 50%;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
                            "  width: 0;\n",
                            "}\n",
                            "\n",
                            "/* Serial-specific style estimator block */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-serial {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "  align-items: center;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  padding-right: 1em;\n",
                            "  padding-left: 1em;\n",
                            "}\n",
                            "\n",
                            "\n",
                            "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
                            "clickable and can be expanded/collapsed.\n",
                            "- Pipeline and ColumnTransformer use this feature and define the default style\n",
                            "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
                            "*/\n",
                            "\n",
                            "/* Pipeline and ColumnTransformer style (default) */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable {\n",
                            "  /* Default theme specific background. It is overwritten whether we have a\n",
                            "  specific estimator or a Pipeline/ColumnTransformer */\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "}\n",
                            "\n",
                            "/* Toggleable label */\n",
                            "#sk-container-id-1 label.sk-toggleable__label {\n",
                            "  cursor: pointer;\n",
                            "  display: block;\n",
                            "  width: 100%;\n",
                            "  margin-bottom: 0;\n",
                            "  padding: 0.5em;\n",
                            "  box-sizing: border-box;\n",
                            "  text-align: center;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
                            "  /* Arrow on the left of the label */\n",
                            "  content: \"▸\";\n",
                            "  float: left;\n",
                            "  margin-right: 0.25em;\n",
                            "  color: var(--sklearn-color-icon);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "}\n",
                            "\n",
                            "/* Toggleable content - dropdown */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable__content {\n",
                            "  max-height: 0;\n",
                            "  max-width: 0;\n",
                            "  overflow: hidden;\n",
                            "  text-align: left;\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable__content pre {\n",
                            "  margin: 0.2em;\n",
                            "  border-radius: 0.25em;\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
                            "  /* Expand drop-down */\n",
                            "  max-height: 200px;\n",
                            "  max-width: 100%;\n",
                            "  overflow: auto;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
                            "  content: \"▾\";\n",
                            "}\n",
                            "\n",
                            "/* Pipeline/ColumnTransformer-specific style */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Estimator-specific style */\n",
                            "\n",
                            "/* Colorize estimator box */\n",
                            "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
                            "#sk-container-id-1 div.sk-label label {\n",
                            "  /* The background is the default theme color */\n",
                            "  color: var(--sklearn-color-text-on-default-background);\n",
                            "}\n",
                            "\n",
                            "/* On hover, darken the color of the background */\n",
                            "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Label box, darken color on hover, fitted */\n",
                            "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Estimator label */\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label label {\n",
                            "  font-family: monospace;\n",
                            "  font-weight: bold;\n",
                            "  display: inline-block;\n",
                            "  line-height: 1.2em;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-label-container {\n",
                            "  text-align: center;\n",
                            "}\n",
                            "\n",
                            "/* Estimator-specific */\n",
                            "#sk-container-id-1 div.sk-estimator {\n",
                            "  font-family: monospace;\n",
                            "  border: 1px dotted var(--sklearn-color-border-box);\n",
                            "  border-radius: 0.25em;\n",
                            "  box-sizing: border-box;\n",
                            "  margin-bottom: 0.5em;\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-estimator.fitted {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "/* on hover */\n",
                            "#sk-container-id-1 div.sk-estimator:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
                            "\n",
                            "/* Common style for \"i\" and \"?\" */\n",
                            "\n",
                            ".sk-estimator-doc-link,\n",
                            "a:link.sk-estimator-doc-link,\n",
                            "a:visited.sk-estimator-doc-link {\n",
                            "  float: right;\n",
                            "  font-size: smaller;\n",
                            "  line-height: 1em;\n",
                            "  font-family: monospace;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  border-radius: 1em;\n",
                            "  height: 1em;\n",
                            "  width: 1em;\n",
                            "  text-decoration: none !important;\n",
                            "  margin-left: 1ex;\n",
                            "  /* unfitted */\n",
                            "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-unfitted-level-1);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link.fitted,\n",
                            "a:link.sk-estimator-doc-link.fitted,\n",
                            "a:visited.sk-estimator-doc-link.fitted {\n",
                            "  /* fitted */\n",
                            "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-fitted-level-1);\n",
                            "}\n",
                            "\n",
                            "/* On hover */\n",
                            "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
                            ".sk-estimator-doc-link:hover,\n",
                            "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
                            ".sk-estimator-doc-link:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
                            ".sk-estimator-doc-link.fitted:hover,\n",
                            "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
                            ".sk-estimator-doc-link.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "/* Span, style for the box shown on hovering the info icon */\n",
                            ".sk-estimator-doc-link span {\n",
                            "  display: none;\n",
                            "  z-index: 9999;\n",
                            "  position: relative;\n",
                            "  font-weight: normal;\n",
                            "  right: .2ex;\n",
                            "  padding: .5ex;\n",
                            "  margin: .5ex;\n",
                            "  width: min-content;\n",
                            "  min-width: 20ex;\n",
                            "  max-width: 50ex;\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  box-shadow: 2pt 2pt 4pt #999;\n",
                            "  /* unfitted */\n",
                            "  background: var(--sklearn-color-unfitted-level-0);\n",
                            "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link.fitted span {\n",
                            "  /* fitted */\n",
                            "  background: var(--sklearn-color-fitted-level-0);\n",
                            "  border: var(--sklearn-color-fitted-level-3);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link:hover span {\n",
                            "  display: block;\n",
                            "}\n",
                            "\n",
                            "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
                            "\n",
                            "#sk-container-id-1 a.estimator_doc_link {\n",
                            "  float: right;\n",
                            "  font-size: 1rem;\n",
                            "  line-height: 1em;\n",
                            "  font-family: monospace;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  border-radius: 1rem;\n",
                            "  height: 1rem;\n",
                            "  width: 1rem;\n",
                            "  text-decoration: none;\n",
                            "  /* unfitted */\n",
                            "  color: var(--sklearn-color-unfitted-level-1);\n",
                            "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
                            "  /* fitted */\n",
                            "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-fitted-level-1);\n",
                            "}\n",
                            "\n",
                            "/* On hover */\n",
                            "#sk-container-id-1 a.estimator_doc_link:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-3);\n",
                            "}\n",
                            "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=13, n_jobs=-1,\n",
                            "                       random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link \" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>RandomForestClassifier(class_weight=&#x27;balanced&#x27;, max_depth=13, n_jobs=-1,\n",
                            "                       random_state=42)</pre></div> </div></div></div></div>"
                        ],
                        "text/plain": [
                            "RandomForestClassifier(class_weight='balanced', max_depth=13, n_jobs=-1,\n",
                            "                       random_state=42)"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "multiclass balanced accuracy: mean=0.4811998421393201\n"
                    ]
                }
            ],
            "source": [
                "model = RandomForestClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=13,\n",
                "    n_jobs=-1,\n",
                "    class_weight=\"balanced\",\n",
                "    random_state=42\n",
                ")\n",
                "display(model)\n",
                "\n",
                "cv = GroupKFold(n_splits=4)\n",
                "results = cross_val_score(\n",
                "    model,\n",
                "    X_train,\n",
                "    y_train,\n",
                "    groups=group_train,\n",
                "    cv=cv,\n",
                "    verbose=True,\n",
                "    scoring=\"balanced_accuracy\"\n",
                ")\n",
                "\n",
                "print(f\"multiclass balanced accuracy: mean={results.mean()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "ename": "KeyError",
                    "evalue": "\"None of [Index([     8,      9,     10,     11,     12,     13,     14,     15,     16,\\n           17,\\n       ...\\n       284501, 284502, 284503, 284504, 284505, 284506, 284507, 284508, 284509,\\n       284510],\\n      dtype='int64', length=213388)] are in the [columns]\"",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[18], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# 在最佳折叠上训练模型\u001b[39;00m\n\u001b[0;32m     23\u001b[0m train_index, val_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X_train, y_train, groups\u001b[38;5;241m=\u001b[39mgroup_train))[best_fold_index]\n\u001b[1;32m---> 24\u001b[0m X_train_best, X_val_best \u001b[38;5;241m=\u001b[39m \u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m, X_train[val_index]\n\u001b[0;32m     25\u001b[0m y_train_best, y_val_best \u001b[38;5;241m=\u001b[39m y_train[train_index], y_train[val_index]\n\u001b[0;32m     27\u001b[0m best_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\n\u001b[0;32m     28\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     29\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m13\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     32\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m     33\u001b[0m )\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "\u001b[1;31mKeyError\u001b[0m: \"None of [Index([     8,      9,     10,     11,     12,     13,     14,     15,     16,\\n           17,\\n       ...\\n       284501, 284502, 284503, 284504, 284505, 284506, 284507, 284508, 284509,\\n       284510],\\n      dtype='int64', length=213388)] are in the [columns]\""
                    ]
                }
            ],
            "source": [
                "from sklearn.model_selection import cross_val_predict\n",
                "from sklearn.metrics import balanced_accuracy_score\n",
                "\n",
                "# ... 现有的模型定义代码 ...\n",
                "\n",
                "cv = GroupKFold(n_splits=4)\n",
                "\n",
                "# 使用cross_val_predict获取每个折叠的预测结果\n",
                "y_pred = cross_val_predict(model, X_train, y_train, groups=group_train, cv=cv, n_jobs=-1)\n",
                "\n",
                "# 计算每个折叠的平衡准确率\n",
                "fold_scores = []\n",
                "for train_index, val_index in cv.split(X_train, y_train, groups=group_train):\n",
                "    y_true_fold = y_train[val_index]\n",
                "    y_pred_fold = y_pred[val_index]\n",
                "    fold_score = balanced_accuracy_score(y_true_fold, y_pred_fold)\n",
                "    fold_scores.append(fold_score)\n",
                "\n",
                "# 找出最佳折叠的索引\n",
                "best_fold_index = fold_scores.index(max(fold_scores))\n",
                "\n",
                "# 在最佳折叠上训练模型\n",
                "train_index, val_index = list(cv.split(X_train, y_train, groups=group_train))[best_fold_index]\n",
                "X_train_best, X_val_best = X_train[train_index], X_train[val_index]\n",
                "y_train_best, y_val_best = y_train[train_index], y_train[val_index]\n",
                "\n",
                "best_model = RandomForestClassifier(\n",
                "    n_estimators=100,\n",
                "    max_depth=13,\n",
                "    n_jobs=-1,\n",
                "    class_weight=\"balanced\",\n",
                "    random_state=42\n",
                ")\n",
                "best_model.fit(X_train_best, y_train_best)\n",
                "\n",
                "# 保存最佳模型\n",
                "import joblib\n",
                "joblib.dump(best_model, 'best_random_forest_model.joblib')\n",
                "\n",
                "print(f\"Best fold balanced accuracy: {max(fold_scores)}\")\n",
                "print(f\"Average balanced accuracy: {sum(fold_scores) / len(fold_scores)}\")\n",
                "print(\"Best model saved as 'best_random_forest_model.joblib'\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {
                "ExecuteTime": {
                    "end_time": "2024-09-18T09:40:12.546163Z",
                    "start_time": "2024-09-18T09:40:12.539944Z"
                },
                "metadata": {}
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "multiclass balanced accuracy: mean=0.46912448749447283\n"
                    ]
                }
            ],
            "source": [
                "print(f\"multiclass balanced accuracy: mean={results.mean()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "image/png": "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",
                        "text/plain": [
                            "<Figure size 1200x600 with 1 Axes>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Accuracies for each dimension:\n",
                        "Dimension 1: Accuracy = 0.5423\n",
                        "Dimension 2: Accuracy = 0.4064\n",
                        "Dimension 3: Accuracy = 0.3934\n",
                        "Dimension 4: Accuracy = 0.4039\n",
                        "Dimension 5: Accuracy = 0.4342\n",
                        "Dimension 6: Accuracy = 0.5074\n",
                        "Dimension 7: Accuracy = 0.5897\n",
                        "Dimension 8: Accuracy = 0.6378\n",
                        "\n",
                        "Overall Accuracy: 0.5789\n",
                        "\n",
                        "Top 20 most important features:\n",
                        "                           feature  importance\n",
                        "32                       dcor(v,X)    0.107233\n",
                        "41                 v~Y_coefficient    0.055358\n",
                        "33                       dcor(v,Y)    0.054612\n",
                        "11                         MI(v,X)    0.043007\n",
                        "46           v~Y_ridge_coefficient    0.041596\n",
                        "52                       MI(v,X)^2    0.041122\n",
                        "8             25%(corr(v, others))    0.031385\n",
                        "35           conditional_MI(v,X|Y)    0.030447\n",
                        "53                       MI(v,Y)^2    0.028371\n",
                        "36           conditional_MI(v,Y|X)    0.026773\n",
                        "12                         MI(v,Y)    0.026611\n",
                        "39             partial_corr(v,Y|X)    0.025058\n",
                        "37           conditional_MI(X,Y|v)    0.023244\n",
                        "38             partial_corr(v,X|Y)    0.020115\n",
                        "2                        corr(v,X)    0.018131\n",
                        "18              spearman_corr(v,X)    0.017354\n",
                        "25               kendall_corr(v,X)    0.016279\n",
                        "43                 v~X_coefficient    0.016058\n",
                        "47           v~X_ridge_coefficient    0.015757\n",
                        "0                        dimension    0.015442\n",
                        "1                 square_dimension    0.014498\n",
                        "9             75%(corr(v, others))    0.014087\n",
                        "26               kendall_corr(v,Y)    0.013212\n",
                        "3                        corr(v,Y)    0.012104\n",
                        "19              spearman_corr(v,Y)    0.011836\n",
                        "54                       MI(X,Y)^2    0.011759\n",
                        "17                         MI(X,Y)    0.011677\n",
                        "22  mean(spearman_corr(v, others))    0.011108\n",
                        "55            max(MI(v, others))^2    0.010541\n",
                        "15             mean(MI(v, others))    0.010528\n",
                        "5             min(corr(v, others))    0.010528\n",
                        "13              max(MI(v, others))    0.010492\n",
                        "16              std(MI(v, others))    0.010450\n",
                        "21   min(spearman_corr(v, others))    0.010345\n",
                        "28    min(kendall_corr(v, others))    0.010129\n",
                        "14              min(MI(v, others))    0.010052\n",
                        "56            min(MI(v, others))^2    0.009879\n",
                        "6            mean(corr(v, others))    0.009685\n",
                        "50                 noise_count_0.3    0.009305\n",
                        "34                       dcor(X,Y)    0.009252\n",
                        "42         v_squared~Y_coefficient    0.009186\n",
                        "44         v_squared~X_coefficient    0.008737\n",
                        "27    max(kendall_corr(v, others))    0.008687\n",
                        "29   mean(kendall_corr(v, others))    0.008675\n",
                        "4             max(corr(v, others))    0.008455\n",
                        "20   max(spearman_corr(v, others))    0.007915\n",
                        "30    std(kendall_corr(v, others))    0.007558\n",
                        "7             std(corr(v, others))    0.007541\n",
                        "51           density_variation_0.3    0.007458\n",
                        "45                 X~Y_coefficient    0.007357\n",
                        "23   std(spearman_corr(v, others))    0.007338\n",
                        "48           X~Y_ridge_coefficient    0.007064\n",
                        "40             partial_corr(X,Y|v)    0.006992\n",
                        "49               cluster_count_0.3    0.005531\n",
                        "31               kendall_corr(X,Y)    0.005444\n",
                        "24              spearman_corr(X,Y)    0.005347\n",
                        "10                       corr(X,Y)    0.005295\n",
                        "\n",
                        "Model and feature importances have been saved.\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "\n",
                "X = X_train\n",
                "y = y_train\n",
                "# Assuming X and y are your features and target variables\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "\n",
                "# Fit the model\n",
                "model.fit(X_train, y_train)\n",
                "\n",
                "# Get predictions\n",
                "y_pred = model.predict(X_test)\n",
                "\n",
                "\n",
                "# Calculate accuracy for each dimension\n",
                "dimensions = sorted(X_test['dimension'].unique())\n",
                "accuracies = []\n",
                "\n",
                "for dim in dimensions:\n",
                "    mask = X_test['dimension'] == dim\n",
                "    y_true_dim = y_test[mask]\n",
                "    y_pred_dim = y_pred[mask]\n",
                "    acc = accuracy_score(y_true_dim, y_pred_dim)\n",
                "    accuracies.append(acc)\n",
                "\n",
                "# Visualize the results\n",
                "plt.figure(figsize=(12, 6))\n",
                "plt.plot(dimensions, accuracies, marker='o')\n",
                "plt.xlabel('Dimension')\n",
                "plt.ylabel('Accuracy')\n",
                "plt.title('Model Accuracy vs Dimension')\n",
                "plt.grid(True)\n",
                "plt.xticks(dimensions)  # Ensure all dimensions are shown on x-axis\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "# Print accuracies\n",
                "print(\"Accuracies for each dimension:\")\n",
                "for dim, acc in zip(dimensions, accuracies):\n",
                "    print(f\"Dimension {dim}: Accuracy = {acc:.4f}\")\n",
                "\n",
                "# Calculate and print overall accuracy\n",
                "overall_accuracy = accuracy_score(y_test, y_pred)\n",
                "print(f\"\\nOverall Accuracy: {overall_accuracy:.4f}\")\n",
                "\n",
                "# Get feature importances\n",
                "importances = model.feature_importances_\n",
                "feature_importances = pd.DataFrame({'feature': X_train.columns, 'importance': importances})\n",
                "feature_importances = feature_importances.sort_values('importance', ascending=False)\n",
                "\n",
                "# Display top 20 most important features\n",
                "print(\"\\nTop 20 most important features:\")\n",
                "print(feature_importances)\n",
                "\n",
                "# Save the model\n",
                "import joblib\n",
                "joblib.dump(model, './resources/random_forest_model_v1.joblib')\n",
                "\n",
                "print(\"\\nModel and feature importances have been saved.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "e:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:82: UserWarning: Device used : cuda\n",
                        "  warnings.warn(f\"Device used : {self.device}\")\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "epoch 0  | loss: 1.98184 | val_balanced_accuracy: 0.21751 |  0:00:08s\n",
                        "epoch 1  | loss: 1.61436 | val_balanced_accuracy: 0.22969 |  0:00:17s\n",
                        "epoch 2  | loss: 1.57693 | val_balanced_accuracy: 0.35237 |  0:00:26s\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[18], line 49\u001b[0m\n\u001b[0;32m     27\u001b[0m tabnet_model \u001b[38;5;241m=\u001b[39m TabNetClassifier(\n\u001b[0;32m     28\u001b[0m     n_d\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,  \u001b[38;5;66;03m# 决策步骤的维度\u001b[39;00m\n\u001b[0;32m     29\u001b[0m     n_a\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,  \u001b[38;5;66;03m# 注意力步骤的维度\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m     device_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     46\u001b[0m )\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# 训练模型\u001b[39;00m\n\u001b[1;32m---> 49\u001b[0m \u001b[43mtabnet_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbalanced_accuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvirtual_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_last\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     62\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# 打印训练结果\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtabnet_model\u001b[38;5;241m.\u001b[39mbest_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:258\u001b[0m, in \u001b[0;36mTabModel.fit\u001b[1;34m(self, X_train, y_train, eval_set, eval_name, eval_metric, loss_fn, weights, max_epochs, patience, batch_size, virtual_batch_size, num_workers, drop_last, callbacks, pin_memory, from_unsupervised, warm_start, augmentations, compute_importance)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs):\n\u001b[0;32m    254\u001b[0m \n\u001b[0;32m    255\u001b[0m     \u001b[38;5;66;03m# Call method on_epoch_begin for all callbacks\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch_idx)\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;66;03m# Apply predict epoch to all eval sets\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m eval_name, valid_dataloader \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(eval_names, valid_dataloaders):\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:489\u001b[0m, in \u001b[0;36mTabModel._train_epoch\u001b[1;34m(self, train_loader)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (X, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[0;32m    487\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_batch_begin(batch_idx)\n\u001b[1;32m--> 489\u001b[0m     batch_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    491\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_container\u001b[38;5;241m.\u001b[39mon_batch_end(batch_idx, batch_logs)\n\u001b[0;32m    493\u001b[0m epoch_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:527\u001b[0m, in \u001b[0;36mTabModel._train_batch\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[0;32m    525\u001b[0m     param\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 527\u001b[0m output, M_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    529\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(output, y)\n\u001b[0;32m    530\u001b[0m \u001b[38;5;66;03m# Add the overall sparsity loss\u001b[39;00m\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\pytorch_tabnet\\tab_network.py:616\u001b[0m, in \u001b[0;36mTabNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    615\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedder(x)\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtabnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\pytorch_tabnet\\tab_network.py:492\u001b[0m, in \u001b[0;36mTabNetNoEmbeddings.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    491\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 492\u001b[0m     steps_output, M_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m     res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mstack(steps_output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    495\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_multi_task:\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;66;03m# Result will be in list format\u001b[39;00m\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\pytorch_tabnet\\tab_network.py:169\u001b[0m, in \u001b[0;36mTabNetEncoder.forward\u001b[1;34m(self, x, prior)\u001b[0m\n\u001b[0;32m    166\u001b[0m     prior \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((bs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention_dim))\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    168\u001b[0m M_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 169\u001b[0m att \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitial_splitter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_d :]\n\u001b[0;32m    170\u001b[0m steps_output \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps):\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\pytorch_tabnet\\tab_network.py:737\u001b[0m, in \u001b[0;36mFeatTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 737\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshared\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecifics(x)\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\pytorch_tabnet\\tab_network.py:774\u001b[0m, in \u001b[0;36mGLU_Block.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    772\u001b[0m scale \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(torch\u001b[38;5;241m.\u001b[39mFloatTensor([\u001b[38;5;241m0.5\u001b[39m])\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m    773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst:  \u001b[38;5;66;03m# the first layer of the block has no scale multiplication\u001b[39;00m\n\u001b[1;32m--> 774\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglu_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    775\u001b[0m     layers_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_glu)\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\pytorch_tabnet\\tab_network.py:804\u001b[0m, in \u001b[0;36mGLU_Layer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m    803\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n\u001b[1;32m--> 804\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    805\u001b[0m     out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmul(x[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim], torch\u001b[38;5;241m.\u001b[39msigmoid(x[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_dim :]))\n\u001b[0;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\pytorch_tabnet\\tab_network.py:36\u001b[0m, in \u001b[0;36mGBN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     35\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvirtual_batch_size)), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m     res \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn(x_) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(res, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\pytorch_tabnet\\tab_network.py:36\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     35\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;28mint\u001b[39m(np\u001b[38;5;241m.\u001b[39mceil(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvirtual_batch_size)), \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 36\u001b[0m     res \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(res, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:176\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    169\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\torch\\nn\\functional.py:2512\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2509\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2510\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2513\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[0;32m   2514\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import balanced_accuracy_score\n",
                "from pytorch_tabnet.tab_model import TabNetClassifier\n",
                "import torch\n",
                "import re\n",
                "# 假设 X_train, y_train 已经准备好\n",
                "\n",
                "# 清理特征名称\n",
                "def clean_feature_names(X):\n",
                "    def clean_name(name):\n",
                "        name = re.sub(r'[^\\w\\s-]', '_', name)\n",
                "        if name[0].isdigit():\n",
                "            name = 'f_' + name\n",
                "        return name\n",
                "    \n",
                "    X.columns = [clean_name(col) for col in X.columns]\n",
                "    return X\n",
                "\n",
                "X_train = clean_feature_names(X_train)\n",
                "\n",
                "# 划分训练集和验证集\n",
                "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
                "\n",
                "# 创建TabNet模型\n",
                "tabnet_model = TabNetClassifier(\n",
                "    n_d=64,  # 决策步骤的维度\n",
                "    n_a=64,  # 注意力步骤的维度\n",
                "    n_steps=5,  # 总共的决策步骤数\n",
                "    gamma=1.5,  # 控制稀疏性的参数\n",
                "    n_independent=2,  # 每个步骤的独立层数\n",
                "    n_shared=2,  # 共享层数\n",
                "    cat_idxs=[],  # 分类特征的索引\n",
                "    cat_dims=[],  # 每个分类特征的唯一值数量\n",
                "    cat_emb_dim=[],  # 每个分类特征的嵌入维度\n",
                "    lambda_sparse=1e-3,  # L1正则化参数\n",
                "    optimizer_fn=torch.optim.Adam,\n",
                "    optimizer_params=dict(lr=2e-2),\n",
                "    scheduler_params=dict(\n",
                "        mode=\"min\", patience=5, min_lr=1e-5, factor=0.5\n",
                "    ),\n",
                "    scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
                "    mask_type=\"entmax\",  # \"sparsemax\" or \"entmax\"\n",
                "    device_name='cuda' if torch.cuda.is_available() else 'cpu'\n",
                ")\n",
                "\n",
                "# 训练模型\n",
                "tabnet_model.fit(\n",
                "    X_train=X_train.values, \n",
                "    y_train=y_train.values,\n",
                "    eval_set=[(X_val.values, y_val.values)],\n",
                "    eval_name=['val'],\n",
                "    eval_metric=['balanced_accuracy'],\n",
                "    max_epochs=100,\n",
                "    patience=10,\n",
                "    batch_size=1024,\n",
                "    virtual_batch_size=256,\n",
                "    num_workers=0,\n",
                "    weights=1,\n",
                "    drop_last=False\n",
                ")\n",
                "\n",
                "# 打印训练结果\n",
                "print(f\"Best epoch: {tabnet_model.best_epoch}\")\n",
                "print(f\"Best validation balanced accuracy: {tabnet_model.best_cost}\")\n",
                "\n",
                "# 在训练集和验证集上评估模型\n",
                "y_train_pred = tabnet_model.predict(X_train.values)\n",
                "y_val_pred = tabnet_model.predict(X_val.values)\n",
                "\n",
                "train_accuracy = balanced_accuracy_score(y_train, y_train_pred)\n",
                "val_accuracy = balanced_accuracy_score(y_val, y_val_pred)\n",
                "\n",
                "print(f\"Train balanced accuracy: {train_accuracy:.4f}\")\n",
                "print(f\"Validation balanced accuracy: {val_accuracy:.4f}\")\n",
                "\n",
                "# 保存模型\n",
                "import joblib\n",
                "# joblib.dump(tabnet_model, './resources/tabnet_model_v0.joblib')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style>#sk-container-id-2 {\n",
                            "  /* Definition of color scheme common for light and dark mode */\n",
                            "  --sklearn-color-text: black;\n",
                            "  --sklearn-color-line: gray;\n",
                            "  /* Definition of color scheme for unfitted estimators */\n",
                            "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
                            "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
                            "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
                            "  --sklearn-color-unfitted-level-3: chocolate;\n",
                            "  /* Definition of color scheme for fitted estimators */\n",
                            "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
                            "  --sklearn-color-fitted-level-1: #d4ebff;\n",
                            "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
                            "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
                            "\n",
                            "  /* Specific color for light theme */\n",
                            "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                            "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
                            "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
                            "  --sklearn-color-icon: #696969;\n",
                            "\n",
                            "  @media (prefers-color-scheme: dark) {\n",
                            "    /* Redefinition of color scheme for dark theme */\n",
                            "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                            "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
                            "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
                            "    --sklearn-color-icon: #878787;\n",
                            "  }\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 pre {\n",
                            "  padding: 0;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 input.sk-hidden--visually {\n",
                            "  border: 0;\n",
                            "  clip: rect(1px 1px 1px 1px);\n",
                            "  clip: rect(1px, 1px, 1px, 1px);\n",
                            "  height: 1px;\n",
                            "  margin: -1px;\n",
                            "  overflow: hidden;\n",
                            "  padding: 0;\n",
                            "  position: absolute;\n",
                            "  width: 1px;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-dashed-wrapped {\n",
                            "  border: 1px dashed var(--sklearn-color-line);\n",
                            "  margin: 0 0.4em 0.5em 0.4em;\n",
                            "  box-sizing: border-box;\n",
                            "  padding-bottom: 0.4em;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-container {\n",
                            "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
                            "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
                            "     so we also need the `!important` here to be able to override the\n",
                            "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
                            "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
                            "  display: inline-block !important;\n",
                            "  position: relative;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-text-repr-fallback {\n",
                            "  display: none;\n",
                            "}\n",
                            "\n",
                            "div.sk-parallel-item,\n",
                            "div.sk-serial,\n",
                            "div.sk-item {\n",
                            "  /* draw centered vertical line to link estimators */\n",
                            "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
                            "  background-size: 2px 100%;\n",
                            "  background-repeat: no-repeat;\n",
                            "  background-position: center center;\n",
                            "}\n",
                            "\n",
                            "/* Parallel-specific style estimator block */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel-item::after {\n",
                            "  content: \"\";\n",
                            "  width: 100%;\n",
                            "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
                            "  flex-grow: 1;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel {\n",
                            "  display: flex;\n",
                            "  align-items: stretch;\n",
                            "  justify-content: center;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  position: relative;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel-item {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
                            "  align-self: flex-end;\n",
                            "  width: 50%;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
                            "  align-self: flex-start;\n",
                            "  width: 50%;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
                            "  width: 0;\n",
                            "}\n",
                            "\n",
                            "/* Serial-specific style estimator block */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-serial {\n",
                            "  display: flex;\n",
                            "  flex-direction: column;\n",
                            "  align-items: center;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  padding-right: 1em;\n",
                            "  padding-left: 1em;\n",
                            "}\n",
                            "\n",
                            "\n",
                            "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
                            "clickable and can be expanded/collapsed.\n",
                            "- Pipeline and ColumnTransformer use this feature and define the default style\n",
                            "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
                            "*/\n",
                            "\n",
                            "/* Pipeline and ColumnTransformer style (default) */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-toggleable {\n",
                            "  /* Default theme specific background. It is overwritten whether we have a\n",
                            "  specific estimator or a Pipeline/ColumnTransformer */\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "}\n",
                            "\n",
                            "/* Toggleable label */\n",
                            "#sk-container-id-2 label.sk-toggleable__label {\n",
                            "  cursor: pointer;\n",
                            "  display: block;\n",
                            "  width: 100%;\n",
                            "  margin-bottom: 0;\n",
                            "  padding: 0.5em;\n",
                            "  box-sizing: border-box;\n",
                            "  text-align: center;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
                            "  /* Arrow on the left of the label */\n",
                            "  content: \"▸\";\n",
                            "  float: left;\n",
                            "  margin-right: 0.25em;\n",
                            "  color: var(--sklearn-color-icon);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "}\n",
                            "\n",
                            "/* Toggleable content - dropdown */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-toggleable__content {\n",
                            "  max-height: 0;\n",
                            "  max-width: 0;\n",
                            "  overflow: hidden;\n",
                            "  text-align: left;\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-toggleable__content pre {\n",
                            "  margin: 0.2em;\n",
                            "  border-radius: 0.25em;\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
                            "  /* Expand drop-down */\n",
                            "  max-height: 200px;\n",
                            "  max-width: 100%;\n",
                            "  overflow: auto;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
                            "  content: \"▾\";\n",
                            "}\n",
                            "\n",
                            "/* Pipeline/ColumnTransformer-specific style */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Estimator-specific style */\n",
                            "\n",
                            "/* Colorize estimator box */\n",
                            "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
                            "#sk-container-id-2 div.sk-label label {\n",
                            "  /* The background is the default theme color */\n",
                            "  color: var(--sklearn-color-text-on-default-background);\n",
                            "}\n",
                            "\n",
                            "/* On hover, darken the color of the background */\n",
                            "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Label box, darken color on hover, fitted */\n",
                            "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Estimator label */\n",
                            "\n",
                            "#sk-container-id-2 div.sk-label label {\n",
                            "  font-family: monospace;\n",
                            "  font-weight: bold;\n",
                            "  display: inline-block;\n",
                            "  line-height: 1.2em;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-label-container {\n",
                            "  text-align: center;\n",
                            "}\n",
                            "\n",
                            "/* Estimator-specific */\n",
                            "#sk-container-id-2 div.sk-estimator {\n",
                            "  font-family: monospace;\n",
                            "  border: 1px dotted var(--sklearn-color-border-box);\n",
                            "  border-radius: 0.25em;\n",
                            "  box-sizing: border-box;\n",
                            "  margin-bottom: 0.5em;\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-0);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-estimator.fitted {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-0);\n",
                            "}\n",
                            "\n",
                            "/* on hover */\n",
                            "#sk-container-id-2 div.sk-estimator:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-2);\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-2);\n",
                            "}\n",
                            "\n",
                            "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
                            "\n",
                            "/* Common style for \"i\" and \"?\" */\n",
                            "\n",
                            ".sk-estimator-doc-link,\n",
                            "a:link.sk-estimator-doc-link,\n",
                            "a:visited.sk-estimator-doc-link {\n",
                            "  float: right;\n",
                            "  font-size: smaller;\n",
                            "  line-height: 1em;\n",
                            "  font-family: monospace;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  border-radius: 1em;\n",
                            "  height: 1em;\n",
                            "  width: 1em;\n",
                            "  text-decoration: none !important;\n",
                            "  margin-left: 1ex;\n",
                            "  /* unfitted */\n",
                            "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-unfitted-level-1);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link.fitted,\n",
                            "a:link.sk-estimator-doc-link.fitted,\n",
                            "a:visited.sk-estimator-doc-link.fitted {\n",
                            "  /* fitted */\n",
                            "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-fitted-level-1);\n",
                            "}\n",
                            "\n",
                            "/* On hover */\n",
                            "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
                            ".sk-estimator-doc-link:hover,\n",
                            "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
                            ".sk-estimator-doc-link:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
                            ".sk-estimator-doc-link.fitted:hover,\n",
                            "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
                            ".sk-estimator-doc-link.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "/* Span, style for the box shown on hovering the info icon */\n",
                            ".sk-estimator-doc-link span {\n",
                            "  display: none;\n",
                            "  z-index: 9999;\n",
                            "  position: relative;\n",
                            "  font-weight: normal;\n",
                            "  right: .2ex;\n",
                            "  padding: .5ex;\n",
                            "  margin: .5ex;\n",
                            "  width: min-content;\n",
                            "  min-width: 20ex;\n",
                            "  max-width: 50ex;\n",
                            "  color: var(--sklearn-color-text);\n",
                            "  box-shadow: 2pt 2pt 4pt #999;\n",
                            "  /* unfitted */\n",
                            "  background: var(--sklearn-color-unfitted-level-0);\n",
                            "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link.fitted span {\n",
                            "  /* fitted */\n",
                            "  background: var(--sklearn-color-fitted-level-0);\n",
                            "  border: var(--sklearn-color-fitted-level-3);\n",
                            "}\n",
                            "\n",
                            ".sk-estimator-doc-link:hover span {\n",
                            "  display: block;\n",
                            "}\n",
                            "\n",
                            "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
                            "\n",
                            "#sk-container-id-2 a.estimator_doc_link {\n",
                            "  float: right;\n",
                            "  font-size: 1rem;\n",
                            "  line-height: 1em;\n",
                            "  font-family: monospace;\n",
                            "  background-color: var(--sklearn-color-background);\n",
                            "  border-radius: 1rem;\n",
                            "  height: 1rem;\n",
                            "  width: 1rem;\n",
                            "  text-decoration: none;\n",
                            "  /* unfitted */\n",
                            "  color: var(--sklearn-color-unfitted-level-1);\n",
                            "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
                            "  /* fitted */\n",
                            "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
                            "  color: var(--sklearn-color-fitted-level-1);\n",
                            "}\n",
                            "\n",
                            "/* On hover */\n",
                            "#sk-container-id-2 a.estimator_doc_link:hover {\n",
                            "  /* unfitted */\n",
                            "  background-color: var(--sklearn-color-unfitted-level-3);\n",
                            "  color: var(--sklearn-color-background);\n",
                            "  text-decoration: none;\n",
                            "}\n",
                            "\n",
                            "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
                            "  /* fitted */\n",
                            "  background-color: var(--sklearn-color-fitted-level-3);\n",
                            "}\n",
                            "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, colsample_bytree=0.7, device=&#x27;gpu&#x27;,\n",
                            "               gpu_device_id=0, gpu_platform_id=1, learning_rate=0.01,\n",
                            "               max_depth=6, n_estimators=2000, n_jobs=-1, num_leaves=29,\n",
                            "               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.7)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator  sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label  sk-toggleable__label-arrow \">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link \">i<span>Not fitted</span></span></label><div class=\"sk-toggleable__content \"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, colsample_bytree=0.7, device=&#x27;gpu&#x27;,\n",
                            "               gpu_device_id=0, gpu_platform_id=1, learning_rate=0.01,\n",
                            "               max_depth=6, n_estimators=2000, n_jobs=-1, num_leaves=29,\n",
                            "               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.7)</pre></div> </div></div></div></div>"
                        ],
                        "text/plain": [
                            "LGBMClassifier(class_weight='balanced', colsample_bytree=0.7, device='gpu',\n",
                            "               gpu_device_id=0, gpu_platform_id=1, learning_rate=0.01,\n",
                            "               max_depth=6, n_estimators=2000, n_jobs=-1, num_leaves=29,\n",
                            "               random_state=42, reg_alpha=0.1, reg_lambda=0.1, subsample=0.7)"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
                        "[LightGBM] [Info] This is the GPU trainer!!\n",
                        "[LightGBM] [Info] Total Bins 7914\n",
                        "[LightGBM] [Info] Number of data points in the train set: 107040, number of used features: 32\n",
                        "[LightGBM] [Info] Using requested OpenCL platform 1 device 0\n",
                        "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation\n",
                        "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
                        "[LightGBM] [Info] GPU programs have been built\n",
                        "[LightGBM] [Info] Size of histogram bin entry: 8\n",
                        "[LightGBM] [Info] 30 dense feature groups (3.27 MB) transferred to GPU in 0.007782 secs. 1 sparse feature groups\n",
                        "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
                        "[LightGBM] [Info] Start training from score -2.079442\n",
                        "[LightGBM] [Info] Start training from score -2.079442\n",
                        "[LightGBM] [Info] Start training from score -2.079442\n",
                        "[LightGBM] [Info] Start training from score -2.079442\n",
                        "[LightGBM] [Info] Start training from score -2.079442\n",
                        "[LightGBM] [Info] Start training from score -2.079441\n",
                        "[LightGBM] [Info] Start training from score -2.079442\n",
                        "[LightGBM] [Info] Start training from score -2.079442\n",
                        "[1]\tvalid_0's multi_logloss: 2.06284\n",
                        "Training until validation scores don't improve for 10 rounds\n",
                        "[2]\tvalid_0's multi_logloss: 2.04686\n",
                        "[3]\tvalid_0's multi_logloss: 2.03166\n",
                        "[4]\tvalid_0's multi_logloss: 2.01618\n",
                        "[5]\tvalid_0's multi_logloss: 2.002\n",
                        "[6]\tvalid_0's multi_logloss: 1.98764\n",
                        "[7]\tvalid_0's multi_logloss: 1.97409\n",
                        "[8]\tvalid_0's multi_logloss: 1.96095\n",
                        "[9]\tvalid_0's multi_logloss: 1.94871\n",
                        "[10]\tvalid_0's multi_logloss: 1.93661\n",
                        "[11]\tvalid_0's multi_logloss: 1.92448\n",
                        "[12]\tvalid_0's multi_logloss: 1.91349\n",
                        "[13]\tvalid_0's multi_logloss: 1.90205\n",
                        "[14]\tvalid_0's multi_logloss: 1.89162\n",
                        "[15]\tvalid_0's multi_logloss: 1.88099\n",
                        "[16]\tvalid_0's multi_logloss: 1.87098\n",
                        "[17]\tvalid_0's multi_logloss: 1.86157\n",
                        "[18]\tvalid_0's multi_logloss: 1.85212\n",
                        "[19]\tvalid_0's multi_logloss: 1.84284\n",
                        "[20]\tvalid_0's multi_logloss: 1.83403\n",
                        "[21]\tvalid_0's multi_logloss: 1.8252\n",
                        "[22]\tvalid_0's multi_logloss: 1.81678\n",
                        "[23]\tvalid_0's multi_logloss: 1.80877\n",
                        "[24]\tvalid_0's multi_logloss: 1.80069\n",
                        "[25]\tvalid_0's multi_logloss: 1.79265\n",
                        "[26]\tvalid_0's multi_logloss: 1.78514\n",
                        "[27]\tvalid_0's multi_logloss: 1.77784\n",
                        "[28]\tvalid_0's multi_logloss: 1.77042\n",
                        "[29]\tvalid_0's multi_logloss: 1.76318\n",
                        "[30]\tvalid_0's multi_logloss: 1.75619\n",
                        "[31]\tvalid_0's multi_logloss: 1.74933\n",
                        "[32]\tvalid_0's multi_logloss: 1.7426\n",
                        "[33]\tvalid_0's multi_logloss: 1.73604\n",
                        "[34]\tvalid_0's multi_logloss: 1.7296\n",
                        "[35]\tvalid_0's multi_logloss: 1.72364\n",
                        "[36]\tvalid_0's multi_logloss: 1.71733\n",
                        "[37]\tvalid_0's multi_logloss: 1.71142\n",
                        "[38]\tvalid_0's multi_logloss: 1.70538\n",
                        "[39]\tvalid_0's multi_logloss: 1.69983\n",
                        "[40]\tvalid_0's multi_logloss: 1.69402\n",
                        "[41]\tvalid_0's multi_logloss: 1.68846\n",
                        "[42]\tvalid_0's multi_logloss: 1.68304\n",
                        "[43]\tvalid_0's multi_logloss: 1.67771\n",
                        "[44]\tvalid_0's multi_logloss: 1.67252\n",
                        "[45]\tvalid_0's multi_logloss: 1.6676\n",
                        "[46]\tvalid_0's multi_logloss: 1.6627\n",
                        "[47]\tvalid_0's multi_logloss: 1.65801\n",
                        "[48]\tvalid_0's multi_logloss: 1.65337\n",
                        "[49]\tvalid_0's multi_logloss: 1.6488\n",
                        "[50]\tvalid_0's multi_logloss: 1.6443\n",
                        "[51]\tvalid_0's multi_logloss: 1.63999\n",
                        "[52]\tvalid_0's multi_logloss: 1.6357\n",
                        "[53]\tvalid_0's multi_logloss: 1.63144\n",
                        "[54]\tvalid_0's multi_logloss: 1.62736\n",
                        "[55]\tvalid_0's multi_logloss: 1.6233\n",
                        "[56]\tvalid_0's multi_logloss: 1.61927\n",
                        "[57]\tvalid_0's multi_logloss: 1.61532\n",
                        "[58]\tvalid_0's multi_logloss: 1.61125\n",
                        "[59]\tvalid_0's multi_logloss: 1.60745\n",
                        "[60]\tvalid_0's multi_logloss: 1.60377\n",
                        "[61]\tvalid_0's multi_logloss: 1.60003\n",
                        "[62]\tvalid_0's multi_logloss: 1.59655\n",
                        "[63]\tvalid_0's multi_logloss: 1.593\n",
                        "[64]\tvalid_0's multi_logloss: 1.58946\n",
                        "[65]\tvalid_0's multi_logloss: 1.58608\n",
                        "[66]\tvalid_0's multi_logloss: 1.58265\n",
                        "[67]\tvalid_0's multi_logloss: 1.57931\n",
                        "[68]\tvalid_0's multi_logloss: 1.57597\n",
                        "[69]\tvalid_0's multi_logloss: 1.57276\n",
                        "[70]\tvalid_0's multi_logloss: 1.56959\n",
                        "[71]\tvalid_0's multi_logloss: 1.56638\n",
                        "[72]\tvalid_0's multi_logloss: 1.56339\n",
                        "[73]\tvalid_0's multi_logloss: 1.56045\n",
                        "[74]\tvalid_0's multi_logloss: 1.55741\n",
                        "[75]\tvalid_0's multi_logloss: 1.55441\n",
                        "[76]\tvalid_0's multi_logloss: 1.55153\n",
                        "[77]\tvalid_0's multi_logloss: 1.54863\n",
                        "[78]\tvalid_0's multi_logloss: 1.54584\n",
                        "[79]\tvalid_0's multi_logloss: 1.54308\n",
                        "[80]\tvalid_0's multi_logloss: 1.54029\n",
                        "[81]\tvalid_0's multi_logloss: 1.53764\n",
                        "[82]\tvalid_0's multi_logloss: 1.53504\n",
                        "[83]\tvalid_0's multi_logloss: 1.53248\n",
                        "[84]\tvalid_0's multi_logloss: 1.52997\n",
                        "[85]\tvalid_0's multi_logloss: 1.52753\n",
                        "[86]\tvalid_0's multi_logloss: 1.5251\n",
                        "[87]\tvalid_0's multi_logloss: 1.52271\n",
                        "[88]\tvalid_0's multi_logloss: 1.52027\n",
                        "[89]\tvalid_0's multi_logloss: 1.518\n",
                        "[90]\tvalid_0's multi_logloss: 1.51574\n",
                        "[91]\tvalid_0's multi_logloss: 1.5135\n",
                        "[92]\tvalid_0's multi_logloss: 1.5113\n",
                        "[93]\tvalid_0's multi_logloss: 1.50915\n",
                        "[94]\tvalid_0's multi_logloss: 1.50704\n",
                        "[95]\tvalid_0's multi_logloss: 1.50494\n",
                        "[96]\tvalid_0's multi_logloss: 1.50279\n",
                        "[97]\tvalid_0's multi_logloss: 1.5008\n",
                        "[98]\tvalid_0's multi_logloss: 1.4988\n",
                        "[99]\tvalid_0's multi_logloss: 1.49694\n",
                        "[100]\tvalid_0's multi_logloss: 1.49501\n",
                        "[101]\tvalid_0's multi_logloss: 1.49315\n",
                        "[102]\tvalid_0's multi_logloss: 1.49117\n",
                        "[103]\tvalid_0's multi_logloss: 1.48922\n",
                        "[104]\tvalid_0's multi_logloss: 1.48737\n",
                        "[105]\tvalid_0's multi_logloss: 1.48552\n",
                        "[106]\tvalid_0's multi_logloss: 1.48374\n",
                        "[107]\tvalid_0's multi_logloss: 1.48206\n",
                        "[108]\tvalid_0's multi_logloss: 1.48032\n",
                        "[109]\tvalid_0's multi_logloss: 1.47861\n",
                        "[110]\tvalid_0's multi_logloss: 1.47689\n",
                        "[111]\tvalid_0's multi_logloss: 1.47522\n",
                        "[112]\tvalid_0's multi_logloss: 1.47362\n",
                        "[113]\tvalid_0's multi_logloss: 1.472\n",
                        "[114]\tvalid_0's multi_logloss: 1.4705\n",
                        "[115]\tvalid_0's multi_logloss: 1.46897\n",
                        "[116]\tvalid_0's multi_logloss: 1.46741\n",
                        "[117]\tvalid_0's multi_logloss: 1.46597\n",
                        "[118]\tvalid_0's multi_logloss: 1.46446\n",
                        "[119]\tvalid_0's multi_logloss: 1.46303\n",
                        "[120]\tvalid_0's multi_logloss: 1.46161\n",
                        "[121]\tvalid_0's multi_logloss: 1.46016\n",
                        "[122]\tvalid_0's multi_logloss: 1.45877\n",
                        "[123]\tvalid_0's multi_logloss: 1.45728\n",
                        "[124]\tvalid_0's multi_logloss: 1.45592\n",
                        "[125]\tvalid_0's multi_logloss: 1.4546\n",
                        "[126]\tvalid_0's multi_logloss: 1.45325\n",
                        "[127]\tvalid_0's multi_logloss: 1.4518\n",
                        "[128]\tvalid_0's multi_logloss: 1.45048\n",
                        "[129]\tvalid_0's multi_logloss: 1.44919\n",
                        "[130]\tvalid_0's multi_logloss: 1.44787\n",
                        "[131]\tvalid_0's multi_logloss: 1.44658\n",
                        "[132]\tvalid_0's multi_logloss: 1.44542\n",
                        "[133]\tvalid_0's multi_logloss: 1.44416\n",
                        "[134]\tvalid_0's multi_logloss: 1.44297\n",
                        "[135]\tvalid_0's multi_logloss: 1.44181\n",
                        "[136]\tvalid_0's multi_logloss: 1.44057\n",
                        "[137]\tvalid_0's multi_logloss: 1.43943\n",
                        "[138]\tvalid_0's multi_logloss: 1.43834\n",
                        "[139]\tvalid_0's multi_logloss: 1.43717\n",
                        "[140]\tvalid_0's multi_logloss: 1.43605\n",
                        "[141]\tvalid_0's multi_logloss: 1.43496\n",
                        "[142]\tvalid_0's multi_logloss: 1.43385\n",
                        "[143]\tvalid_0's multi_logloss: 1.43274\n",
                        "[144]\tvalid_0's multi_logloss: 1.43169\n",
                        "[145]\tvalid_0's multi_logloss: 1.43062\n",
                        "[146]\tvalid_0's multi_logloss: 1.42956\n",
                        "[147]\tvalid_0's multi_logloss: 1.42851\n",
                        "[148]\tvalid_0's multi_logloss: 1.42756\n",
                        "[149]\tvalid_0's multi_logloss: 1.42656\n",
                        "[150]\tvalid_0's multi_logloss: 1.42557\n",
                        "[151]\tvalid_0's multi_logloss: 1.4246\n",
                        "[152]\tvalid_0's multi_logloss: 1.42362\n",
                        "[153]\tvalid_0's multi_logloss: 1.42267\n",
                        "[154]\tvalid_0's multi_logloss: 1.42179\n",
                        "[155]\tvalid_0's multi_logloss: 1.42082\n",
                        "[156]\tvalid_0's multi_logloss: 1.4199\n",
                        "[157]\tvalid_0's multi_logloss: 1.419\n",
                        "[158]\tvalid_0's multi_logloss: 1.41815\n",
                        "[159]\tvalid_0's multi_logloss: 1.41728\n",
                        "[160]\tvalid_0's multi_logloss: 1.41641\n",
                        "[161]\tvalid_0's multi_logloss: 1.4155\n",
                        "[162]\tvalid_0's multi_logloss: 1.41463\n",
                        "[163]\tvalid_0's multi_logloss: 1.41385\n",
                        "[164]\tvalid_0's multi_logloss: 1.41306\n",
                        "[165]\tvalid_0's multi_logloss: 1.41224\n",
                        "[166]\tvalid_0's multi_logloss: 1.41145\n",
                        "[167]\tvalid_0's multi_logloss: 1.41064\n",
                        "[168]\tvalid_0's multi_logloss: 1.40987\n",
                        "[169]\tvalid_0's multi_logloss: 1.4091\n",
                        "[170]\tvalid_0's multi_logloss: 1.40836\n",
                        "[171]\tvalid_0's multi_logloss: 1.40759\n",
                        "[172]\tvalid_0's multi_logloss: 1.40681\n",
                        "[173]\tvalid_0's multi_logloss: 1.40612\n",
                        "[174]\tvalid_0's multi_logloss: 1.40538\n",
                        "[175]\tvalid_0's multi_logloss: 1.40463\n",
                        "[176]\tvalid_0's multi_logloss: 1.40386\n",
                        "[177]\tvalid_0's multi_logloss: 1.40314\n",
                        "[178]\tvalid_0's multi_logloss: 1.40246\n",
                        "[179]\tvalid_0's multi_logloss: 1.40173\n",
                        "[180]\tvalid_0's multi_logloss: 1.40104\n",
                        "[181]\tvalid_0's multi_logloss: 1.40037\n",
                        "[182]\tvalid_0's multi_logloss: 1.39978\n",
                        "[183]\tvalid_0's multi_logloss: 1.39907\n",
                        "[184]\tvalid_0's multi_logloss: 1.39848\n",
                        "[185]\tvalid_0's multi_logloss: 1.39787\n",
                        "[186]\tvalid_0's multi_logloss: 1.39727\n",
                        "[187]\tvalid_0's multi_logloss: 1.39666\n",
                        "[188]\tvalid_0's multi_logloss: 1.39606\n",
                        "[189]\tvalid_0's multi_logloss: 1.39545\n",
                        "[190]\tvalid_0's multi_logloss: 1.39484\n",
                        "[191]\tvalid_0's multi_logloss: 1.39423\n",
                        "[192]\tvalid_0's multi_logloss: 1.39363\n",
                        "[193]\tvalid_0's multi_logloss: 1.39304\n",
                        "[194]\tvalid_0's multi_logloss: 1.3924\n",
                        "[195]\tvalid_0's multi_logloss: 1.39186\n",
                        "[196]\tvalid_0's multi_logloss: 1.39121\n",
                        "[197]\tvalid_0's multi_logloss: 1.39067\n",
                        "[198]\tvalid_0's multi_logloss: 1.39016\n",
                        "[199]\tvalid_0's multi_logloss: 1.38963\n",
                        "[200]\tvalid_0's multi_logloss: 1.38912\n",
                        "[201]\tvalid_0's multi_logloss: 1.38859\n",
                        "[202]\tvalid_0's multi_logloss: 1.38803\n",
                        "[203]\tvalid_0's multi_logloss: 1.38753\n",
                        "[204]\tvalid_0's multi_logloss: 1.38701\n",
                        "[205]\tvalid_0's multi_logloss: 1.3865\n",
                        "[206]\tvalid_0's multi_logloss: 1.386\n",
                        "[207]\tvalid_0's multi_logloss: 1.38551\n",
                        "[208]\tvalid_0's multi_logloss: 1.38505\n",
                        "[209]\tvalid_0's multi_logloss: 1.38448\n",
                        "[210]\tvalid_0's multi_logloss: 1.38398\n",
                        "[211]\tvalid_0's multi_logloss: 1.38347\n",
                        "[212]\tvalid_0's multi_logloss: 1.38303\n",
                        "[213]\tvalid_0's multi_logloss: 1.38255\n",
                        "[214]\tvalid_0's multi_logloss: 1.38207\n",
                        "[215]\tvalid_0's multi_logloss: 1.38157\n",
                        "[216]\tvalid_0's multi_logloss: 1.3811\n",
                        "[217]\tvalid_0's multi_logloss: 1.3806\n",
                        "[218]\tvalid_0's multi_logloss: 1.38021\n",
                        "[219]\tvalid_0's multi_logloss: 1.37976\n",
                        "[220]\tvalid_0's multi_logloss: 1.37933\n",
                        "[221]\tvalid_0's multi_logloss: 1.37887\n",
                        "[222]\tvalid_0's multi_logloss: 1.3784\n",
                        "[223]\tvalid_0's multi_logloss: 1.37799\n",
                        "[224]\tvalid_0's multi_logloss: 1.37755\n",
                        "[225]\tvalid_0's multi_logloss: 1.37716\n",
                        "[226]\tvalid_0's multi_logloss: 1.37671\n",
                        "[227]\tvalid_0's multi_logloss: 1.37635\n",
                        "[228]\tvalid_0's multi_logloss: 1.37594\n",
                        "[229]\tvalid_0's multi_logloss: 1.37551\n",
                        "[230]\tvalid_0's multi_logloss: 1.37518\n",
                        "[231]\tvalid_0's multi_logloss: 1.37482\n",
                        "[232]\tvalid_0's multi_logloss: 1.37438\n",
                        "[233]\tvalid_0's multi_logloss: 1.37402\n",
                        "[234]\tvalid_0's multi_logloss: 1.37365\n",
                        "[235]\tvalid_0's multi_logloss: 1.37328\n",
                        "[236]\tvalid_0's multi_logloss: 1.37286\n",
                        "[237]\tvalid_0's multi_logloss: 1.37251\n",
                        "[238]\tvalid_0's multi_logloss: 1.37213\n",
                        "[239]\tvalid_0's multi_logloss: 1.37175\n",
                        "[240]\tvalid_0's multi_logloss: 1.37139\n",
                        "[241]\tvalid_0's multi_logloss: 1.37099\n",
                        "[242]\tvalid_0's multi_logloss: 1.37066\n",
                        "[243]\tvalid_0's multi_logloss: 1.37036\n",
                        "[244]\tvalid_0's multi_logloss: 1.37005\n",
                        "[245]\tvalid_0's multi_logloss: 1.36973\n",
                        "[246]\tvalid_0's multi_logloss: 1.36943\n",
                        "[247]\tvalid_0's multi_logloss: 1.36907\n",
                        "[248]\tvalid_0's multi_logloss: 1.36872\n",
                        "[249]\tvalid_0's multi_logloss: 1.36836\n",
                        "[250]\tvalid_0's multi_logloss: 1.36802\n",
                        "[251]\tvalid_0's multi_logloss: 1.36773\n",
                        "[252]\tvalid_0's multi_logloss: 1.36735\n",
                        "[253]\tvalid_0's multi_logloss: 1.36701\n",
                        "[254]\tvalid_0's multi_logloss: 1.36673\n",
                        "[255]\tvalid_0's multi_logloss: 1.36638\n",
                        "[256]\tvalid_0's multi_logloss: 1.36608\n",
                        "[257]\tvalid_0's multi_logloss: 1.3658\n",
                        "[258]\tvalid_0's multi_logloss: 1.36544\n",
                        "[259]\tvalid_0's multi_logloss: 1.36513\n",
                        "[260]\tvalid_0's multi_logloss: 1.36482\n",
                        "[261]\tvalid_0's multi_logloss: 1.36453\n",
                        "[262]\tvalid_0's multi_logloss: 1.36423\n",
                        "[263]\tvalid_0's multi_logloss: 1.36397\n",
                        "[264]\tvalid_0's multi_logloss: 1.36368\n",
                        "[265]\tvalid_0's multi_logloss: 1.36338\n",
                        "[266]\tvalid_0's multi_logloss: 1.36309\n",
                        "[267]\tvalid_0's multi_logloss: 1.36278\n",
                        "[268]\tvalid_0's multi_logloss: 1.36249\n",
                        "[269]\tvalid_0's multi_logloss: 1.36216\n",
                        "[270]\tvalid_0's multi_logloss: 1.36185\n",
                        "[271]\tvalid_0's multi_logloss: 1.36152\n",
                        "[272]\tvalid_0's multi_logloss: 1.36125\n",
                        "[273]\tvalid_0's multi_logloss: 1.36093\n",
                        "[274]\tvalid_0's multi_logloss: 1.36071\n",
                        "[275]\tvalid_0's multi_logloss: 1.36044\n",
                        "[276]\tvalid_0's multi_logloss: 1.36013\n",
                        "[277]\tvalid_0's multi_logloss: 1.35986\n",
                        "[278]\tvalid_0's multi_logloss: 1.35961\n",
                        "[279]\tvalid_0's multi_logloss: 1.35933\n",
                        "[280]\tvalid_0's multi_logloss: 1.35903\n",
                        "[281]\tvalid_0's multi_logloss: 1.35881\n",
                        "[282]\tvalid_0's multi_logloss: 1.35848\n",
                        "[283]\tvalid_0's multi_logloss: 1.35822\n",
                        "[284]\tvalid_0's multi_logloss: 1.35799\n",
                        "[285]\tvalid_0's multi_logloss: 1.35771\n",
                        "[286]\tvalid_0's multi_logloss: 1.35745\n",
                        "[287]\tvalid_0's multi_logloss: 1.3572\n",
                        "[288]\tvalid_0's multi_logloss: 1.3569\n",
                        "[289]\tvalid_0's multi_logloss: 1.35658\n",
                        "[290]\tvalid_0's multi_logloss: 1.35632\n",
                        "[291]\tvalid_0's multi_logloss: 1.35605\n",
                        "[292]\tvalid_0's multi_logloss: 1.3558\n",
                        "[293]\tvalid_0's multi_logloss: 1.35554\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[294]\tvalid_0's multi_logloss: 1.35528\n",
                        "[295]\tvalid_0's multi_logloss: 1.35509\n",
                        "[296]\tvalid_0's multi_logloss: 1.35482\n",
                        "[297]\tvalid_0's multi_logloss: 1.35459\n",
                        "[298]\tvalid_0's multi_logloss: 1.35437\n",
                        "[299]\tvalid_0's multi_logloss: 1.35405\n",
                        "[300]\tvalid_0's multi_logloss: 1.35384\n",
                        "[301]\tvalid_0's multi_logloss: 1.3536\n",
                        "[302]\tvalid_0's multi_logloss: 1.35336\n",
                        "[303]\tvalid_0's multi_logloss: 1.3531\n",
                        "[304]\tvalid_0's multi_logloss: 1.35285\n",
                        "[305]\tvalid_0's multi_logloss: 1.35262\n",
                        "[306]\tvalid_0's multi_logloss: 1.35241\n",
                        "[307]\tvalid_0's multi_logloss: 1.3522\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[308]\tvalid_0's multi_logloss: 1.35196\n",
                        "[309]\tvalid_0's multi_logloss: 1.35173\n",
                        "[310]\tvalid_0's multi_logloss: 1.3515\n",
                        "[311]\tvalid_0's multi_logloss: 1.35129\n",
                        "[312]\tvalid_0's multi_logloss: 1.35106\n",
                        "[313]\tvalid_0's multi_logloss: 1.35083\n",
                        "[314]\tvalid_0's multi_logloss: 1.3506\n",
                        "[315]\tvalid_0's multi_logloss: 1.35038\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[316]\tvalid_0's multi_logloss: 1.35019\n",
                        "[317]\tvalid_0's multi_logloss: 1.34996\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[318]\tvalid_0's multi_logloss: 1.34977\n",
                        "[319]\tvalid_0's multi_logloss: 1.34953\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[320]\tvalid_0's multi_logloss: 1.34935\n",
                        "[321]\tvalid_0's multi_logloss: 1.34915\n",
                        "[322]\tvalid_0's multi_logloss: 1.34892\n",
                        "[323]\tvalid_0's multi_logloss: 1.34866\n",
                        "[324]\tvalid_0's multi_logloss: 1.34842\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[325]\tvalid_0's multi_logloss: 1.34826\n",
                        "[326]\tvalid_0's multi_logloss: 1.34805\n",
                        "[327]\tvalid_0's multi_logloss: 1.34789\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[328]\tvalid_0's multi_logloss: 1.34767\n",
                        "[329]\tvalid_0's multi_logloss: 1.34749\n",
                        "[330]\tvalid_0's multi_logloss: 1.34725\n",
                        "[331]\tvalid_0's multi_logloss: 1.34702\n",
                        "[332]\tvalid_0's multi_logloss: 1.34678\n",
                        "[333]\tvalid_0's multi_logloss: 1.34658\n",
                        "[334]\tvalid_0's multi_logloss: 1.3464\n",
                        "[335]\tvalid_0's multi_logloss: 1.34622\n",
                        "[336]\tvalid_0's multi_logloss: 1.34605\n",
                        "[337]\tvalid_0's multi_logloss: 1.34584\n",
                        "[338]\tvalid_0's multi_logloss: 1.34566\n",
                        "[339]\tvalid_0's multi_logloss: 1.34544\n",
                        "[340]\tvalid_0's multi_logloss: 1.34521\n",
                        "[341]\tvalid_0's multi_logloss: 1.34499\n",
                        "[342]\tvalid_0's multi_logloss: 1.3448\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[343]\tvalid_0's multi_logloss: 1.34458\n",
                        "[344]\tvalid_0's multi_logloss: 1.34442\n",
                        "[345]\tvalid_0's multi_logloss: 1.3442\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[346]\tvalid_0's multi_logloss: 1.34398\n",
                        "[347]\tvalid_0's multi_logloss: 1.34376\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[348]\tvalid_0's multi_logloss: 1.34354\n",
                        "[349]\tvalid_0's multi_logloss: 1.34332\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[350]\tvalid_0's multi_logloss: 1.34314\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[351]\tvalid_0's multi_logloss: 1.34294\n",
                        "[352]\tvalid_0's multi_logloss: 1.34276\n",
                        "[353]\tvalid_0's multi_logloss: 1.34259\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[354]\tvalid_0's multi_logloss: 1.34239\n",
                        "[355]\tvalid_0's multi_logloss: 1.34223\n",
                        "[356]\tvalid_0's multi_logloss: 1.34204\n",
                        "[357]\tvalid_0's multi_logloss: 1.34188\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[358]\tvalid_0's multi_logloss: 1.34168\n",
                        "[359]\tvalid_0's multi_logloss: 1.3415\n",
                        "[360]\tvalid_0's multi_logloss: 1.34133\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[361]\tvalid_0's multi_logloss: 1.34119\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[362]\tvalid_0's multi_logloss: 1.34105\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[363]\tvalid_0's multi_logloss: 1.34091\n",
                        "[364]\tvalid_0's multi_logloss: 1.34075\n",
                        "[365]\tvalid_0's multi_logloss: 1.34059\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[366]\tvalid_0's multi_logloss: 1.34043\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[367]\tvalid_0's multi_logloss: 1.34024\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[368]\tvalid_0's multi_logloss: 1.34005\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[369]\tvalid_0's multi_logloss: 1.33989\n",
                        "[370]\tvalid_0's multi_logloss: 1.3397\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[371]\tvalid_0's multi_logloss: 1.33953\n",
                        "[372]\tvalid_0's multi_logloss: 1.33937\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[373]\tvalid_0's multi_logloss: 1.33921\n",
                        "[374]\tvalid_0's multi_logloss: 1.33906\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[375]\tvalid_0's multi_logloss: 1.33893\n",
                        "[376]\tvalid_0's multi_logloss: 1.33875\n",
                        "[377]\tvalid_0's multi_logloss: 1.33854\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[378]\tvalid_0's multi_logloss: 1.33841\n",
                        "[379]\tvalid_0's multi_logloss: 1.33825\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[380]\tvalid_0's multi_logloss: 1.33808\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[381]\tvalid_0's multi_logloss: 1.33786\n",
                        "[382]\tvalid_0's multi_logloss: 1.33771\n",
                        "[383]\tvalid_0's multi_logloss: 1.33756\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[384]\tvalid_0's multi_logloss: 1.33737\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[385]\tvalid_0's multi_logloss: 1.33722\n",
                        "[386]\tvalid_0's multi_logloss: 1.33707\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[387]\tvalid_0's multi_logloss: 1.33692\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[388]\tvalid_0's multi_logloss: 1.33674\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[389]\tvalid_0's multi_logloss: 1.3366\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[390]\tvalid_0's multi_logloss: 1.33644\n",
                        "[391]\tvalid_0's multi_logloss: 1.3363\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[392]\tvalid_0's multi_logloss: 1.33617\n",
                        "[393]\tvalid_0's multi_logloss: 1.33604\n",
                        "[394]\tvalid_0's multi_logloss: 1.33593\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[395]\tvalid_0's multi_logloss: 1.33577\n",
                        "[396]\tvalid_0's multi_logloss: 1.33564\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[397]\tvalid_0's multi_logloss: 1.33553\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[398]\tvalid_0's multi_logloss: 1.33541\n",
                        "[399]\tvalid_0's multi_logloss: 1.33526\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[400]\tvalid_0's multi_logloss: 1.33516\n",
                        "[401]\tvalid_0's multi_logloss: 1.33504\n",
                        "[402]\tvalid_0's multi_logloss: 1.33489\n",
                        "[403]\tvalid_0's multi_logloss: 1.33473\n",
                        "[404]\tvalid_0's multi_logloss: 1.33461\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[405]\tvalid_0's multi_logloss: 1.33443\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[406]\tvalid_0's multi_logloss: 1.3343\n",
                        "[407]\tvalid_0's multi_logloss: 1.33416\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[408]\tvalid_0's multi_logloss: 1.33399\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[409]\tvalid_0's multi_logloss: 1.33385\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[410]\tvalid_0's multi_logloss: 1.33373\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[411]\tvalid_0's multi_logloss: 1.33357\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[412]\tvalid_0's multi_logloss: 1.33344\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[413]\tvalid_0's multi_logloss: 1.33329\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[414]\tvalid_0's multi_logloss: 1.33316\n",
                        "[415]\tvalid_0's multi_logloss: 1.33303\n",
                        "[416]\tvalid_0's multi_logloss: 1.33291\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[417]\tvalid_0's multi_logloss: 1.33279\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[418]\tvalid_0's multi_logloss: 1.33265\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[419]\tvalid_0's multi_logloss: 1.33252\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[420]\tvalid_0's multi_logloss: 1.33238\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[421]\tvalid_0's multi_logloss: 1.33228\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[422]\tvalid_0's multi_logloss: 1.33212\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[423]\tvalid_0's multi_logloss: 1.33198\n",
                        "[424]\tvalid_0's multi_logloss: 1.33186\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[425]\tvalid_0's multi_logloss: 1.33177\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[426]\tvalid_0's multi_logloss: 1.33165\n",
                        "[427]\tvalid_0's multi_logloss: 1.33151\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[428]\tvalid_0's multi_logloss: 1.33136\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[429]\tvalid_0's multi_logloss: 1.33123\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[430]\tvalid_0's multi_logloss: 1.33111\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[431]\tvalid_0's multi_logloss: 1.33099\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[432]\tvalid_0's multi_logloss: 1.3309\n",
                        "[433]\tvalid_0's multi_logloss: 1.33079\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[434]\tvalid_0's multi_logloss: 1.33067\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[435]\tvalid_0's multi_logloss: 1.33056\n",
                        "[436]\tvalid_0's multi_logloss: 1.33045\n",
                        "[437]\tvalid_0's multi_logloss: 1.33033\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[438]\tvalid_0's multi_logloss: 1.33019\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[439]\tvalid_0's multi_logloss: 1.33006\n",
                        "[440]\tvalid_0's multi_logloss: 1.32994\n",
                        "[441]\tvalid_0's multi_logloss: 1.32981\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[442]\tvalid_0's multi_logloss: 1.32968\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[443]\tvalid_0's multi_logloss: 1.32954\n",
                        "[444]\tvalid_0's multi_logloss: 1.32939\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[445]\tvalid_0's multi_logloss: 1.32926\n",
                        "[446]\tvalid_0's multi_logloss: 1.32911\n",
                        "[447]\tvalid_0's multi_logloss: 1.329\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[448]\tvalid_0's multi_logloss: 1.32887\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[449]\tvalid_0's multi_logloss: 1.32877\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[450]\tvalid_0's multi_logloss: 1.32862\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[451]\tvalid_0's multi_logloss: 1.32853\n",
                        "[452]\tvalid_0's multi_logloss: 1.32842\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[453]\tvalid_0's multi_logloss: 1.32831\n",
                        "[454]\tvalid_0's multi_logloss: 1.3282\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[455]\tvalid_0's multi_logloss: 1.32809\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[456]\tvalid_0's multi_logloss: 1.32799\n",
                        "[457]\tvalid_0's multi_logloss: 1.32786\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[458]\tvalid_0's multi_logloss: 1.32777\n",
                        "[459]\tvalid_0's multi_logloss: 1.32765\n",
                        "[460]\tvalid_0's multi_logloss: 1.32754\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[461]\tvalid_0's multi_logloss: 1.32743\n",
                        "[462]\tvalid_0's multi_logloss: 1.32732\n",
                        "[463]\tvalid_0's multi_logloss: 1.32719\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[464]\tvalid_0's multi_logloss: 1.32705\n",
                        "[465]\tvalid_0's multi_logloss: 1.32692\n",
                        "[466]\tvalid_0's multi_logloss: 1.3268\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[467]\tvalid_0's multi_logloss: 1.32667\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[468]\tvalid_0's multi_logloss: 1.3266\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[469]\tvalid_0's multi_logloss: 1.32645\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[470]\tvalid_0's multi_logloss: 1.32631\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[471]\tvalid_0's multi_logloss: 1.32618\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[472]\tvalid_0's multi_logloss: 1.32609\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[473]\tvalid_0's multi_logloss: 1.32599\n",
                        "[474]\tvalid_0's multi_logloss: 1.32588\n",
                        "[475]\tvalid_0's multi_logloss: 1.32575\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[476]\tvalid_0's multi_logloss: 1.32565\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[477]\tvalid_0's multi_logloss: 1.32554\n",
                        "[478]\tvalid_0's multi_logloss: 1.32545\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[479]\tvalid_0's multi_logloss: 1.3253\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[480]\tvalid_0's multi_logloss: 1.32518\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[481]\tvalid_0's multi_logloss: 1.32508\n",
                        "[482]\tvalid_0's multi_logloss: 1.32494\n",
                        "[483]\tvalid_0's multi_logloss: 1.32483\n",
                        "[484]\tvalid_0's multi_logloss: 1.32471\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[485]\tvalid_0's multi_logloss: 1.32462\n",
                        "[486]\tvalid_0's multi_logloss: 1.32451\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[487]\tvalid_0's multi_logloss: 1.32443\n",
                        "[488]\tvalid_0's multi_logloss: 1.32434\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[489]\tvalid_0's multi_logloss: 1.32423\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[490]\tvalid_0's multi_logloss: 1.32412\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[491]\tvalid_0's multi_logloss: 1.32402\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[492]\tvalid_0's multi_logloss: 1.32395\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[493]\tvalid_0's multi_logloss: 1.32384\n",
                        "[494]\tvalid_0's multi_logloss: 1.32374\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[495]\tvalid_0's multi_logloss: 1.32364\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[496]\tvalid_0's multi_logloss: 1.32351\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[497]\tvalid_0's multi_logloss: 1.3234\n",
                        "[498]\tvalid_0's multi_logloss: 1.32329\n",
                        "[499]\tvalid_0's multi_logloss: 1.3232\n",
                        "[500]\tvalid_0's multi_logloss: 1.32311\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[501]\tvalid_0's multi_logloss: 1.32301\n",
                        "[502]\tvalid_0's multi_logloss: 1.32289\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[503]\tvalid_0's multi_logloss: 1.32276\n",
                        "[504]\tvalid_0's multi_logloss: 1.32265\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[505]\tvalid_0's multi_logloss: 1.32254\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[506]\tvalid_0's multi_logloss: 1.32247\n",
                        "[507]\tvalid_0's multi_logloss: 1.32237\n",
                        "[508]\tvalid_0's multi_logloss: 1.32228\n",
                        "[509]\tvalid_0's multi_logloss: 1.32221\n",
                        "[510]\tvalid_0's multi_logloss: 1.3221\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[511]\tvalid_0's multi_logloss: 1.32202\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[512]\tvalid_0's multi_logloss: 1.32194\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[513]\tvalid_0's multi_logloss: 1.32187\n",
                        "[514]\tvalid_0's multi_logloss: 1.32179\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[515]\tvalid_0's multi_logloss: 1.32167\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[516]\tvalid_0's multi_logloss: 1.3216\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[517]\tvalid_0's multi_logloss: 1.32153\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[518]\tvalid_0's multi_logloss: 1.32142\n",
                        "[519]\tvalid_0's multi_logloss: 1.32132\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[520]\tvalid_0's multi_logloss: 1.32123\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[521]\tvalid_0's multi_logloss: 1.32111\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[522]\tvalid_0's multi_logloss: 1.321\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[523]\tvalid_0's multi_logloss: 1.3209\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[524]\tvalid_0's multi_logloss: 1.32082\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[525]\tvalid_0's multi_logloss: 1.32072\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[526]\tvalid_0's multi_logloss: 1.32063\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[527]\tvalid_0's multi_logloss: 1.32055\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[528]\tvalid_0's multi_logloss: 1.32044\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[529]\tvalid_0's multi_logloss: 1.32034\n",
                        "[530]\tvalid_0's multi_logloss: 1.32024\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[531]\tvalid_0's multi_logloss: 1.32017\n",
                        "[532]\tvalid_0's multi_logloss: 1.32011\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[533]\tvalid_0's multi_logloss: 1.32001\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[534]\tvalid_0's multi_logloss: 1.31992\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[535]\tvalid_0's multi_logloss: 1.31982\n",
                        "[536]\tvalid_0's multi_logloss: 1.31968\n",
                        "[537]\tvalid_0's multi_logloss: 1.3196\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[538]\tvalid_0's multi_logloss: 1.31951\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[539]\tvalid_0's multi_logloss: 1.31944\n",
                        "[540]\tvalid_0's multi_logloss: 1.31932\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[541]\tvalid_0's multi_logloss: 1.31923\n",
                        "[542]\tvalid_0's multi_logloss: 1.3191\n",
                        "[543]\tvalid_0's multi_logloss: 1.31901\n",
                        "[544]\tvalid_0's multi_logloss: 1.3189\n",
                        "[545]\tvalid_0's multi_logloss: 1.31881\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[546]\tvalid_0's multi_logloss: 1.31874\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[547]\tvalid_0's multi_logloss: 1.31864\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[548]\tvalid_0's multi_logloss: 1.31855\n",
                        "[549]\tvalid_0's multi_logloss: 1.31841\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[550]\tvalid_0's multi_logloss: 1.31833\n",
                        "[551]\tvalid_0's multi_logloss: 1.31826\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[552]\tvalid_0's multi_logloss: 1.31819\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[553]\tvalid_0's multi_logloss: 1.3181\n",
                        "[554]\tvalid_0's multi_logloss: 1.31804\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[555]\tvalid_0's multi_logloss: 1.31797\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[556]\tvalid_0's multi_logloss: 1.31786\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[557]\tvalid_0's multi_logloss: 1.31776\n",
                        "[558]\tvalid_0's multi_logloss: 1.31768\n",
                        "[559]\tvalid_0's multi_logloss: 1.31759\n",
                        "[560]\tvalid_0's multi_logloss: 1.31748\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[561]\tvalid_0's multi_logloss: 1.3174\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[562]\tvalid_0's multi_logloss: 1.31733\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[563]\tvalid_0's multi_logloss: 1.3172\n",
                        "[564]\tvalid_0's multi_logloss: 1.31709\n",
                        "[565]\tvalid_0's multi_logloss: 1.31699\n",
                        "[566]\tvalid_0's multi_logloss: 1.3169\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[567]\tvalid_0's multi_logloss: 1.31679\n",
                        "[568]\tvalid_0's multi_logloss: 1.31667\n",
                        "[569]\tvalid_0's multi_logloss: 1.31659\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[570]\tvalid_0's multi_logloss: 1.31652\n",
                        "[571]\tvalid_0's multi_logloss: 1.31642\n",
                        "[572]\tvalid_0's multi_logloss: 1.31633\n",
                        "[573]\tvalid_0's multi_logloss: 1.31625\n",
                        "[574]\tvalid_0's multi_logloss: 1.31619\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[575]\tvalid_0's multi_logloss: 1.31611\n",
                        "[576]\tvalid_0's multi_logloss: 1.31604\n",
                        "[577]\tvalid_0's multi_logloss: 1.31596\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[578]\tvalid_0's multi_logloss: 1.31585\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[579]\tvalid_0's multi_logloss: 1.31577\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[580]\tvalid_0's multi_logloss: 1.31568\n",
                        "[581]\tvalid_0's multi_logloss: 1.31559\n",
                        "[582]\tvalid_0's multi_logloss: 1.31552\n",
                        "[583]\tvalid_0's multi_logloss: 1.31545\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[584]\tvalid_0's multi_logloss: 1.31538\n",
                        "[585]\tvalid_0's multi_logloss: 1.31528\n",
                        "[586]\tvalid_0's multi_logloss: 1.31517\n",
                        "[587]\tvalid_0's multi_logloss: 1.3151\n",
                        "[588]\tvalid_0's multi_logloss: 1.31504\n",
                        "[589]\tvalid_0's multi_logloss: 1.31496\n",
                        "[590]\tvalid_0's multi_logloss: 1.31487\n",
                        "[591]\tvalid_0's multi_logloss: 1.3148\n",
                        "[592]\tvalid_0's multi_logloss: 1.31473\n",
                        "[593]\tvalid_0's multi_logloss: 1.31465\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[594]\tvalid_0's multi_logloss: 1.31453\n",
                        "[595]\tvalid_0's multi_logloss: 1.31446\n",
                        "[596]\tvalid_0's multi_logloss: 1.31437\n",
                        "[597]\tvalid_0's multi_logloss: 1.31429\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[598]\tvalid_0's multi_logloss: 1.31422\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[599]\tvalid_0's multi_logloss: 1.31414\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[600]\tvalid_0's multi_logloss: 1.31402\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[601]\tvalid_0's multi_logloss: 1.31395\n",
                        "[602]\tvalid_0's multi_logloss: 1.31387\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[603]\tvalid_0's multi_logloss: 1.3138\n",
                        "[604]\tvalid_0's multi_logloss: 1.3137\n",
                        "[605]\tvalid_0's multi_logloss: 1.31362\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[606]\tvalid_0's multi_logloss: 1.31355\n",
                        "[607]\tvalid_0's multi_logloss: 1.31344\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[608]\tvalid_0's multi_logloss: 1.31335\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[609]\tvalid_0's multi_logloss: 1.31325\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[610]\tvalid_0's multi_logloss: 1.31319\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[611]\tvalid_0's multi_logloss: 1.31309\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[612]\tvalid_0's multi_logloss: 1.31301\n",
                        "[613]\tvalid_0's multi_logloss: 1.31294\n",
                        "[614]\tvalid_0's multi_logloss: 1.31283\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[615]\tvalid_0's multi_logloss: 1.31276\n",
                        "[616]\tvalid_0's multi_logloss: 1.31269\n",
                        "[617]\tvalid_0's multi_logloss: 1.31261\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[618]\tvalid_0's multi_logloss: 1.31252\n",
                        "[619]\tvalid_0's multi_logloss: 1.31242\n",
                        "[620]\tvalid_0's multi_logloss: 1.31233\n",
                        "[621]\tvalid_0's multi_logloss: 1.31224\n",
                        "[622]\tvalid_0's multi_logloss: 1.31218\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[623]\tvalid_0's multi_logloss: 1.3121\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[624]\tvalid_0's multi_logloss: 1.31204\n",
                        "[625]\tvalid_0's multi_logloss: 1.31195\n",
                        "[626]\tvalid_0's multi_logloss: 1.31184\n",
                        "[627]\tvalid_0's multi_logloss: 1.31176\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[628]\tvalid_0's multi_logloss: 1.31169\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[629]\tvalid_0's multi_logloss: 1.31161\n",
                        "[630]\tvalid_0's multi_logloss: 1.31154\n",
                        "[631]\tvalid_0's multi_logloss: 1.3115\n",
                        "[632]\tvalid_0's multi_logloss: 1.31141\n",
                        "[633]\tvalid_0's multi_logloss: 1.31131\n",
                        "[634]\tvalid_0's multi_logloss: 1.31124\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[635]\tvalid_0's multi_logloss: 1.31117\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[636]\tvalid_0's multi_logloss: 1.31109\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[637]\tvalid_0's multi_logloss: 1.31103\n",
                        "[638]\tvalid_0's multi_logloss: 1.31093\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[639]\tvalid_0's multi_logloss: 1.31087\n",
                        "[640]\tvalid_0's multi_logloss: 1.31079\n",
                        "[641]\tvalid_0's multi_logloss: 1.31072\n",
                        "[642]\tvalid_0's multi_logloss: 1.31065\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[643]\tvalid_0's multi_logloss: 1.31056\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[644]\tvalid_0's multi_logloss: 1.31051\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[645]\tvalid_0's multi_logloss: 1.31042\n",
                        "[646]\tvalid_0's multi_logloss: 1.31036\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[647]\tvalid_0's multi_logloss: 1.31029\n",
                        "[648]\tvalid_0's multi_logloss: 1.31023\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[649]\tvalid_0's multi_logloss: 1.31018\n",
                        "[650]\tvalid_0's multi_logloss: 1.31011\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[651]\tvalid_0's multi_logloss: 1.31001\n",
                        "[652]\tvalid_0's multi_logloss: 1.30994\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[653]\tvalid_0's multi_logloss: 1.30987\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[654]\tvalid_0's multi_logloss: 1.3098\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[655]\tvalid_0's multi_logloss: 1.30973\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[656]\tvalid_0's multi_logloss: 1.30964\n",
                        "[657]\tvalid_0's multi_logloss: 1.30958\n",
                        "[658]\tvalid_0's multi_logloss: 1.30952\n",
                        "[659]\tvalid_0's multi_logloss: 1.30946\n",
                        "[660]\tvalid_0's multi_logloss: 1.30938\n",
                        "[661]\tvalid_0's multi_logloss: 1.30931\n",
                        "[662]\tvalid_0's multi_logloss: 1.30925\n",
                        "[663]\tvalid_0's multi_logloss: 1.3092\n",
                        "[664]\tvalid_0's multi_logloss: 1.30913\n",
                        "[665]\tvalid_0's multi_logloss: 1.30907\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[666]\tvalid_0's multi_logloss: 1.30899\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[667]\tvalid_0's multi_logloss: 1.3089\n",
                        "[668]\tvalid_0's multi_logloss: 1.30882\n",
                        "[669]\tvalid_0's multi_logloss: 1.30875\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[670]\tvalid_0's multi_logloss: 1.30865\n",
                        "[671]\tvalid_0's multi_logloss: 1.30857\n",
                        "[672]\tvalid_0's multi_logloss: 1.3085\n",
                        "[673]\tvalid_0's multi_logloss: 1.3084\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[674]\tvalid_0's multi_logloss: 1.30834\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[675]\tvalid_0's multi_logloss: 1.30828\n",
                        "[676]\tvalid_0's multi_logloss: 1.30819\n",
                        "[677]\tvalid_0's multi_logloss: 1.30813\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[678]\tvalid_0's multi_logloss: 1.30806\n",
                        "[679]\tvalid_0's multi_logloss: 1.30798\n",
                        "[680]\tvalid_0's multi_logloss: 1.30792\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[681]\tvalid_0's multi_logloss: 1.30787\n",
                        "[682]\tvalid_0's multi_logloss: 1.30781\n",
                        "[683]\tvalid_0's multi_logloss: 1.30774\n",
                        "[684]\tvalid_0's multi_logloss: 1.30769\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[685]\tvalid_0's multi_logloss: 1.30762\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[686]\tvalid_0's multi_logloss: 1.30756\n",
                        "[687]\tvalid_0's multi_logloss: 1.30749\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[688]\tvalid_0's multi_logloss: 1.30744\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[689]\tvalid_0's multi_logloss: 1.30738\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[690]\tvalid_0's multi_logloss: 1.30731\n",
                        "[691]\tvalid_0's multi_logloss: 1.30725\n",
                        "[692]\tvalid_0's multi_logloss: 1.30719\n",
                        "[693]\tvalid_0's multi_logloss: 1.30712\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[694]\tvalid_0's multi_logloss: 1.30706\n",
                        "[695]\tvalid_0's multi_logloss: 1.307\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[696]\tvalid_0's multi_logloss: 1.30694\n",
                        "[697]\tvalid_0's multi_logloss: 1.30686\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[698]\tvalid_0's multi_logloss: 1.30682\n",
                        "[699]\tvalid_0's multi_logloss: 1.30675\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[700]\tvalid_0's multi_logloss: 1.30663\n",
                        "[701]\tvalid_0's multi_logloss: 1.30655\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[702]\tvalid_0's multi_logloss: 1.30647\n",
                        "[703]\tvalid_0's multi_logloss: 1.3064\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[704]\tvalid_0's multi_logloss: 1.30636\n",
                        "[705]\tvalid_0's multi_logloss: 1.30628\n",
                        "[706]\tvalid_0's multi_logloss: 1.30623\n",
                        "[707]\tvalid_0's multi_logloss: 1.30615\n",
                        "[708]\tvalid_0's multi_logloss: 1.30607\n",
                        "[709]\tvalid_0's multi_logloss: 1.30603\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[710]\tvalid_0's multi_logloss: 1.30596\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[711]\tvalid_0's multi_logloss: 1.30591\n",
                        "[712]\tvalid_0's multi_logloss: 1.30584\n",
                        "[713]\tvalid_0's multi_logloss: 1.30577\n",
                        "[714]\tvalid_0's multi_logloss: 1.30571\n",
                        "[715]\tvalid_0's multi_logloss: 1.30564\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[716]\tvalid_0's multi_logloss: 1.30555\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[717]\tvalid_0's multi_logloss: 1.30548\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[718]\tvalid_0's multi_logloss: 1.30542\n",
                        "[719]\tvalid_0's multi_logloss: 1.30536\n",
                        "[720]\tvalid_0's multi_logloss: 1.30531\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[721]\tvalid_0's multi_logloss: 1.30522\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[722]\tvalid_0's multi_logloss: 1.30514\n",
                        "[723]\tvalid_0's multi_logloss: 1.30506\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[724]\tvalid_0's multi_logloss: 1.30498\n",
                        "[725]\tvalid_0's multi_logloss: 1.30491\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[726]\tvalid_0's multi_logloss: 1.30485\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[727]\tvalid_0's multi_logloss: 1.30476\n",
                        "[728]\tvalid_0's multi_logloss: 1.30471\n",
                        "[729]\tvalid_0's multi_logloss: 1.30465\n",
                        "[730]\tvalid_0's multi_logloss: 1.30459\n",
                        "[731]\tvalid_0's multi_logloss: 1.30451\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[732]\tvalid_0's multi_logloss: 1.30444\n",
                        "[733]\tvalid_0's multi_logloss: 1.30438\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[734]\tvalid_0's multi_logloss: 1.30429\n",
                        "[735]\tvalid_0's multi_logloss: 1.30423\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[736]\tvalid_0's multi_logloss: 1.30416\n",
                        "[737]\tvalid_0's multi_logloss: 1.30409\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[738]\tvalid_0's multi_logloss: 1.30404\n",
                        "[739]\tvalid_0's multi_logloss: 1.30398\n",
                        "[740]\tvalid_0's multi_logloss: 1.30392\n",
                        "[741]\tvalid_0's multi_logloss: 1.30386\n",
                        "[742]\tvalid_0's multi_logloss: 1.3038\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[743]\tvalid_0's multi_logloss: 1.30375\n",
                        "[744]\tvalid_0's multi_logloss: 1.30366\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[745]\tvalid_0's multi_logloss: 1.30357\n",
                        "[746]\tvalid_0's multi_logloss: 1.3035\n",
                        "[747]\tvalid_0's multi_logloss: 1.30344\n",
                        "[748]\tvalid_0's multi_logloss: 1.30338\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[749]\tvalid_0's multi_logloss: 1.30332\n",
                        "[750]\tvalid_0's multi_logloss: 1.30324\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[751]\tvalid_0's multi_logloss: 1.30317\n",
                        "[752]\tvalid_0's multi_logloss: 1.30311\n",
                        "[753]\tvalid_0's multi_logloss: 1.30305\n",
                        "[754]\tvalid_0's multi_logloss: 1.303\n",
                        "[755]\tvalid_0's multi_logloss: 1.30294\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[756]\tvalid_0's multi_logloss: 1.30286\n",
                        "[757]\tvalid_0's multi_logloss: 1.3028\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[758]\tvalid_0's multi_logloss: 1.30275\n",
                        "[759]\tvalid_0's multi_logloss: 1.30271\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[760]\tvalid_0's multi_logloss: 1.30265\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[761]\tvalid_0's multi_logloss: 1.30259\n",
                        "[762]\tvalid_0's multi_logloss: 1.3025\n",
                        "[763]\tvalid_0's multi_logloss: 1.30245\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[764]\tvalid_0's multi_logloss: 1.30237\n",
                        "[765]\tvalid_0's multi_logloss: 1.30229\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[766]\tvalid_0's multi_logloss: 1.30225\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[767]\tvalid_0's multi_logloss: 1.3022\n",
                        "[768]\tvalid_0's multi_logloss: 1.30211\n",
                        "[769]\tvalid_0's multi_logloss: 1.30205\n",
                        "[770]\tvalid_0's multi_logloss: 1.30199\n",
                        "[771]\tvalid_0's multi_logloss: 1.30194\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[772]\tvalid_0's multi_logloss: 1.30188\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[773]\tvalid_0's multi_logloss: 1.30181\n",
                        "[774]\tvalid_0's multi_logloss: 1.30176\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[775]\tvalid_0's multi_logloss: 1.30168\n",
                        "[776]\tvalid_0's multi_logloss: 1.30162\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[777]\tvalid_0's multi_logloss: 1.30155\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[778]\tvalid_0's multi_logloss: 1.30148\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[779]\tvalid_0's multi_logloss: 1.30143\n",
                        "[780]\tvalid_0's multi_logloss: 1.30138\n",
                        "[781]\tvalid_0's multi_logloss: 1.30134\n",
                        "[782]\tvalid_0's multi_logloss: 1.30128\n",
                        "[783]\tvalid_0's multi_logloss: 1.30122\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[784]\tvalid_0's multi_logloss: 1.30115\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[785]\tvalid_0's multi_logloss: 1.30109\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[786]\tvalid_0's multi_logloss: 1.30102\n",
                        "[787]\tvalid_0's multi_logloss: 1.30096\n",
                        "[788]\tvalid_0's multi_logloss: 1.30089\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[789]\tvalid_0's multi_logloss: 1.30085\n",
                        "[790]\tvalid_0's multi_logloss: 1.30081\n",
                        "[791]\tvalid_0's multi_logloss: 1.30075\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[792]\tvalid_0's multi_logloss: 1.30071\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[793]\tvalid_0's multi_logloss: 1.30069\n",
                        "[794]\tvalid_0's multi_logloss: 1.30062\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[795]\tvalid_0's multi_logloss: 1.30057\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[796]\tvalid_0's multi_logloss: 1.30048\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[797]\tvalid_0's multi_logloss: 1.30043\n",
                        "[798]\tvalid_0's multi_logloss: 1.30037\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[799]\tvalid_0's multi_logloss: 1.30032\n",
                        "[800]\tvalid_0's multi_logloss: 1.30026\n",
                        "[801]\tvalid_0's multi_logloss: 1.30022\n",
                        "[802]\tvalid_0's multi_logloss: 1.30016\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[803]\tvalid_0's multi_logloss: 1.30008\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[804]\tvalid_0's multi_logloss: 1.30004\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[805]\tvalid_0's multi_logloss: 1.29999\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[806]\tvalid_0's multi_logloss: 1.29994\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[807]\tvalid_0's multi_logloss: 1.29989\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[808]\tvalid_0's multi_logloss: 1.29981\n",
                        "[809]\tvalid_0's multi_logloss: 1.29974\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[810]\tvalid_0's multi_logloss: 1.29969\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[811]\tvalid_0's multi_logloss: 1.29965\n",
                        "[812]\tvalid_0's multi_logloss: 1.29961\n",
                        "[813]\tvalid_0's multi_logloss: 1.29955\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[814]\tvalid_0's multi_logloss: 1.2995\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[815]\tvalid_0's multi_logloss: 1.29945\n",
                        "[816]\tvalid_0's multi_logloss: 1.29938\n",
                        "[817]\tvalid_0's multi_logloss: 1.29932\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[818]\tvalid_0's multi_logloss: 1.29927\n",
                        "[819]\tvalid_0's multi_logloss: 1.29922\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[820]\tvalid_0's multi_logloss: 1.29919\n",
                        "[821]\tvalid_0's multi_logloss: 1.29914\n",
                        "[822]\tvalid_0's multi_logloss: 1.29907\n",
                        "[823]\tvalid_0's multi_logloss: 1.29902\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[824]\tvalid_0's multi_logloss: 1.29895\n",
                        "[825]\tvalid_0's multi_logloss: 1.2989\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[826]\tvalid_0's multi_logloss: 1.29884\n",
                        "[827]\tvalid_0's multi_logloss: 1.29878\n",
                        "[828]\tvalid_0's multi_logloss: 1.29872\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[829]\tvalid_0's multi_logloss: 1.29867\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[830]\tvalid_0's multi_logloss: 1.29862\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[831]\tvalid_0's multi_logloss: 1.29857\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[832]\tvalid_0's multi_logloss: 1.29851\n",
                        "[833]\tvalid_0's multi_logloss: 1.29844\n",
                        "[834]\tvalid_0's multi_logloss: 1.29839\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[835]\tvalid_0's multi_logloss: 1.29834\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[836]\tvalid_0's multi_logloss: 1.2983\n",
                        "[837]\tvalid_0's multi_logloss: 1.29823\n",
                        "[838]\tvalid_0's multi_logloss: 1.2982\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[839]\tvalid_0's multi_logloss: 1.29815\n",
                        "[840]\tvalid_0's multi_logloss: 1.29808\n",
                        "[841]\tvalid_0's multi_logloss: 1.298\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[842]\tvalid_0's multi_logloss: 1.29795\n",
                        "[843]\tvalid_0's multi_logloss: 1.29791\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[844]\tvalid_0's multi_logloss: 1.29786\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[845]\tvalid_0's multi_logloss: 1.29779\n",
                        "[846]\tvalid_0's multi_logloss: 1.29775\n",
                        "[847]\tvalid_0's multi_logloss: 1.29769\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[848]\tvalid_0's multi_logloss: 1.29766\n",
                        "[849]\tvalid_0's multi_logloss: 1.2976\n",
                        "[850]\tvalid_0's multi_logloss: 1.29756\n",
                        "[851]\tvalid_0's multi_logloss: 1.29752\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[852]\tvalid_0's multi_logloss: 1.29747\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[853]\tvalid_0's multi_logloss: 1.29741\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[854]\tvalid_0's multi_logloss: 1.29736\n",
                        "[855]\tvalid_0's multi_logloss: 1.29731\n",
                        "[856]\tvalid_0's multi_logloss: 1.29726\n",
                        "[857]\tvalid_0's multi_logloss: 1.29721\n",
                        "[858]\tvalid_0's multi_logloss: 1.29714\n",
                        "[859]\tvalid_0's multi_logloss: 1.2971\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[860]\tvalid_0's multi_logloss: 1.29704\n",
                        "[861]\tvalid_0's multi_logloss: 1.29698\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[862]\tvalid_0's multi_logloss: 1.29696\n",
                        "[863]\tvalid_0's multi_logloss: 1.29692\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[864]\tvalid_0's multi_logloss: 1.29688\n",
                        "[865]\tvalid_0's multi_logloss: 1.29683\n",
                        "[866]\tvalid_0's multi_logloss: 1.29678\n",
                        "[867]\tvalid_0's multi_logloss: 1.29674\n",
                        "[868]\tvalid_0's multi_logloss: 1.29669\n",
                        "[869]\tvalid_0's multi_logloss: 1.29664\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[870]\tvalid_0's multi_logloss: 1.29659\n",
                        "[871]\tvalid_0's multi_logloss: 1.29654\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[872]\tvalid_0's multi_logloss: 1.29649\n",
                        "[873]\tvalid_0's multi_logloss: 1.29645\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[874]\tvalid_0's multi_logloss: 1.29641\n",
                        "[875]\tvalid_0's multi_logloss: 1.29635\n",
                        "[876]\tvalid_0's multi_logloss: 1.29631\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[877]\tvalid_0's multi_logloss: 1.29629\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[878]\tvalid_0's multi_logloss: 1.29625\n",
                        "[879]\tvalid_0's multi_logloss: 1.29621\n",
                        "[880]\tvalid_0's multi_logloss: 1.29615\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[881]\tvalid_0's multi_logloss: 1.29609\n",
                        "[882]\tvalid_0's multi_logloss: 1.29604\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[883]\tvalid_0's multi_logloss: 1.29599\n",
                        "[884]\tvalid_0's multi_logloss: 1.29594\n",
                        "[885]\tvalid_0's multi_logloss: 1.2959\n",
                        "[886]\tvalid_0's multi_logloss: 1.29584\n",
                        "[887]\tvalid_0's multi_logloss: 1.29579\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[888]\tvalid_0's multi_logloss: 1.29573\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[889]\tvalid_0's multi_logloss: 1.29572\n",
                        "[890]\tvalid_0's multi_logloss: 1.29567\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[891]\tvalid_0's multi_logloss: 1.29563\n",
                        "[892]\tvalid_0's multi_logloss: 1.29557\n",
                        "[893]\tvalid_0's multi_logloss: 1.29552\n",
                        "[894]\tvalid_0's multi_logloss: 1.29548\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[895]\tvalid_0's multi_logloss: 1.29544\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[896]\tvalid_0's multi_logloss: 1.29539\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[897]\tvalid_0's multi_logloss: 1.29535\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[898]\tvalid_0's multi_logloss: 1.2953\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[899]\tvalid_0's multi_logloss: 1.29523\n",
                        "[900]\tvalid_0's multi_logloss: 1.29518\n",
                        "[901]\tvalid_0's multi_logloss: 1.29515\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[902]\tvalid_0's multi_logloss: 1.29512\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[903]\tvalid_0's multi_logloss: 1.29508\n",
                        "[904]\tvalid_0's multi_logloss: 1.29501\n",
                        "[905]\tvalid_0's multi_logloss: 1.29496\n",
                        "[906]\tvalid_0's multi_logloss: 1.29492\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[907]\tvalid_0's multi_logloss: 1.29486\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[908]\tvalid_0's multi_logloss: 1.29481\n",
                        "[909]\tvalid_0's multi_logloss: 1.29473\n",
                        "[910]\tvalid_0's multi_logloss: 1.29468\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[911]\tvalid_0's multi_logloss: 1.29464\n",
                        "[912]\tvalid_0's multi_logloss: 1.29459\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[913]\tvalid_0's multi_logloss: 1.29455\n",
                        "[914]\tvalid_0's multi_logloss: 1.29451\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[915]\tvalid_0's multi_logloss: 1.29443\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[916]\tvalid_0's multi_logloss: 1.29439\n",
                        "[917]\tvalid_0's multi_logloss: 1.29433\n",
                        "[918]\tvalid_0's multi_logloss: 1.29427\n",
                        "[919]\tvalid_0's multi_logloss: 1.29421\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[920]\tvalid_0's multi_logloss: 1.29417\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[921]\tvalid_0's multi_logloss: 1.29411\n",
                        "[922]\tvalid_0's multi_logloss: 1.29405\n",
                        "[923]\tvalid_0's multi_logloss: 1.29401\n",
                        "[924]\tvalid_0's multi_logloss: 1.29397\n",
                        "[925]\tvalid_0's multi_logloss: 1.29391\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[926]\tvalid_0's multi_logloss: 1.29387\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[927]\tvalid_0's multi_logloss: 1.29383\n",
                        "[928]\tvalid_0's multi_logloss: 1.29377\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[929]\tvalid_0's multi_logloss: 1.29374\n",
                        "[930]\tvalid_0's multi_logloss: 1.2937\n",
                        "[931]\tvalid_0's multi_logloss: 1.29363\n",
                        "[932]\tvalid_0's multi_logloss: 1.29358\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[933]\tvalid_0's multi_logloss: 1.29353\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[934]\tvalid_0's multi_logloss: 1.29348\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[935]\tvalid_0's multi_logloss: 1.29345\n",
                        "[936]\tvalid_0's multi_logloss: 1.29341\n",
                        "[937]\tvalid_0's multi_logloss: 1.29337\n",
                        "[938]\tvalid_0's multi_logloss: 1.29332\n",
                        "[939]\tvalid_0's multi_logloss: 1.29329\n",
                        "[940]\tvalid_0's multi_logloss: 1.29324\n",
                        "[941]\tvalid_0's multi_logloss: 1.29318\n",
                        "[942]\tvalid_0's multi_logloss: 1.29313\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[943]\tvalid_0's multi_logloss: 1.29309\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[944]\tvalid_0's multi_logloss: 1.29304\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[945]\tvalid_0's multi_logloss: 1.29299\n",
                        "[946]\tvalid_0's multi_logloss: 1.29295\n",
                        "[947]\tvalid_0's multi_logloss: 1.29291\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[948]\tvalid_0's multi_logloss: 1.29286\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[949]\tvalid_0's multi_logloss: 1.29282\n",
                        "[950]\tvalid_0's multi_logloss: 1.29276\n",
                        "[951]\tvalid_0's multi_logloss: 1.29268\n",
                        "[952]\tvalid_0's multi_logloss: 1.29262\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[953]\tvalid_0's multi_logloss: 1.29257\n",
                        "[954]\tvalid_0's multi_logloss: 1.29253\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[955]\tvalid_0's multi_logloss: 1.29248\n",
                        "[956]\tvalid_0's multi_logloss: 1.29244\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[957]\tvalid_0's multi_logloss: 1.29238\n",
                        "[958]\tvalid_0's multi_logloss: 1.29234\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[959]\tvalid_0's multi_logloss: 1.29229\n",
                        "[960]\tvalid_0's multi_logloss: 1.29225\n",
                        "[961]\tvalid_0's multi_logloss: 1.29217\n",
                        "[962]\tvalid_0's multi_logloss: 1.29213\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[963]\tvalid_0's multi_logloss: 1.29208\n",
                        "[964]\tvalid_0's multi_logloss: 1.29202\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[965]\tvalid_0's multi_logloss: 1.29197\n",
                        "[966]\tvalid_0's multi_logloss: 1.29193\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[967]\tvalid_0's multi_logloss: 1.29189\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[968]\tvalid_0's multi_logloss: 1.29184\n",
                        "[969]\tvalid_0's multi_logloss: 1.29178\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[970]\tvalid_0's multi_logloss: 1.29172\n",
                        "[971]\tvalid_0's multi_logloss: 1.29168\n",
                        "[972]\tvalid_0's multi_logloss: 1.29163\n",
                        "[973]\tvalid_0's multi_logloss: 1.29159\n",
                        "[974]\tvalid_0's multi_logloss: 1.29153\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[975]\tvalid_0's multi_logloss: 1.29149\n",
                        "[976]\tvalid_0's multi_logloss: 1.29145\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[977]\tvalid_0's multi_logloss: 1.29141\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[978]\tvalid_0's multi_logloss: 1.29136\n",
                        "[979]\tvalid_0's multi_logloss: 1.29133\n",
                        "[980]\tvalid_0's multi_logloss: 1.2913\n",
                        "[981]\tvalid_0's multi_logloss: 1.29126\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[982]\tvalid_0's multi_logloss: 1.29123\n",
                        "[983]\tvalid_0's multi_logloss: 1.29118\n",
                        "[984]\tvalid_0's multi_logloss: 1.29113\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[985]\tvalid_0's multi_logloss: 1.2911\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[986]\tvalid_0's multi_logloss: 1.29107\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[987]\tvalid_0's multi_logloss: 1.29102\n",
                        "[988]\tvalid_0's multi_logloss: 1.29096\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[989]\tvalid_0's multi_logloss: 1.29091\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[990]\tvalid_0's multi_logloss: 1.29087\n",
                        "[991]\tvalid_0's multi_logloss: 1.29084\n",
                        "[992]\tvalid_0's multi_logloss: 1.29079\n",
                        "[993]\tvalid_0's multi_logloss: 1.29075\n",
                        "[994]\tvalid_0's multi_logloss: 1.29069\n",
                        "[995]\tvalid_0's multi_logloss: 1.29066\n",
                        "[996]\tvalid_0's multi_logloss: 1.2906\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[997]\tvalid_0's multi_logloss: 1.29055\n",
                        "[998]\tvalid_0's multi_logloss: 1.29051\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[999]\tvalid_0's multi_logloss: 1.29046\n",
                        "[1000]\tvalid_0's multi_logloss: 1.29041\n",
                        "[1001]\tvalid_0's multi_logloss: 1.29035\n",
                        "[1002]\tvalid_0's multi_logloss: 1.29032\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1003]\tvalid_0's multi_logloss: 1.29028\n",
                        "[1004]\tvalid_0's multi_logloss: 1.29023\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1005]\tvalid_0's multi_logloss: 1.29018\n",
                        "[1006]\tvalid_0's multi_logloss: 1.29015\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1007]\tvalid_0's multi_logloss: 1.2901\n",
                        "[1008]\tvalid_0's multi_logloss: 1.29005\n",
                        "[1009]\tvalid_0's multi_logloss: 1.29\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1010]\tvalid_0's multi_logloss: 1.28995\n",
                        "[1011]\tvalid_0's multi_logloss: 1.28989\n",
                        "[1012]\tvalid_0's multi_logloss: 1.28985\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1013]\tvalid_0's multi_logloss: 1.28981\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1014]\tvalid_0's multi_logloss: 1.28977\n",
                        "[1015]\tvalid_0's multi_logloss: 1.28974\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1016]\tvalid_0's multi_logloss: 1.28969\n",
                        "[1017]\tvalid_0's multi_logloss: 1.28961\n",
                        "[1018]\tvalid_0's multi_logloss: 1.28957\n",
                        "[1019]\tvalid_0's multi_logloss: 1.28953\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1020]\tvalid_0's multi_logloss: 1.28951\n",
                        "[1021]\tvalid_0's multi_logloss: 1.28947\n",
                        "[1022]\tvalid_0's multi_logloss: 1.28942\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1023]\tvalid_0's multi_logloss: 1.28935\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1024]\tvalid_0's multi_logloss: 1.2893\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1025]\tvalid_0's multi_logloss: 1.28925\n",
                        "[1026]\tvalid_0's multi_logloss: 1.28922\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1027]\tvalid_0's multi_logloss: 1.28918\n",
                        "[1028]\tvalid_0's multi_logloss: 1.28913\n",
                        "[1029]\tvalid_0's multi_logloss: 1.2891\n",
                        "[1030]\tvalid_0's multi_logloss: 1.28905\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1031]\tvalid_0's multi_logloss: 1.28902\n",
                        "[1032]\tvalid_0's multi_logloss: 1.28899\n",
                        "[1033]\tvalid_0's multi_logloss: 1.28895\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1034]\tvalid_0's multi_logloss: 1.28893\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1035]\tvalid_0's multi_logloss: 1.28891\n",
                        "[1036]\tvalid_0's multi_logloss: 1.28885\n",
                        "[1037]\tvalid_0's multi_logloss: 1.28882\n",
                        "[1038]\tvalid_0's multi_logloss: 1.28877\n",
                        "[1039]\tvalid_0's multi_logloss: 1.28872\n",
                        "[1040]\tvalid_0's multi_logloss: 1.28868\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1041]\tvalid_0's multi_logloss: 1.28865\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1042]\tvalid_0's multi_logloss: 1.28863\n",
                        "[1043]\tvalid_0's multi_logloss: 1.28859\n",
                        "[1044]\tvalid_0's multi_logloss: 1.28854\n",
                        "[1045]\tvalid_0's multi_logloss: 1.28851\n",
                        "[1046]\tvalid_0's multi_logloss: 1.28848\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1047]\tvalid_0's multi_logloss: 1.28844\n",
                        "[1048]\tvalid_0's multi_logloss: 1.28839\n",
                        "[1049]\tvalid_0's multi_logloss: 1.28836\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1050]\tvalid_0's multi_logloss: 1.28831\n",
                        "[1051]\tvalid_0's multi_logloss: 1.28826\n",
                        "[1052]\tvalid_0's multi_logloss: 1.28822\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1053]\tvalid_0's multi_logloss: 1.28818\n",
                        "[1054]\tvalid_0's multi_logloss: 1.28814\n",
                        "[1055]\tvalid_0's multi_logloss: 1.2881\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1056]\tvalid_0's multi_logloss: 1.28806\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1057]\tvalid_0's multi_logloss: 1.28804\n",
                        "[1058]\tvalid_0's multi_logloss: 1.28801\n",
                        "[1059]\tvalid_0's multi_logloss: 1.28797\n",
                        "[1060]\tvalid_0's multi_logloss: 1.28792\n",
                        "[1061]\tvalid_0's multi_logloss: 1.28789\n",
                        "[1062]\tvalid_0's multi_logloss: 1.28786\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1063]\tvalid_0's multi_logloss: 1.28781\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1064]\tvalid_0's multi_logloss: 1.28777\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1065]\tvalid_0's multi_logloss: 1.28775\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1066]\tvalid_0's multi_logloss: 1.28771\n",
                        "[1067]\tvalid_0's multi_logloss: 1.28764\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1068]\tvalid_0's multi_logloss: 1.28757\n",
                        "[1069]\tvalid_0's multi_logloss: 1.28754\n",
                        "[1070]\tvalid_0's multi_logloss: 1.28751\n",
                        "[1071]\tvalid_0's multi_logloss: 1.28745\n",
                        "[1072]\tvalid_0's multi_logloss: 1.2874\n",
                        "[1073]\tvalid_0's multi_logloss: 1.28738\n",
                        "[1074]\tvalid_0's multi_logloss: 1.28735\n",
                        "[1075]\tvalid_0's multi_logloss: 1.28732\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1076]\tvalid_0's multi_logloss: 1.28728\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1077]\tvalid_0's multi_logloss: 1.28723\n",
                        "[1078]\tvalid_0's multi_logloss: 1.28719\n",
                        "[1079]\tvalid_0's multi_logloss: 1.28715\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1080]\tvalid_0's multi_logloss: 1.28712\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1081]\tvalid_0's multi_logloss: 1.28709\n",
                        "[1082]\tvalid_0's multi_logloss: 1.28707\n",
                        "[1083]\tvalid_0's multi_logloss: 1.28703\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1084]\tvalid_0's multi_logloss: 1.28698\n",
                        "[1085]\tvalid_0's multi_logloss: 1.28695\n",
                        "[1086]\tvalid_0's multi_logloss: 1.28693\n",
                        "[1087]\tvalid_0's multi_logloss: 1.28688\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1088]\tvalid_0's multi_logloss: 1.28684\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1089]\tvalid_0's multi_logloss: 1.28679\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1090]\tvalid_0's multi_logloss: 1.28676\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1091]\tvalid_0's multi_logloss: 1.28674\n",
                        "[1092]\tvalid_0's multi_logloss: 1.28671\n",
                        "[1093]\tvalid_0's multi_logloss: 1.28668\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1094]\tvalid_0's multi_logloss: 1.28665\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1095]\tvalid_0's multi_logloss: 1.28661\n",
                        "[1096]\tvalid_0's multi_logloss: 1.28658\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1097]\tvalid_0's multi_logloss: 1.28654\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1098]\tvalid_0's multi_logloss: 1.28649\n",
                        "[1099]\tvalid_0's multi_logloss: 1.28646\n",
                        "[1100]\tvalid_0's multi_logloss: 1.28643\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1101]\tvalid_0's multi_logloss: 1.28639\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1102]\tvalid_0's multi_logloss: 1.28637\n",
                        "[1103]\tvalid_0's multi_logloss: 1.28633\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1104]\tvalid_0's multi_logloss: 1.28629\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1105]\tvalid_0's multi_logloss: 1.28626\n",
                        "[1106]\tvalid_0's multi_logloss: 1.28622\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1107]\tvalid_0's multi_logloss: 1.28619\n",
                        "[1108]\tvalid_0's multi_logloss: 1.28616\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1109]\tvalid_0's multi_logloss: 1.28612\n",
                        "[1110]\tvalid_0's multi_logloss: 1.28608\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1111]\tvalid_0's multi_logloss: 1.28604\n",
                        "[1112]\tvalid_0's multi_logloss: 1.28601\n",
                        "[1113]\tvalid_0's multi_logloss: 1.28597\n",
                        "[1114]\tvalid_0's multi_logloss: 1.28594\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1115]\tvalid_0's multi_logloss: 1.28591\n",
                        "[1116]\tvalid_0's multi_logloss: 1.28586\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1117]\tvalid_0's multi_logloss: 1.2858\n",
                        "[1118]\tvalid_0's multi_logloss: 1.28576\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1119]\tvalid_0's multi_logloss: 1.28573\n",
                        "[1120]\tvalid_0's multi_logloss: 1.28569\n",
                        "[1121]\tvalid_0's multi_logloss: 1.28568\n",
                        "[1122]\tvalid_0's multi_logloss: 1.28564\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1123]\tvalid_0's multi_logloss: 1.28562\n",
                        "[1124]\tvalid_0's multi_logloss: 1.2856\n",
                        "[1125]\tvalid_0's multi_logloss: 1.28558\n",
                        "[1126]\tvalid_0's multi_logloss: 1.28554\n",
                        "[1127]\tvalid_0's multi_logloss: 1.2855\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1128]\tvalid_0's multi_logloss: 1.28546\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1129]\tvalid_0's multi_logloss: 1.28542\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1130]\tvalid_0's multi_logloss: 1.28538\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1131]\tvalid_0's multi_logloss: 1.28534\n",
                        "[1132]\tvalid_0's multi_logloss: 1.28532\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1133]\tvalid_0's multi_logloss: 1.28529\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1134]\tvalid_0's multi_logloss: 1.28526\n",
                        "[1135]\tvalid_0's multi_logloss: 1.28523\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1136]\tvalid_0's multi_logloss: 1.28519\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1137]\tvalid_0's multi_logloss: 1.28516\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1138]\tvalid_0's multi_logloss: 1.28513\n",
                        "[1139]\tvalid_0's multi_logloss: 1.28509\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1140]\tvalid_0's multi_logloss: 1.28505\n",
                        "[1141]\tvalid_0's multi_logloss: 1.28501\n",
                        "[1142]\tvalid_0's multi_logloss: 1.28498\n",
                        "[1143]\tvalid_0's multi_logloss: 1.28495\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1144]\tvalid_0's multi_logloss: 1.28493\n",
                        "[1145]\tvalid_0's multi_logloss: 1.28491\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1146]\tvalid_0's multi_logloss: 1.28486\n",
                        "[1147]\tvalid_0's multi_logloss: 1.28482\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1148]\tvalid_0's multi_logloss: 1.2848\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1149]\tvalid_0's multi_logloss: 1.28475\n",
                        "[1150]\tvalid_0's multi_logloss: 1.28472\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1151]\tvalid_0's multi_logloss: 1.28469\n",
                        "[1152]\tvalid_0's multi_logloss: 1.28467\n",
                        "[1153]\tvalid_0's multi_logloss: 1.28464\n",
                        "[1154]\tvalid_0's multi_logloss: 1.28461\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1155]\tvalid_0's multi_logloss: 1.28459\n",
                        "[1156]\tvalid_0's multi_logloss: 1.28455\n",
                        "[1157]\tvalid_0's multi_logloss: 1.28451\n",
                        "[1158]\tvalid_0's multi_logloss: 1.28447\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1159]\tvalid_0's multi_logloss: 1.28444\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1160]\tvalid_0's multi_logloss: 1.2844\n",
                        "[1161]\tvalid_0's multi_logloss: 1.28436\n",
                        "[1162]\tvalid_0's multi_logloss: 1.28433\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1163]\tvalid_0's multi_logloss: 1.28428\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1164]\tvalid_0's multi_logloss: 1.28426\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1165]\tvalid_0's multi_logloss: 1.28422\n",
                        "[1166]\tvalid_0's multi_logloss: 1.28418\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1167]\tvalid_0's multi_logloss: 1.28415\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1168]\tvalid_0's multi_logloss: 1.28412\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1169]\tvalid_0's multi_logloss: 1.28409\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1170]\tvalid_0's multi_logloss: 1.28407\n",
                        "[1171]\tvalid_0's multi_logloss: 1.28404\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1172]\tvalid_0's multi_logloss: 1.28399\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1173]\tvalid_0's multi_logloss: 1.28397\n",
                        "[1174]\tvalid_0's multi_logloss: 1.28394\n",
                        "[1175]\tvalid_0's multi_logloss: 1.2839\n",
                        "[1176]\tvalid_0's multi_logloss: 1.28387\n",
                        "[1177]\tvalid_0's multi_logloss: 1.28382\n",
                        "[1178]\tvalid_0's multi_logloss: 1.28378\n",
                        "[1179]\tvalid_0's multi_logloss: 1.28374\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1180]\tvalid_0's multi_logloss: 1.2837\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1181]\tvalid_0's multi_logloss: 1.28368\n",
                        "[1182]\tvalid_0's multi_logloss: 1.28363\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1183]\tvalid_0's multi_logloss: 1.28358\n",
                        "[1184]\tvalid_0's multi_logloss: 1.28355\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1185]\tvalid_0's multi_logloss: 1.28351\n",
                        "[1186]\tvalid_0's multi_logloss: 1.28345\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1187]\tvalid_0's multi_logloss: 1.28341\n",
                        "[1188]\tvalid_0's multi_logloss: 1.28338\n",
                        "[1189]\tvalid_0's multi_logloss: 1.28335\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1190]\tvalid_0's multi_logloss: 1.28331\n",
                        "[1191]\tvalid_0's multi_logloss: 1.28328\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1192]\tvalid_0's multi_logloss: 1.28326\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1193]\tvalid_0's multi_logloss: 1.28323\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1194]\tvalid_0's multi_logloss: 1.28321\n",
                        "[1195]\tvalid_0's multi_logloss: 1.28318\n",
                        "[1196]\tvalid_0's multi_logloss: 1.28316\n",
                        "[1197]\tvalid_0's multi_logloss: 1.28312\n",
                        "[1198]\tvalid_0's multi_logloss: 1.28307\n",
                        "[1199]\tvalid_0's multi_logloss: 1.28305\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1200]\tvalid_0's multi_logloss: 1.28302\n",
                        "[1201]\tvalid_0's multi_logloss: 1.28299\n",
                        "[1202]\tvalid_0's multi_logloss: 1.28295\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1203]\tvalid_0's multi_logloss: 1.28293\n",
                        "[1204]\tvalid_0's multi_logloss: 1.28288\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1205]\tvalid_0's multi_logloss: 1.28283\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1206]\tvalid_0's multi_logloss: 1.28279\n",
                        "[1207]\tvalid_0's multi_logloss: 1.28274\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1208]\tvalid_0's multi_logloss: 1.28272\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1209]\tvalid_0's multi_logloss: 1.28269\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1210]\tvalid_0's multi_logloss: 1.28265\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1211]\tvalid_0's multi_logloss: 1.28262\n",
                        "[1212]\tvalid_0's multi_logloss: 1.28258\n",
                        "[1213]\tvalid_0's multi_logloss: 1.28254\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1214]\tvalid_0's multi_logloss: 1.28253\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1215]\tvalid_0's multi_logloss: 1.28251\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1216]\tvalid_0's multi_logloss: 1.28246\n",
                        "[1217]\tvalid_0's multi_logloss: 1.28242\n",
                        "[1218]\tvalid_0's multi_logloss: 1.28236\n",
                        "[1219]\tvalid_0's multi_logloss: 1.28232\n",
                        "[1220]\tvalid_0's multi_logloss: 1.28227\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1221]\tvalid_0's multi_logloss: 1.28223\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1222]\tvalid_0's multi_logloss: 1.28221\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1223]\tvalid_0's multi_logloss: 1.28218\n",
                        "[1224]\tvalid_0's multi_logloss: 1.28217\n",
                        "[1225]\tvalid_0's multi_logloss: 1.28214\n",
                        "[1226]\tvalid_0's multi_logloss: 1.28213\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1227]\tvalid_0's multi_logloss: 1.28209\n",
                        "[1228]\tvalid_0's multi_logloss: 1.28205\n",
                        "[1229]\tvalid_0's multi_logloss: 1.28203\n",
                        "[1230]\tvalid_0's multi_logloss: 1.28201\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1231]\tvalid_0's multi_logloss: 1.28195\n",
                        "[1232]\tvalid_0's multi_logloss: 1.28192\n",
                        "[1233]\tvalid_0's multi_logloss: 1.28188\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1234]\tvalid_0's multi_logloss: 1.28186\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1235]\tvalid_0's multi_logloss: 1.28185\n",
                        "[1236]\tvalid_0's multi_logloss: 1.28182\n",
                        "[1237]\tvalid_0's multi_logloss: 1.28177\n",
                        "[1238]\tvalid_0's multi_logloss: 1.28173\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1239]\tvalid_0's multi_logloss: 1.28171\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1240]\tvalid_0's multi_logloss: 1.28168\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1241]\tvalid_0's multi_logloss: 1.28166\n",
                        "[1242]\tvalid_0's multi_logloss: 1.28164\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1243]\tvalid_0's multi_logloss: 1.28161\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1244]\tvalid_0's multi_logloss: 1.28159\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1245]\tvalid_0's multi_logloss: 1.28155\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1246]\tvalid_0's multi_logloss: 1.28151\n",
                        "[1247]\tvalid_0's multi_logloss: 1.28147\n",
                        "[1248]\tvalid_0's multi_logloss: 1.28144\n",
                        "[1249]\tvalid_0's multi_logloss: 1.2814\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1250]\tvalid_0's multi_logloss: 1.28138\n",
                        "[1251]\tvalid_0's multi_logloss: 1.28134\n",
                        "[1252]\tvalid_0's multi_logloss: 1.28134\n",
                        "[1253]\tvalid_0's multi_logloss: 1.2813\n",
                        "[1254]\tvalid_0's multi_logloss: 1.28125\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1255]\tvalid_0's multi_logloss: 1.28123\n",
                        "[1256]\tvalid_0's multi_logloss: 1.28117\n",
                        "[1257]\tvalid_0's multi_logloss: 1.28116\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1258]\tvalid_0's multi_logloss: 1.28112\n",
                        "[1259]\tvalid_0's multi_logloss: 1.28108\n",
                        "[1260]\tvalid_0's multi_logloss: 1.28104\n",
                        "[1261]\tvalid_0's multi_logloss: 1.28099\n",
                        "[1262]\tvalid_0's multi_logloss: 1.28094\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1263]\tvalid_0's multi_logloss: 1.28091\n",
                        "[1264]\tvalid_0's multi_logloss: 1.28088\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1265]\tvalid_0's multi_logloss: 1.28084\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1266]\tvalid_0's multi_logloss: 1.28081\n",
                        "[1267]\tvalid_0's multi_logloss: 1.28075\n",
                        "[1268]\tvalid_0's multi_logloss: 1.28074\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1269]\tvalid_0's multi_logloss: 1.28072\n",
                        "[1270]\tvalid_0's multi_logloss: 1.28068\n",
                        "[1271]\tvalid_0's multi_logloss: 1.28064\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1272]\tvalid_0's multi_logloss: 1.28063\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1273]\tvalid_0's multi_logloss: 1.28059\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1274]\tvalid_0's multi_logloss: 1.28057\n",
                        "[1275]\tvalid_0's multi_logloss: 1.28052\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1276]\tvalid_0's multi_logloss: 1.28048\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1277]\tvalid_0's multi_logloss: 1.28044\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1278]\tvalid_0's multi_logloss: 1.2804\n",
                        "[1279]\tvalid_0's multi_logloss: 1.28035\n",
                        "[1280]\tvalid_0's multi_logloss: 1.28032\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1281]\tvalid_0's multi_logloss: 1.28027\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1282]\tvalid_0's multi_logloss: 1.28025\n",
                        "[1283]\tvalid_0's multi_logloss: 1.2802\n",
                        "[1284]\tvalid_0's multi_logloss: 1.28017\n",
                        "[1285]\tvalid_0's multi_logloss: 1.28014\n",
                        "[1286]\tvalid_0's multi_logloss: 1.28011\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1287]\tvalid_0's multi_logloss: 1.28009\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1288]\tvalid_0's multi_logloss: 1.28006\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1289]\tvalid_0's multi_logloss: 1.28002\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1290]\tvalid_0's multi_logloss: 1.28\n",
                        "[1291]\tvalid_0's multi_logloss: 1.27996\n",
                        "[1292]\tvalid_0's multi_logloss: 1.27993\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1293]\tvalid_0's multi_logloss: 1.2799\n",
                        "[1294]\tvalid_0's multi_logloss: 1.27989\n",
                        "[1295]\tvalid_0's multi_logloss: 1.27984\n",
                        "[1296]\tvalid_0's multi_logloss: 1.27981\n",
                        "[1297]\tvalid_0's multi_logloss: 1.27978\n",
                        "[1298]\tvalid_0's multi_logloss: 1.27977\n",
                        "[1299]\tvalid_0's multi_logloss: 1.27975\n",
                        "[1300]\tvalid_0's multi_logloss: 1.27971\n",
                        "[1301]\tvalid_0's multi_logloss: 1.2797\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1302]\tvalid_0's multi_logloss: 1.27967\n",
                        "[1303]\tvalid_0's multi_logloss: 1.27962\n",
                        "[1304]\tvalid_0's multi_logloss: 1.27958\n",
                        "[1305]\tvalid_0's multi_logloss: 1.27957\n",
                        "[1306]\tvalid_0's multi_logloss: 1.27954\n",
                        "[1307]\tvalid_0's multi_logloss: 1.27949\n",
                        "[1308]\tvalid_0's multi_logloss: 1.27947\n",
                        "[1309]\tvalid_0's multi_logloss: 1.27946\n",
                        "[1310]\tvalid_0's multi_logloss: 1.27943\n",
                        "[1311]\tvalid_0's multi_logloss: 1.27939\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1312]\tvalid_0's multi_logloss: 1.27935\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1313]\tvalid_0's multi_logloss: 1.27933\n",
                        "[1314]\tvalid_0's multi_logloss: 1.2793\n",
                        "[1315]\tvalid_0's multi_logloss: 1.27926\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1316]\tvalid_0's multi_logloss: 1.27923\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1317]\tvalid_0's multi_logloss: 1.2792\n",
                        "[1318]\tvalid_0's multi_logloss: 1.27917\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1319]\tvalid_0's multi_logloss: 1.27914\n",
                        "[1320]\tvalid_0's multi_logloss: 1.2791\n",
                        "[1321]\tvalid_0's multi_logloss: 1.27907\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1322]\tvalid_0's multi_logloss: 1.27905\n",
                        "[1323]\tvalid_0's multi_logloss: 1.27901\n",
                        "[1324]\tvalid_0's multi_logloss: 1.279\n",
                        "[1325]\tvalid_0's multi_logloss: 1.27899\n",
                        "[1326]\tvalid_0's multi_logloss: 1.27895\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1327]\tvalid_0's multi_logloss: 1.27893\n",
                        "[1328]\tvalid_0's multi_logloss: 1.27889\n",
                        "[1329]\tvalid_0's multi_logloss: 1.27885\n",
                        "[1330]\tvalid_0's multi_logloss: 1.27881\n",
                        "[1331]\tvalid_0's multi_logloss: 1.27877\n",
                        "[1332]\tvalid_0's multi_logloss: 1.27874\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1333]\tvalid_0's multi_logloss: 1.2787\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1334]\tvalid_0's multi_logloss: 1.27867\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1335]\tvalid_0's multi_logloss: 1.27865\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1336]\tvalid_0's multi_logloss: 1.27861\n",
                        "[1337]\tvalid_0's multi_logloss: 1.27857\n",
                        "[1338]\tvalid_0's multi_logloss: 1.27855\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1339]\tvalid_0's multi_logloss: 1.27852\n",
                        "[1340]\tvalid_0's multi_logloss: 1.27849\n",
                        "[1341]\tvalid_0's multi_logloss: 1.27845\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1342]\tvalid_0's multi_logloss: 1.27843\n",
                        "[1343]\tvalid_0's multi_logloss: 1.27839\n",
                        "[1344]\tvalid_0's multi_logloss: 1.27837\n",
                        "[1345]\tvalid_0's multi_logloss: 1.27835\n",
                        "[1346]\tvalid_0's multi_logloss: 1.27831\n",
                        "[1347]\tvalid_0's multi_logloss: 1.27826\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1348]\tvalid_0's multi_logloss: 1.27823\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1349]\tvalid_0's multi_logloss: 1.2782\n",
                        "[1350]\tvalid_0's multi_logloss: 1.27816\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1351]\tvalid_0's multi_logloss: 1.27815\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1352]\tvalid_0's multi_logloss: 1.27812\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1353]\tvalid_0's multi_logloss: 1.2781\n",
                        "[1354]\tvalid_0's multi_logloss: 1.27807\n",
                        "[1355]\tvalid_0's multi_logloss: 1.27802\n",
                        "[1356]\tvalid_0's multi_logloss: 1.27799\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1357]\tvalid_0's multi_logloss: 1.27796\n",
                        "[1358]\tvalid_0's multi_logloss: 1.27794\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1359]\tvalid_0's multi_logloss: 1.2779\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1360]\tvalid_0's multi_logloss: 1.27787\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1361]\tvalid_0's multi_logloss: 1.27782\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1362]\tvalid_0's multi_logloss: 1.2778\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1363]\tvalid_0's multi_logloss: 1.27778\n",
                        "[1364]\tvalid_0's multi_logloss: 1.27776\n",
                        "[1365]\tvalid_0's multi_logloss: 1.27775\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1366]\tvalid_0's multi_logloss: 1.27773\n",
                        "[1367]\tvalid_0's multi_logloss: 1.27771\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1368]\tvalid_0's multi_logloss: 1.27768\n",
                        "[1369]\tvalid_0's multi_logloss: 1.27766\n",
                        "[1370]\tvalid_0's multi_logloss: 1.27764\n",
                        "[1371]\tvalid_0's multi_logloss: 1.2776\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1372]\tvalid_0's multi_logloss: 1.27756\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1373]\tvalid_0's multi_logloss: 1.27754\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1374]\tvalid_0's multi_logloss: 1.27752\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1375]\tvalid_0's multi_logloss: 1.2775\n",
                        "[1376]\tvalid_0's multi_logloss: 1.27747\n",
                        "[1377]\tvalid_0's multi_logloss: 1.27745\n",
                        "[1378]\tvalid_0's multi_logloss: 1.27741\n",
                        "[1379]\tvalid_0's multi_logloss: 1.27739\n",
                        "[1380]\tvalid_0's multi_logloss: 1.27737\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1381]\tvalid_0's multi_logloss: 1.27733\n",
                        "[1382]\tvalid_0's multi_logloss: 1.27731\n",
                        "[1383]\tvalid_0's multi_logloss: 1.27729\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1384]\tvalid_0's multi_logloss: 1.27727\n",
                        "[1385]\tvalid_0's multi_logloss: 1.27724\n",
                        "[1386]\tvalid_0's multi_logloss: 1.2772\n",
                        "[1387]\tvalid_0's multi_logloss: 1.27718\n",
                        "[1388]\tvalid_0's multi_logloss: 1.27715\n",
                        "[1389]\tvalid_0's multi_logloss: 1.27713\n",
                        "[1390]\tvalid_0's multi_logloss: 1.2771\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1391]\tvalid_0's multi_logloss: 1.27707\n",
                        "[1392]\tvalid_0's multi_logloss: 1.27703\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1393]\tvalid_0's multi_logloss: 1.27701\n",
                        "[1394]\tvalid_0's multi_logloss: 1.27698\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1395]\tvalid_0's multi_logloss: 1.27696\n",
                        "[1396]\tvalid_0's multi_logloss: 1.27692\n",
                        "[1397]\tvalid_0's multi_logloss: 1.27687\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1398]\tvalid_0's multi_logloss: 1.27685\n",
                        "[1399]\tvalid_0's multi_logloss: 1.27681\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1400]\tvalid_0's multi_logloss: 1.27679\n",
                        "[1401]\tvalid_0's multi_logloss: 1.27676\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1402]\tvalid_0's multi_logloss: 1.27675\n",
                        "[1403]\tvalid_0's multi_logloss: 1.27673\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1404]\tvalid_0's multi_logloss: 1.27671\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1405]\tvalid_0's multi_logloss: 1.27667\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1406]\tvalid_0's multi_logloss: 1.27664\n",
                        "[1407]\tvalid_0's multi_logloss: 1.27661\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1408]\tvalid_0's multi_logloss: 1.27658\n",
                        "[1409]\tvalid_0's multi_logloss: 1.27655\n",
                        "[1410]\tvalid_0's multi_logloss: 1.27653\n",
                        "[1411]\tvalid_0's multi_logloss: 1.27651\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1412]\tvalid_0's multi_logloss: 1.27648\n",
                        "[1413]\tvalid_0's multi_logloss: 1.27646\n",
                        "[1414]\tvalid_0's multi_logloss: 1.27644\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1415]\tvalid_0's multi_logloss: 1.27642\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1416]\tvalid_0's multi_logloss: 1.2764\n",
                        "[1417]\tvalid_0's multi_logloss: 1.27637\n",
                        "[1418]\tvalid_0's multi_logloss: 1.27635\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1419]\tvalid_0's multi_logloss: 1.27634\n",
                        "[1420]\tvalid_0's multi_logloss: 1.27631\n",
                        "[1421]\tvalid_0's multi_logloss: 1.27629\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1422]\tvalid_0's multi_logloss: 1.27625\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1423]\tvalid_0's multi_logloss: 1.27622\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1424]\tvalid_0's multi_logloss: 1.27619\n",
                        "[1425]\tvalid_0's multi_logloss: 1.27617\n",
                        "[1426]\tvalid_0's multi_logloss: 1.27615\n",
                        "[1427]\tvalid_0's multi_logloss: 1.27611\n",
                        "[1428]\tvalid_0's multi_logloss: 1.27607\n",
                        "[1429]\tvalid_0's multi_logloss: 1.27606\n",
                        "[1430]\tvalid_0's multi_logloss: 1.27602\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1431]\tvalid_0's multi_logloss: 1.276\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1432]\tvalid_0's multi_logloss: 1.27597\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1433]\tvalid_0's multi_logloss: 1.27595\n",
                        "[1434]\tvalid_0's multi_logloss: 1.27593\n",
                        "[1435]\tvalid_0's multi_logloss: 1.27592\n",
                        "[1436]\tvalid_0's multi_logloss: 1.27587\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1437]\tvalid_0's multi_logloss: 1.27583\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1438]\tvalid_0's multi_logloss: 1.2758\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1439]\tvalid_0's multi_logloss: 1.27579\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1440]\tvalid_0's multi_logloss: 1.27577\n",
                        "[1441]\tvalid_0's multi_logloss: 1.27574\n",
                        "[1442]\tvalid_0's multi_logloss: 1.2757\n",
                        "[1443]\tvalid_0's multi_logloss: 1.27566\n",
                        "[1444]\tvalid_0's multi_logloss: 1.27563\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1445]\tvalid_0's multi_logloss: 1.27562\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1446]\tvalid_0's multi_logloss: 1.27558\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1447]\tvalid_0's multi_logloss: 1.27557\n",
                        "[1448]\tvalid_0's multi_logloss: 1.27551\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1449]\tvalid_0's multi_logloss: 1.27549\n",
                        "[1450]\tvalid_0's multi_logloss: 1.27547\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1451]\tvalid_0's multi_logloss: 1.27543\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1452]\tvalid_0's multi_logloss: 1.27541\n",
                        "[1453]\tvalid_0's multi_logloss: 1.27539\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1454]\tvalid_0's multi_logloss: 1.27538\n",
                        "[1455]\tvalid_0's multi_logloss: 1.27536\n",
                        "[1456]\tvalid_0's multi_logloss: 1.27533\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1457]\tvalid_0's multi_logloss: 1.27529\n",
                        "[1458]\tvalid_0's multi_logloss: 1.27525\n",
                        "[1459]\tvalid_0's multi_logloss: 1.27522\n",
                        "[1460]\tvalid_0's multi_logloss: 1.2752\n",
                        "[1461]\tvalid_0's multi_logloss: 1.27516\n",
                        "[1462]\tvalid_0's multi_logloss: 1.27512\n",
                        "[1463]\tvalid_0's multi_logloss: 1.27509\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1464]\tvalid_0's multi_logloss: 1.27508\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1465]\tvalid_0's multi_logloss: 1.27505\n",
                        "[1466]\tvalid_0's multi_logloss: 1.27503\n",
                        "[1467]\tvalid_0's multi_logloss: 1.27501\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1468]\tvalid_0's multi_logloss: 1.27498\n",
                        "[1469]\tvalid_0's multi_logloss: 1.27497\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1470]\tvalid_0's multi_logloss: 1.27494\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1471]\tvalid_0's multi_logloss: 1.27491\n",
                        "[1472]\tvalid_0's multi_logloss: 1.27487\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1473]\tvalid_0's multi_logloss: 1.27483\n",
                        "[1474]\tvalid_0's multi_logloss: 1.27483\n",
                        "[1475]\tvalid_0's multi_logloss: 1.2748\n",
                        "[1476]\tvalid_0's multi_logloss: 1.27476\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1477]\tvalid_0's multi_logloss: 1.27474\n",
                        "[1478]\tvalid_0's multi_logloss: 1.27471\n",
                        "[1479]\tvalid_0's multi_logloss: 1.2747\n",
                        "[1480]\tvalid_0's multi_logloss: 1.27467\n",
                        "[1481]\tvalid_0's multi_logloss: 1.27465\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1482]\tvalid_0's multi_logloss: 1.27463\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1483]\tvalid_0's multi_logloss: 1.27459\n",
                        "[1484]\tvalid_0's multi_logloss: 1.27455\n",
                        "[1485]\tvalid_0's multi_logloss: 1.27454\n",
                        "[1486]\tvalid_0's multi_logloss: 1.27453\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1487]\tvalid_0's multi_logloss: 1.27451\n",
                        "[1488]\tvalid_0's multi_logloss: 1.27448\n",
                        "[1489]\tvalid_0's multi_logloss: 1.27447\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1490]\tvalid_0's multi_logloss: 1.27443\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1491]\tvalid_0's multi_logloss: 1.27442\n",
                        "[1492]\tvalid_0's multi_logloss: 1.27441\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1493]\tvalid_0's multi_logloss: 1.27437\n",
                        "[1494]\tvalid_0's multi_logloss: 1.27434\n",
                        "[1495]\tvalid_0's multi_logloss: 1.2743\n",
                        "[1496]\tvalid_0's multi_logloss: 1.27429\n",
                        "[1497]\tvalid_0's multi_logloss: 1.27426\n",
                        "[1498]\tvalid_0's multi_logloss: 1.27423\n",
                        "[1499]\tvalid_0's multi_logloss: 1.27421\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1500]\tvalid_0's multi_logloss: 1.27418\n",
                        "[1501]\tvalid_0's multi_logloss: 1.27415\n",
                        "[1502]\tvalid_0's multi_logloss: 1.27412\n",
                        "[1503]\tvalid_0's multi_logloss: 1.2741\n",
                        "[1504]\tvalid_0's multi_logloss: 1.27408\n",
                        "[1505]\tvalid_0's multi_logloss: 1.27405\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1506]\tvalid_0's multi_logloss: 1.27403\n",
                        "[1507]\tvalid_0's multi_logloss: 1.274\n",
                        "[1508]\tvalid_0's multi_logloss: 1.27397\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1509]\tvalid_0's multi_logloss: 1.27395\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1510]\tvalid_0's multi_logloss: 1.27392\n",
                        "[1511]\tvalid_0's multi_logloss: 1.2739\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1512]\tvalid_0's multi_logloss: 1.27386\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1513]\tvalid_0's multi_logloss: 1.27384\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1514]\tvalid_0's multi_logloss: 1.2738\n",
                        "[1515]\tvalid_0's multi_logloss: 1.27379\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1516]\tvalid_0's multi_logloss: 1.27376\n",
                        "[1517]\tvalid_0's multi_logloss: 1.27373\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1518]\tvalid_0's multi_logloss: 1.27371\n",
                        "[1519]\tvalid_0's multi_logloss: 1.27369\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1520]\tvalid_0's multi_logloss: 1.27366\n",
                        "[1521]\tvalid_0's multi_logloss: 1.27363\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1522]\tvalid_0's multi_logloss: 1.2736\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1523]\tvalid_0's multi_logloss: 1.27359\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1524]\tvalid_0's multi_logloss: 1.27356\n",
                        "[1525]\tvalid_0's multi_logloss: 1.27354\n",
                        "[1526]\tvalid_0's multi_logloss: 1.27353\n",
                        "[1527]\tvalid_0's multi_logloss: 1.2735\n",
                        "[1528]\tvalid_0's multi_logloss: 1.27348\n",
                        "[1529]\tvalid_0's multi_logloss: 1.27343\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1530]\tvalid_0's multi_logloss: 1.27341\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1531]\tvalid_0's multi_logloss: 1.2734\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1532]\tvalid_0's multi_logloss: 1.27337\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1533]\tvalid_0's multi_logloss: 1.27333\n",
                        "[1534]\tvalid_0's multi_logloss: 1.27329\n",
                        "[1535]\tvalid_0's multi_logloss: 1.27324\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1536]\tvalid_0's multi_logloss: 1.27321\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1537]\tvalid_0's multi_logloss: 1.27318\n",
                        "[1538]\tvalid_0's multi_logloss: 1.27317\n",
                        "[1539]\tvalid_0's multi_logloss: 1.27314\n",
                        "[1540]\tvalid_0's multi_logloss: 1.27313\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1541]\tvalid_0's multi_logloss: 1.27311\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1542]\tvalid_0's multi_logloss: 1.27309\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1543]\tvalid_0's multi_logloss: 1.27307\n",
                        "[1544]\tvalid_0's multi_logloss: 1.27304\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1545]\tvalid_0's multi_logloss: 1.27302\n",
                        "[1546]\tvalid_0's multi_logloss: 1.273\n",
                        "[1547]\tvalid_0's multi_logloss: 1.27298\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1548]\tvalid_0's multi_logloss: 1.27295\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1549]\tvalid_0's multi_logloss: 1.27292\n",
                        "[1550]\tvalid_0's multi_logloss: 1.27291\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1551]\tvalid_0's multi_logloss: 1.27288\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1552]\tvalid_0's multi_logloss: 1.27286\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1553]\tvalid_0's multi_logloss: 1.27283\n",
                        "[1554]\tvalid_0's multi_logloss: 1.2728\n",
                        "[1555]\tvalid_0's multi_logloss: 1.27276\n",
                        "[1556]\tvalid_0's multi_logloss: 1.27274\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1557]\tvalid_0's multi_logloss: 1.27272\n",
                        "[1558]\tvalid_0's multi_logloss: 1.2727\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1559]\tvalid_0's multi_logloss: 1.27267\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1560]\tvalid_0's multi_logloss: 1.27265\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1561]\tvalid_0's multi_logloss: 1.27263\n",
                        "[1562]\tvalid_0's multi_logloss: 1.2726\n",
                        "[1563]\tvalid_0's multi_logloss: 1.27257\n",
                        "[1564]\tvalid_0's multi_logloss: 1.27256\n",
                        "[1565]\tvalid_0's multi_logloss: 1.27252\n",
                        "[1566]\tvalid_0's multi_logloss: 1.2725\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1567]\tvalid_0's multi_logloss: 1.27246\n",
                        "[1568]\tvalid_0's multi_logloss: 1.27244\n",
                        "[1569]\tvalid_0's multi_logloss: 1.27242\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1570]\tvalid_0's multi_logloss: 1.2724\n",
                        "[1571]\tvalid_0's multi_logloss: 1.27237\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1572]\tvalid_0's multi_logloss: 1.27234\n",
                        "[1573]\tvalid_0's multi_logloss: 1.27232\n",
                        "[1574]\tvalid_0's multi_logloss: 1.27229\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1575]\tvalid_0's multi_logloss: 1.27229\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1576]\tvalid_0's multi_logloss: 1.27226\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1577]\tvalid_0's multi_logloss: 1.27222\n",
                        "[1578]\tvalid_0's multi_logloss: 1.27219\n",
                        "[1579]\tvalid_0's multi_logloss: 1.27217\n",
                        "[1580]\tvalid_0's multi_logloss: 1.27214\n",
                        "[1581]\tvalid_0's multi_logloss: 1.27212\n",
                        "[1582]\tvalid_0's multi_logloss: 1.2721\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1583]\tvalid_0's multi_logloss: 1.27208\n",
                        "[1584]\tvalid_0's multi_logloss: 1.27206\n",
                        "[1585]\tvalid_0's multi_logloss: 1.27203\n",
                        "[1586]\tvalid_0's multi_logloss: 1.27201\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1587]\tvalid_0's multi_logloss: 1.27197\n",
                        "[1588]\tvalid_0's multi_logloss: 1.27195\n",
                        "[1589]\tvalid_0's multi_logloss: 1.27193\n",
                        "[1590]\tvalid_0's multi_logloss: 1.2719\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1591]\tvalid_0's multi_logloss: 1.27188\n",
                        "[1592]\tvalid_0's multi_logloss: 1.27186\n",
                        "[1593]\tvalid_0's multi_logloss: 1.27183\n",
                        "[1594]\tvalid_0's multi_logloss: 1.27179\n",
                        "[1595]\tvalid_0's multi_logloss: 1.27175\n",
                        "[1596]\tvalid_0's multi_logloss: 1.27171\n",
                        "[1597]\tvalid_0's multi_logloss: 1.27167\n",
                        "[1598]\tvalid_0's multi_logloss: 1.27165\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1599]\tvalid_0's multi_logloss: 1.27163\n",
                        "[1600]\tvalid_0's multi_logloss: 1.27161\n",
                        "[1601]\tvalid_0's multi_logloss: 1.27158\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1602]\tvalid_0's multi_logloss: 1.27156\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1603]\tvalid_0's multi_logloss: 1.27155\n",
                        "[1604]\tvalid_0's multi_logloss: 1.27153\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1605]\tvalid_0's multi_logloss: 1.27151\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1606]\tvalid_0's multi_logloss: 1.2715\n",
                        "[1607]\tvalid_0's multi_logloss: 1.27148\n",
                        "[1608]\tvalid_0's multi_logloss: 1.27144\n",
                        "[1609]\tvalid_0's multi_logloss: 1.2714\n",
                        "[1610]\tvalid_0's multi_logloss: 1.27137\n",
                        "[1611]\tvalid_0's multi_logloss: 1.27135\n",
                        "[1612]\tvalid_0's multi_logloss: 1.27132\n",
                        "[1613]\tvalid_0's multi_logloss: 1.27131\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1614]\tvalid_0's multi_logloss: 1.27128\n",
                        "[1615]\tvalid_0's multi_logloss: 1.27125\n",
                        "[1616]\tvalid_0's multi_logloss: 1.27122\n",
                        "[1617]\tvalid_0's multi_logloss: 1.27118\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1618]\tvalid_0's multi_logloss: 1.27117\n",
                        "[1619]\tvalid_0's multi_logloss: 1.27115\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1620]\tvalid_0's multi_logloss: 1.27113\n",
                        "[1621]\tvalid_0's multi_logloss: 1.27111\n",
                        "[1622]\tvalid_0's multi_logloss: 1.27108\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1623]\tvalid_0's multi_logloss: 1.27105\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1624]\tvalid_0's multi_logloss: 1.27102\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1625]\tvalid_0's multi_logloss: 1.271\n",
                        "[1626]\tvalid_0's multi_logloss: 1.27097\n",
                        "[1627]\tvalid_0's multi_logloss: 1.27095\n",
                        "[1628]\tvalid_0's multi_logloss: 1.27092\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1629]\tvalid_0's multi_logloss: 1.27087\n",
                        "[1630]\tvalid_0's multi_logloss: 1.27085\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1631]\tvalid_0's multi_logloss: 1.2708\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1632]\tvalid_0's multi_logloss: 1.27077\n",
                        "[1633]\tvalid_0's multi_logloss: 1.27075\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1634]\tvalid_0's multi_logloss: 1.27073\n",
                        "[1635]\tvalid_0's multi_logloss: 1.27071\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1636]\tvalid_0's multi_logloss: 1.2707\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1637]\tvalid_0's multi_logloss: 1.27068\n",
                        "[1638]\tvalid_0's multi_logloss: 1.27066\n",
                        "[1639]\tvalid_0's multi_logloss: 1.27064\n",
                        "[1640]\tvalid_0's multi_logloss: 1.27061\n",
                        "[1641]\tvalid_0's multi_logloss: 1.27058\n",
                        "[1642]\tvalid_0's multi_logloss: 1.27056\n",
                        "[1643]\tvalid_0's multi_logloss: 1.27054\n",
                        "[1644]\tvalid_0's multi_logloss: 1.27052\n",
                        "[1645]\tvalid_0's multi_logloss: 1.2705\n",
                        "[1646]\tvalid_0's multi_logloss: 1.27048\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1647]\tvalid_0's multi_logloss: 1.27047\n",
                        "[1648]\tvalid_0's multi_logloss: 1.27045\n",
                        "[1649]\tvalid_0's multi_logloss: 1.27043\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1650]\tvalid_0's multi_logloss: 1.27039\n",
                        "[1651]\tvalid_0's multi_logloss: 1.27038\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1652]\tvalid_0's multi_logloss: 1.27037\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1653]\tvalid_0's multi_logloss: 1.27034\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1654]\tvalid_0's multi_logloss: 1.27031\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1655]\tvalid_0's multi_logloss: 1.27028\n",
                        "[1656]\tvalid_0's multi_logloss: 1.27024\n",
                        "[1657]\tvalid_0's multi_logloss: 1.27022\n",
                        "[1658]\tvalid_0's multi_logloss: 1.2702\n",
                        "[1659]\tvalid_0's multi_logloss: 1.27019\n",
                        "[1660]\tvalid_0's multi_logloss: 1.27017\n",
                        "[1661]\tvalid_0's multi_logloss: 1.27013\n",
                        "[1662]\tvalid_0's multi_logloss: 1.2701\n",
                        "[1663]\tvalid_0's multi_logloss: 1.27007\n",
                        "[1664]\tvalid_0's multi_logloss: 1.27003\n",
                        "[1665]\tvalid_0's multi_logloss: 1.27001\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1666]\tvalid_0's multi_logloss: 1.26997\n",
                        "[1667]\tvalid_0's multi_logloss: 1.26995\n",
                        "[1668]\tvalid_0's multi_logloss: 1.26993\n",
                        "[1669]\tvalid_0's multi_logloss: 1.2699\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1670]\tvalid_0's multi_logloss: 1.26988\n",
                        "[1671]\tvalid_0's multi_logloss: 1.26985\n",
                        "[1672]\tvalid_0's multi_logloss: 1.26982\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1673]\tvalid_0's multi_logloss: 1.26981\n",
                        "[1674]\tvalid_0's multi_logloss: 1.26979\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1675]\tvalid_0's multi_logloss: 1.26976\n",
                        "[1676]\tvalid_0's multi_logloss: 1.26974\n",
                        "[1677]\tvalid_0's multi_logloss: 1.26971\n",
                        "[1678]\tvalid_0's multi_logloss: 1.26968\n",
                        "[1679]\tvalid_0's multi_logloss: 1.26966\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1680]\tvalid_0's multi_logloss: 1.26964\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1681]\tvalid_0's multi_logloss: 1.26962\n",
                        "[1682]\tvalid_0's multi_logloss: 1.2696\n",
                        "[1683]\tvalid_0's multi_logloss: 1.2696\n",
                        "[1684]\tvalid_0's multi_logloss: 1.26956\n",
                        "[1685]\tvalid_0's multi_logloss: 1.26953\n",
                        "[1686]\tvalid_0's multi_logloss: 1.2695\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1687]\tvalid_0's multi_logloss: 1.26946\n",
                        "[1688]\tvalid_0's multi_logloss: 1.26945\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1689]\tvalid_0's multi_logloss: 1.26943\n",
                        "[1690]\tvalid_0's multi_logloss: 1.26942\n",
                        "[1691]\tvalid_0's multi_logloss: 1.26941\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1692]\tvalid_0's multi_logloss: 1.26939\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1693]\tvalid_0's multi_logloss: 1.26937\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1694]\tvalid_0's multi_logloss: 1.26935\n",
                        "[1695]\tvalid_0's multi_logloss: 1.26934\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1696]\tvalid_0's multi_logloss: 1.26931\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1697]\tvalid_0's multi_logloss: 1.26929\n",
                        "[1698]\tvalid_0's multi_logloss: 1.26926\n",
                        "[1699]\tvalid_0's multi_logloss: 1.26922\n",
                        "[1700]\tvalid_0's multi_logloss: 1.2692\n",
                        "[1701]\tvalid_0's multi_logloss: 1.26917\n",
                        "[1702]\tvalid_0's multi_logloss: 1.26915\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1703]\tvalid_0's multi_logloss: 1.26912\n",
                        "[1704]\tvalid_0's multi_logloss: 1.2691\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1705]\tvalid_0's multi_logloss: 1.26907\n",
                        "[1706]\tvalid_0's multi_logloss: 1.26904\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1707]\tvalid_0's multi_logloss: 1.26903\n",
                        "[1708]\tvalid_0's multi_logloss: 1.26902\n",
                        "[1709]\tvalid_0's multi_logloss: 1.269\n",
                        "[1710]\tvalid_0's multi_logloss: 1.26896\n",
                        "[1711]\tvalid_0's multi_logloss: 1.26894\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1712]\tvalid_0's multi_logloss: 1.26892\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1713]\tvalid_0's multi_logloss: 1.2689\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1714]\tvalid_0's multi_logloss: 1.26886\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1715]\tvalid_0's multi_logloss: 1.26883\n",
                        "[1716]\tvalid_0's multi_logloss: 1.26882\n",
                        "[1717]\tvalid_0's multi_logloss: 1.2688\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1718]\tvalid_0's multi_logloss: 1.26878\n",
                        "[1719]\tvalid_0's multi_logloss: 1.26876\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1720]\tvalid_0's multi_logloss: 1.26872\n",
                        "[1721]\tvalid_0's multi_logloss: 1.2687\n",
                        "[1722]\tvalid_0's multi_logloss: 1.26869\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1723]\tvalid_0's multi_logloss: 1.26866\n",
                        "[1724]\tvalid_0's multi_logloss: 1.26863\n",
                        "[1725]\tvalid_0's multi_logloss: 1.2686\n",
                        "[1726]\tvalid_0's multi_logloss: 1.26858\n",
                        "[1727]\tvalid_0's multi_logloss: 1.26858\n",
                        "[1728]\tvalid_0's multi_logloss: 1.26855\n",
                        "[1729]\tvalid_0's multi_logloss: 1.26853\n",
                        "[1730]\tvalid_0's multi_logloss: 1.2685\n",
                        "[1731]\tvalid_0's multi_logloss: 1.26847\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1732]\tvalid_0's multi_logloss: 1.26845\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1733]\tvalid_0's multi_logloss: 1.26842\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1734]\tvalid_0's multi_logloss: 1.26841\n",
                        "[1735]\tvalid_0's multi_logloss: 1.26838\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1736]\tvalid_0's multi_logloss: 1.26835\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1737]\tvalid_0's multi_logloss: 1.26834\n",
                        "[1738]\tvalid_0's multi_logloss: 1.26832\n",
                        "[1739]\tvalid_0's multi_logloss: 1.2683\n",
                        "[1740]\tvalid_0's multi_logloss: 1.26827\n",
                        "[1741]\tvalid_0's multi_logloss: 1.26824\n",
                        "[1742]\tvalid_0's multi_logloss: 1.26822\n",
                        "[1743]\tvalid_0's multi_logloss: 1.2682\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1744]\tvalid_0's multi_logloss: 1.26818\n",
                        "[1745]\tvalid_0's multi_logloss: 1.26815\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1746]\tvalid_0's multi_logloss: 1.26814\n",
                        "[1747]\tvalid_0's multi_logloss: 1.26811\n",
                        "[1748]\tvalid_0's multi_logloss: 1.26809\n",
                        "[1749]\tvalid_0's multi_logloss: 1.26809\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1750]\tvalid_0's multi_logloss: 1.26806\n",
                        "[1751]\tvalid_0's multi_logloss: 1.26803\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1752]\tvalid_0's multi_logloss: 1.26801\n",
                        "[1753]\tvalid_0's multi_logloss: 1.26801\n",
                        "[1754]\tvalid_0's multi_logloss: 1.26797\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1755]\tvalid_0's multi_logloss: 1.26795\n",
                        "[1756]\tvalid_0's multi_logloss: 1.26794\n",
                        "[1757]\tvalid_0's multi_logloss: 1.26793\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1758]\tvalid_0's multi_logloss: 1.26791\n",
                        "[1759]\tvalid_0's multi_logloss: 1.26788\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1760]\tvalid_0's multi_logloss: 1.26787\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1761]\tvalid_0's multi_logloss: 1.26785\n",
                        "[1762]\tvalid_0's multi_logloss: 1.26782\n",
                        "[1763]\tvalid_0's multi_logloss: 1.26781\n",
                        "[1764]\tvalid_0's multi_logloss: 1.2678\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1765]\tvalid_0's multi_logloss: 1.26778\n",
                        "[1766]\tvalid_0's multi_logloss: 1.26775\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1767]\tvalid_0's multi_logloss: 1.26774\n",
                        "[1768]\tvalid_0's multi_logloss: 1.26771\n",
                        "[1769]\tvalid_0's multi_logloss: 1.26769\n",
                        "[1770]\tvalid_0's multi_logloss: 1.26767\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1771]\tvalid_0's multi_logloss: 1.26765\n",
                        "[1772]\tvalid_0's multi_logloss: 1.26764\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1773]\tvalid_0's multi_logloss: 1.26761\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1774]\tvalid_0's multi_logloss: 1.26759\n",
                        "[1775]\tvalid_0's multi_logloss: 1.26755\n",
                        "[1776]\tvalid_0's multi_logloss: 1.26753\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1777]\tvalid_0's multi_logloss: 1.26751\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1778]\tvalid_0's multi_logloss: 1.26749\n",
                        "[1779]\tvalid_0's multi_logloss: 1.26748\n",
                        "[1780]\tvalid_0's multi_logloss: 1.26746\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1781]\tvalid_0's multi_logloss: 1.26744\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1782]\tvalid_0's multi_logloss: 1.26741\n",
                        "[1783]\tvalid_0's multi_logloss: 1.26739\n",
                        "[1784]\tvalid_0's multi_logloss: 1.26738\n",
                        "[1785]\tvalid_0's multi_logloss: 1.26735\n",
                        "[1786]\tvalid_0's multi_logloss: 1.26733\n",
                        "[1787]\tvalid_0's multi_logloss: 1.26731\n",
                        "[1788]\tvalid_0's multi_logloss: 1.26729\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1789]\tvalid_0's multi_logloss: 1.26727\n",
                        "[1790]\tvalid_0's multi_logloss: 1.26725\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1791]\tvalid_0's multi_logloss: 1.2672\n",
                        "[1792]\tvalid_0's multi_logloss: 1.26717\n",
                        "[1793]\tvalid_0's multi_logloss: 1.26715\n",
                        "[1794]\tvalid_0's multi_logloss: 1.26712\n",
                        "[1795]\tvalid_0's multi_logloss: 1.26709\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1796]\tvalid_0's multi_logloss: 1.26706\n",
                        "[1797]\tvalid_0's multi_logloss: 1.26703\n",
                        "[1798]\tvalid_0's multi_logloss: 1.26699\n",
                        "[1799]\tvalid_0's multi_logloss: 1.26697\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1800]\tvalid_0's multi_logloss: 1.26694\n",
                        "[1801]\tvalid_0's multi_logloss: 1.26692\n",
                        "[1802]\tvalid_0's multi_logloss: 1.2669\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1803]\tvalid_0's multi_logloss: 1.26688\n",
                        "[1804]\tvalid_0's multi_logloss: 1.26684\n",
                        "[1805]\tvalid_0's multi_logloss: 1.26682\n",
                        "[1806]\tvalid_0's multi_logloss: 1.2668\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1807]\tvalid_0's multi_logloss: 1.26678\n",
                        "[1808]\tvalid_0's multi_logloss: 1.26676\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1809]\tvalid_0's multi_logloss: 1.26674\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1810]\tvalid_0's multi_logloss: 1.26673\n",
                        "[1811]\tvalid_0's multi_logloss: 1.26671\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1812]\tvalid_0's multi_logloss: 1.26668\n",
                        "[1813]\tvalid_0's multi_logloss: 1.26667\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1814]\tvalid_0's multi_logloss: 1.26665\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1815]\tvalid_0's multi_logloss: 1.26663\n",
                        "[1816]\tvalid_0's multi_logloss: 1.2666\n",
                        "[1817]\tvalid_0's multi_logloss: 1.26658\n",
                        "[1818]\tvalid_0's multi_logloss: 1.26657\n",
                        "[1819]\tvalid_0's multi_logloss: 1.26655\n",
                        "[1820]\tvalid_0's multi_logloss: 1.26652\n",
                        "[1821]\tvalid_0's multi_logloss: 1.2665\n",
                        "[1822]\tvalid_0's multi_logloss: 1.26647\n",
                        "[1823]\tvalid_0's multi_logloss: 1.26645\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1824]\tvalid_0's multi_logloss: 1.26643\n",
                        "[1825]\tvalid_0's multi_logloss: 1.26641\n",
                        "[1826]\tvalid_0's multi_logloss: 1.26638\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1827]\tvalid_0's multi_logloss: 1.26636\n",
                        "[1828]\tvalid_0's multi_logloss: 1.26634\n",
                        "[1829]\tvalid_0's multi_logloss: 1.26631\n",
                        "[1830]\tvalid_0's multi_logloss: 1.26629\n",
                        "[1831]\tvalid_0's multi_logloss: 1.26626\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1832]\tvalid_0's multi_logloss: 1.26626\n",
                        "[1833]\tvalid_0's multi_logloss: 1.26624\n",
                        "[1834]\tvalid_0's multi_logloss: 1.26623\n",
                        "[1835]\tvalid_0's multi_logloss: 1.26619\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1836]\tvalid_0's multi_logloss: 1.26617\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1837]\tvalid_0's multi_logloss: 1.26616\n",
                        "[1838]\tvalid_0's multi_logloss: 1.26614\n",
                        "[1839]\tvalid_0's multi_logloss: 1.26613\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1840]\tvalid_0's multi_logloss: 1.26611\n",
                        "[1841]\tvalid_0's multi_logloss: 1.26609\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1842]\tvalid_0's multi_logloss: 1.26607\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1843]\tvalid_0's multi_logloss: 1.26605\n",
                        "[1844]\tvalid_0's multi_logloss: 1.26603\n",
                        "[1845]\tvalid_0's multi_logloss: 1.266\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1846]\tvalid_0's multi_logloss: 1.26599\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1847]\tvalid_0's multi_logloss: 1.26597\n",
                        "[1848]\tvalid_0's multi_logloss: 1.26596\n",
                        "[1849]\tvalid_0's multi_logloss: 1.26594\n",
                        "[1850]\tvalid_0's multi_logloss: 1.26591\n",
                        "[1851]\tvalid_0's multi_logloss: 1.26588\n",
                        "[1852]\tvalid_0's multi_logloss: 1.26586\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1853]\tvalid_0's multi_logloss: 1.26584\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1854]\tvalid_0's multi_logloss: 1.26582\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1855]\tvalid_0's multi_logloss: 1.26579\n",
                        "[1856]\tvalid_0's multi_logloss: 1.26576\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1857]\tvalid_0's multi_logloss: 1.26573\n",
                        "[1858]\tvalid_0's multi_logloss: 1.26572\n",
                        "[1859]\tvalid_0's multi_logloss: 1.26568\n",
                        "[1860]\tvalid_0's multi_logloss: 1.26566\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1861]\tvalid_0's multi_logloss: 1.26564\n",
                        "[1862]\tvalid_0's multi_logloss: 1.26562\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1863]\tvalid_0's multi_logloss: 1.26559\n",
                        "[1864]\tvalid_0's multi_logloss: 1.26558\n",
                        "[1865]\tvalid_0's multi_logloss: 1.26557\n",
                        "[1866]\tvalid_0's multi_logloss: 1.26554\n",
                        "[1867]\tvalid_0's multi_logloss: 1.26552\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1868]\tvalid_0's multi_logloss: 1.2655\n",
                        "[1869]\tvalid_0's multi_logloss: 1.26549\n",
                        "[1870]\tvalid_0's multi_logloss: 1.26547\n",
                        "[1871]\tvalid_0's multi_logloss: 1.26545\n",
                        "[1872]\tvalid_0's multi_logloss: 1.26543\n",
                        "[1873]\tvalid_0's multi_logloss: 1.26541\n",
                        "[1874]\tvalid_0's multi_logloss: 1.26538\n",
                        "[1875]\tvalid_0's multi_logloss: 1.26536\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1876]\tvalid_0's multi_logloss: 1.26533\n",
                        "[1877]\tvalid_0's multi_logloss: 1.2653\n",
                        "[1878]\tvalid_0's multi_logloss: 1.26529\n",
                        "[1879]\tvalid_0's multi_logloss: 1.26528\n",
                        "[1880]\tvalid_0's multi_logloss: 1.26526\n",
                        "[1881]\tvalid_0's multi_logloss: 1.26524\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1882]\tvalid_0's multi_logloss: 1.26523\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1883]\tvalid_0's multi_logloss: 1.26522\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1884]\tvalid_0's multi_logloss: 1.26519\n",
                        "[1885]\tvalid_0's multi_logloss: 1.26519\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1886]\tvalid_0's multi_logloss: 1.26517\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1887]\tvalid_0's multi_logloss: 1.26515\n",
                        "[1888]\tvalid_0's multi_logloss: 1.26513\n",
                        "[1889]\tvalid_0's multi_logloss: 1.26512\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1890]\tvalid_0's multi_logloss: 1.2651\n",
                        "[1891]\tvalid_0's multi_logloss: 1.26508\n",
                        "[1892]\tvalid_0's multi_logloss: 1.26506\n",
                        "[1893]\tvalid_0's multi_logloss: 1.26505\n",
                        "[1894]\tvalid_0's multi_logloss: 1.26501\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1895]\tvalid_0's multi_logloss: 1.26499\n",
                        "[1896]\tvalid_0's multi_logloss: 1.26497\n",
                        "[1897]\tvalid_0's multi_logloss: 1.26493\n",
                        "[1898]\tvalid_0's multi_logloss: 1.26491\n",
                        "[1899]\tvalid_0's multi_logloss: 1.2649\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1900]\tvalid_0's multi_logloss: 1.26489\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1901]\tvalid_0's multi_logloss: 1.26487\n",
                        "[1902]\tvalid_0's multi_logloss: 1.26485\n",
                        "[1903]\tvalid_0's multi_logloss: 1.26482\n",
                        "[1904]\tvalid_0's multi_logloss: 1.26479\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1905]\tvalid_0's multi_logloss: 1.26478\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1906]\tvalid_0's multi_logloss: 1.26475\n",
                        "[1907]\tvalid_0's multi_logloss: 1.26472\n",
                        "[1908]\tvalid_0's multi_logloss: 1.26472\n",
                        "[1909]\tvalid_0's multi_logloss: 1.26469\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1910]\tvalid_0's multi_logloss: 1.26466\n",
                        "[1911]\tvalid_0's multi_logloss: 1.26464\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1912]\tvalid_0's multi_logloss: 1.26462\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1913]\tvalid_0's multi_logloss: 1.26459\n",
                        "[1914]\tvalid_0's multi_logloss: 1.26456\n",
                        "[1915]\tvalid_0's multi_logloss: 1.26454\n",
                        "[1916]\tvalid_0's multi_logloss: 1.26455\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1917]\tvalid_0's multi_logloss: 1.26452\n",
                        "[1918]\tvalid_0's multi_logloss: 1.26448\n",
                        "[1919]\tvalid_0's multi_logloss: 1.26446\n",
                        "[1920]\tvalid_0's multi_logloss: 1.26443\n",
                        "[1921]\tvalid_0's multi_logloss: 1.26441\n",
                        "[1922]\tvalid_0's multi_logloss: 1.26438\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1923]\tvalid_0's multi_logloss: 1.26436\n",
                        "[1924]\tvalid_0's multi_logloss: 1.26434\n",
                        "[1925]\tvalid_0's multi_logloss: 1.26432\n",
                        "[1926]\tvalid_0's multi_logloss: 1.26429\n",
                        "[1927]\tvalid_0's multi_logloss: 1.26427\n",
                        "[1928]\tvalid_0's multi_logloss: 1.26424\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1929]\tvalid_0's multi_logloss: 1.26422\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1930]\tvalid_0's multi_logloss: 1.26419\n",
                        "[1931]\tvalid_0's multi_logloss: 1.26417\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1932]\tvalid_0's multi_logloss: 1.26414\n",
                        "[1933]\tvalid_0's multi_logloss: 1.26412\n",
                        "[1934]\tvalid_0's multi_logloss: 1.2641\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1935]\tvalid_0's multi_logloss: 1.26409\n",
                        "[1936]\tvalid_0's multi_logloss: 1.26405\n",
                        "[1937]\tvalid_0's multi_logloss: 1.26403\n",
                        "[1938]\tvalid_0's multi_logloss: 1.264\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1939]\tvalid_0's multi_logloss: 1.26401\n",
                        "[1940]\tvalid_0's multi_logloss: 1.26397\n",
                        "[1941]\tvalid_0's multi_logloss: 1.26396\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1942]\tvalid_0's multi_logloss: 1.26394\n",
                        "[1943]\tvalid_0's multi_logloss: 1.26392\n",
                        "[1944]\tvalid_0's multi_logloss: 1.26389\n",
                        "[1945]\tvalid_0's multi_logloss: 1.26387\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1946]\tvalid_0's multi_logloss: 1.26385\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1947]\tvalid_0's multi_logloss: 1.26385\n",
                        "[1948]\tvalid_0's multi_logloss: 1.26382\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1949]\tvalid_0's multi_logloss: 1.2638\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1950]\tvalid_0's multi_logloss: 1.26377\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1951]\tvalid_0's multi_logloss: 1.26375\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1952]\tvalid_0's multi_logloss: 1.26373\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1953]\tvalid_0's multi_logloss: 1.26371\n",
                        "[1954]\tvalid_0's multi_logloss: 1.2637\n",
                        "[1955]\tvalid_0's multi_logloss: 1.26369\n",
                        "[1956]\tvalid_0's multi_logloss: 1.26368\n",
                        "[1957]\tvalid_0's multi_logloss: 1.26366\n",
                        "[1958]\tvalid_0's multi_logloss: 1.26364\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1959]\tvalid_0's multi_logloss: 1.26361\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1960]\tvalid_0's multi_logloss: 1.2636\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1961]\tvalid_0's multi_logloss: 1.26358\n",
                        "[1962]\tvalid_0's multi_logloss: 1.26354\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1963]\tvalid_0's multi_logloss: 1.26354\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1964]\tvalid_0's multi_logloss: 1.26353\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1965]\tvalid_0's multi_logloss: 1.26351\n",
                        "[1966]\tvalid_0's multi_logloss: 1.26347\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1967]\tvalid_0's multi_logloss: 1.26345\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1968]\tvalid_0's multi_logloss: 1.26345\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1969]\tvalid_0's multi_logloss: 1.26343\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1970]\tvalid_0's multi_logloss: 1.26341\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1971]\tvalid_0's multi_logloss: 1.26338\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1972]\tvalid_0's multi_logloss: 1.26336\n",
                        "[1973]\tvalid_0's multi_logloss: 1.26336\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1974]\tvalid_0's multi_logloss: 1.26334\n",
                        "[1975]\tvalid_0's multi_logloss: 1.26331\n",
                        "[1976]\tvalid_0's multi_logloss: 1.26329\n",
                        "[1977]\tvalid_0's multi_logloss: 1.26326\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1978]\tvalid_0's multi_logloss: 1.26325\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1979]\tvalid_0's multi_logloss: 1.26322\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1980]\tvalid_0's multi_logloss: 1.2632\n",
                        "[1981]\tvalid_0's multi_logloss: 1.26318\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1982]\tvalid_0's multi_logloss: 1.26317\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1983]\tvalid_0's multi_logloss: 1.26317\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1984]\tvalid_0's multi_logloss: 1.26315\n",
                        "[1985]\tvalid_0's multi_logloss: 1.26312\n",
                        "[1986]\tvalid_0's multi_logloss: 1.26311\n",
                        "[1987]\tvalid_0's multi_logloss: 1.2631\n",
                        "[1988]\tvalid_0's multi_logloss: 1.26307\n",
                        "[1989]\tvalid_0's multi_logloss: 1.26305\n",
                        "[1990]\tvalid_0's multi_logloss: 1.26303\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1991]\tvalid_0's multi_logloss: 1.26301\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1992]\tvalid_0's multi_logloss: 1.26299\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1993]\tvalid_0's multi_logloss: 1.26296\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1994]\tvalid_0's multi_logloss: 1.26295\n",
                        "[1995]\tvalid_0's multi_logloss: 1.26293\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1996]\tvalid_0's multi_logloss: 1.26291\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1997]\tvalid_0's multi_logloss: 1.26287\n",
                        "[1998]\tvalid_0's multi_logloss: 1.26284\n",
                        "[1999]\tvalid_0's multi_logloss: 1.26282\n",
                        "[2000]\tvalid_0's multi_logloss: 1.26279\n",
                        "Did not meet early stopping. Best iteration is:\n",
                        "[2000]\tvalid_0's multi_logloss: 1.26279\n",
                        "Fold train balanced accuracy: 0.6271\n",
                        "Fold validation balanced accuracy: 0.4324\n",
                        "---\n",
                        "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
                        "[LightGBM] [Info] This is the GPU trainer!!\n",
                        "[LightGBM] [Info] Total Bins 7914\n",
                        "[LightGBM] [Info] Number of data points in the train set: 107041, number of used features: 32\n",
                        "[LightGBM] [Info] Using requested OpenCL platform 1 device 0\n",
                        "[LightGBM] [Info] Using GPU Device: NVIDIA GeForce RTX 3060 Laptop GPU, Vendor: NVIDIA Corporation\n",
                        "[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...\n",
                        "[LightGBM] [Info] GPU programs have been built\n",
                        "[LightGBM] [Info] Size of histogram bin entry: 8\n",
                        "[LightGBM] [Info] 30 dense feature groups (3.27 MB) transferred to GPU in 0.007173 secs. 1 sparse feature groups\n",
                        "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
                        "[LightGBM] [Info] Start training from score -2.079442\n",
                        "[LightGBM] [Info] Start training from score -2.079442\n",
                        "[LightGBM] [Info] Start training from score -2.079442\n",
                        "[LightGBM] [Info] Start training from score -2.079442\n",
                        "[LightGBM] [Info] Start training from score -2.079442\n",
                        "[LightGBM] [Info] Start training from score -2.079442\n",
                        "[LightGBM] [Info] Start training from score -2.079442\n",
                        "[LightGBM] [Info] Start training from score -2.079442\n",
                        "[1]\tvalid_0's multi_logloss: 2.06262\n",
                        "Training until validation scores don't improve for 10 rounds\n",
                        "[2]\tvalid_0's multi_logloss: 2.04653\n",
                        "[3]\tvalid_0's multi_logloss: 2.03113\n",
                        "[4]\tvalid_0's multi_logloss: 2.01561\n",
                        "[5]\tvalid_0's multi_logloss: 2.0013\n",
                        "[6]\tvalid_0's multi_logloss: 1.98666\n",
                        "[7]\tvalid_0's multi_logloss: 1.97302\n",
                        "[8]\tvalid_0's multi_logloss: 1.9598\n",
                        "[9]\tvalid_0's multi_logloss: 1.94739\n",
                        "[10]\tvalid_0's multi_logloss: 1.93512\n",
                        "[11]\tvalid_0's multi_logloss: 1.92287\n",
                        "[12]\tvalid_0's multi_logloss: 1.9118\n",
                        "[13]\tvalid_0's multi_logloss: 1.90021\n",
                        "[14]\tvalid_0's multi_logloss: 1.88967\n",
                        "[15]\tvalid_0's multi_logloss: 1.87897\n",
                        "[16]\tvalid_0's multi_logloss: 1.86889\n",
                        "[17]\tvalid_0's multi_logloss: 1.85942\n",
                        "[18]\tvalid_0's multi_logloss: 1.84987\n",
                        "[19]\tvalid_0's multi_logloss: 1.84045\n",
                        "[20]\tvalid_0's multi_logloss: 1.83152\n",
                        "[21]\tvalid_0's multi_logloss: 1.82259\n",
                        "[22]\tvalid_0's multi_logloss: 1.81409\n",
                        "[23]\tvalid_0's multi_logloss: 1.80606\n",
                        "[24]\tvalid_0's multi_logloss: 1.79787\n",
                        "[25]\tvalid_0's multi_logloss: 1.78976\n",
                        "[26]\tvalid_0's multi_logloss: 1.78219\n",
                        "[27]\tvalid_0's multi_logloss: 1.77482\n",
                        "[28]\tvalid_0's multi_logloss: 1.76732\n",
                        "[29]\tvalid_0's multi_logloss: 1.76\n",
                        "[30]\tvalid_0's multi_logloss: 1.75302\n",
                        "[31]\tvalid_0's multi_logloss: 1.74602\n",
                        "[32]\tvalid_0's multi_logloss: 1.73918\n",
                        "[33]\tvalid_0's multi_logloss: 1.73258\n",
                        "[34]\tvalid_0's multi_logloss: 1.72603\n",
                        "[35]\tvalid_0's multi_logloss: 1.72005\n",
                        "[36]\tvalid_0's multi_logloss: 1.71375\n",
                        "[37]\tvalid_0's multi_logloss: 1.7078\n",
                        "[38]\tvalid_0's multi_logloss: 1.70176\n",
                        "[39]\tvalid_0's multi_logloss: 1.69612\n",
                        "[40]\tvalid_0's multi_logloss: 1.69026\n",
                        "[41]\tvalid_0's multi_logloss: 1.68467\n",
                        "[42]\tvalid_0's multi_logloss: 1.67936\n",
                        "[43]\tvalid_0's multi_logloss: 1.674\n",
                        "[44]\tvalid_0's multi_logloss: 1.66879\n",
                        "[45]\tvalid_0's multi_logloss: 1.66376\n",
                        "[46]\tvalid_0's multi_logloss: 1.65882\n",
                        "[47]\tvalid_0's multi_logloss: 1.65405\n",
                        "[48]\tvalid_0's multi_logloss: 1.64936\n",
                        "[49]\tvalid_0's multi_logloss: 1.64482\n",
                        "[50]\tvalid_0's multi_logloss: 1.64028\n",
                        "[51]\tvalid_0's multi_logloss: 1.63597\n",
                        "[52]\tvalid_0's multi_logloss: 1.63169\n",
                        "[53]\tvalid_0's multi_logloss: 1.62741\n",
                        "[54]\tvalid_0's multi_logloss: 1.62332\n",
                        "[55]\tvalid_0's multi_logloss: 1.61915\n",
                        "[56]\tvalid_0's multi_logloss: 1.61503\n",
                        "[57]\tvalid_0's multi_logloss: 1.61097\n",
                        "[58]\tvalid_0's multi_logloss: 1.60681\n",
                        "[59]\tvalid_0's multi_logloss: 1.60299\n",
                        "[60]\tvalid_0's multi_logloss: 1.59921\n",
                        "[61]\tvalid_0's multi_logloss: 1.5955\n",
                        "[62]\tvalid_0's multi_logloss: 1.59199\n",
                        "[63]\tvalid_0's multi_logloss: 1.58843\n",
                        "[64]\tvalid_0's multi_logloss: 1.58487\n",
                        "[65]\tvalid_0's multi_logloss: 1.58144\n",
                        "[66]\tvalid_0's multi_logloss: 1.57796\n",
                        "[67]\tvalid_0's multi_logloss: 1.57464\n",
                        "[68]\tvalid_0's multi_logloss: 1.57122\n",
                        "[69]\tvalid_0's multi_logloss: 1.56793\n",
                        "[70]\tvalid_0's multi_logloss: 1.56471\n",
                        "[71]\tvalid_0's multi_logloss: 1.56147\n",
                        "[72]\tvalid_0's multi_logloss: 1.55833\n",
                        "[73]\tvalid_0's multi_logloss: 1.55533\n",
                        "[74]\tvalid_0's multi_logloss: 1.55222\n",
                        "[75]\tvalid_0's multi_logloss: 1.54912\n",
                        "[76]\tvalid_0's multi_logloss: 1.5462\n",
                        "[77]\tvalid_0's multi_logloss: 1.54326\n",
                        "[78]\tvalid_0's multi_logloss: 1.54043\n",
                        "[79]\tvalid_0's multi_logloss: 1.53761\n",
                        "[80]\tvalid_0's multi_logloss: 1.53472\n",
                        "[81]\tvalid_0's multi_logloss: 1.53203\n",
                        "[82]\tvalid_0's multi_logloss: 1.5294\n",
                        "[83]\tvalid_0's multi_logloss: 1.52684\n",
                        "[84]\tvalid_0's multi_logloss: 1.52427\n",
                        "[85]\tvalid_0's multi_logloss: 1.52178\n",
                        "[86]\tvalid_0's multi_logloss: 1.51927\n",
                        "[87]\tvalid_0's multi_logloss: 1.51681\n",
                        "[88]\tvalid_0's multi_logloss: 1.51435\n",
                        "[89]\tvalid_0's multi_logloss: 1.51202\n",
                        "[90]\tvalid_0's multi_logloss: 1.50976\n",
                        "[91]\tvalid_0's multi_logloss: 1.50747\n",
                        "[92]\tvalid_0's multi_logloss: 1.5052\n",
                        "[93]\tvalid_0's multi_logloss: 1.50299\n",
                        "[94]\tvalid_0's multi_logloss: 1.50083\n",
                        "[95]\tvalid_0's multi_logloss: 1.49866\n",
                        "[96]\tvalid_0's multi_logloss: 1.49646\n",
                        "[97]\tvalid_0's multi_logloss: 1.49447\n",
                        "[98]\tvalid_0's multi_logloss: 1.49248\n",
                        "[99]\tvalid_0's multi_logloss: 1.49056\n",
                        "[100]\tvalid_0's multi_logloss: 1.4886\n",
                        "[101]\tvalid_0's multi_logloss: 1.48671\n",
                        "[102]\tvalid_0's multi_logloss: 1.4847\n",
                        "[103]\tvalid_0's multi_logloss: 1.48278\n",
                        "[104]\tvalid_0's multi_logloss: 1.48084\n",
                        "[105]\tvalid_0's multi_logloss: 1.479\n",
                        "[106]\tvalid_0's multi_logloss: 1.47719\n",
                        "[107]\tvalid_0's multi_logloss: 1.47551\n",
                        "[108]\tvalid_0's multi_logloss: 1.47376\n",
                        "[109]\tvalid_0's multi_logloss: 1.47202\n",
                        "[110]\tvalid_0's multi_logloss: 1.47031\n",
                        "[111]\tvalid_0's multi_logloss: 1.46857\n",
                        "[112]\tvalid_0's multi_logloss: 1.46696\n",
                        "[113]\tvalid_0's multi_logloss: 1.46529\n",
                        "[114]\tvalid_0's multi_logloss: 1.46373\n",
                        "[115]\tvalid_0's multi_logloss: 1.46217\n",
                        "[116]\tvalid_0's multi_logloss: 1.4606\n",
                        "[117]\tvalid_0's multi_logloss: 1.45911\n",
                        "[118]\tvalid_0's multi_logloss: 1.4576\n",
                        "[119]\tvalid_0's multi_logloss: 1.45614\n",
                        "[120]\tvalid_0's multi_logloss: 1.45474\n",
                        "[121]\tvalid_0's multi_logloss: 1.45327\n",
                        "[122]\tvalid_0's multi_logloss: 1.45179\n",
                        "[123]\tvalid_0's multi_logloss: 1.45034\n",
                        "[124]\tvalid_0's multi_logloss: 1.44896\n",
                        "[125]\tvalid_0's multi_logloss: 1.44762\n",
                        "[126]\tvalid_0's multi_logloss: 1.44625\n",
                        "[127]\tvalid_0's multi_logloss: 1.44479\n",
                        "[128]\tvalid_0's multi_logloss: 1.44349\n",
                        "[129]\tvalid_0's multi_logloss: 1.44214\n",
                        "[130]\tvalid_0's multi_logloss: 1.44079\n",
                        "[131]\tvalid_0's multi_logloss: 1.43946\n",
                        "[132]\tvalid_0's multi_logloss: 1.43829\n",
                        "[133]\tvalid_0's multi_logloss: 1.43704\n",
                        "[134]\tvalid_0's multi_logloss: 1.43587\n",
                        "[135]\tvalid_0's multi_logloss: 1.43468\n",
                        "[136]\tvalid_0's multi_logloss: 1.43348\n",
                        "[137]\tvalid_0's multi_logloss: 1.43231\n",
                        "[138]\tvalid_0's multi_logloss: 1.43119\n",
                        "[139]\tvalid_0's multi_logloss: 1.42996\n",
                        "[140]\tvalid_0's multi_logloss: 1.4288\n",
                        "[141]\tvalid_0's multi_logloss: 1.42764\n",
                        "[142]\tvalid_0's multi_logloss: 1.42651\n",
                        "[143]\tvalid_0's multi_logloss: 1.42537\n",
                        "[144]\tvalid_0's multi_logloss: 1.42432\n",
                        "[145]\tvalid_0's multi_logloss: 1.42321\n",
                        "[146]\tvalid_0's multi_logloss: 1.42215\n",
                        "[147]\tvalid_0's multi_logloss: 1.42108\n",
                        "[148]\tvalid_0's multi_logloss: 1.4201\n",
                        "[149]\tvalid_0's multi_logloss: 1.41909\n",
                        "[150]\tvalid_0's multi_logloss: 1.41807\n",
                        "[151]\tvalid_0's multi_logloss: 1.41707\n",
                        "[152]\tvalid_0's multi_logloss: 1.41608\n",
                        "[153]\tvalid_0's multi_logloss: 1.41511\n",
                        "[154]\tvalid_0's multi_logloss: 1.41421\n",
                        "[155]\tvalid_0's multi_logloss: 1.41321\n",
                        "[156]\tvalid_0's multi_logloss: 1.41229\n",
                        "[157]\tvalid_0's multi_logloss: 1.41135\n",
                        "[158]\tvalid_0's multi_logloss: 1.41049\n",
                        "[159]\tvalid_0's multi_logloss: 1.40957\n",
                        "[160]\tvalid_0's multi_logloss: 1.40865\n",
                        "[161]\tvalid_0's multi_logloss: 1.40772\n",
                        "[162]\tvalid_0's multi_logloss: 1.40684\n",
                        "[163]\tvalid_0's multi_logloss: 1.40598\n",
                        "[164]\tvalid_0's multi_logloss: 1.40515\n",
                        "[165]\tvalid_0's multi_logloss: 1.40424\n",
                        "[166]\tvalid_0's multi_logloss: 1.40343\n",
                        "[167]\tvalid_0's multi_logloss: 1.40258\n",
                        "[168]\tvalid_0's multi_logloss: 1.40181\n",
                        "[169]\tvalid_0's multi_logloss: 1.40101\n",
                        "[170]\tvalid_0's multi_logloss: 1.40021\n",
                        "[171]\tvalid_0's multi_logloss: 1.3994\n",
                        "[172]\tvalid_0's multi_logloss: 1.39862\n",
                        "[173]\tvalid_0's multi_logloss: 1.39784\n",
                        "[174]\tvalid_0's multi_logloss: 1.39704\n",
                        "[175]\tvalid_0's multi_logloss: 1.39631\n",
                        "[176]\tvalid_0's multi_logloss: 1.39551\n",
                        "[177]\tvalid_0's multi_logloss: 1.39476\n",
                        "[178]\tvalid_0's multi_logloss: 1.39405\n",
                        "[179]\tvalid_0's multi_logloss: 1.39329\n",
                        "[180]\tvalid_0's multi_logloss: 1.39256\n",
                        "[181]\tvalid_0's multi_logloss: 1.39186\n",
                        "[182]\tvalid_0's multi_logloss: 1.39122\n",
                        "[183]\tvalid_0's multi_logloss: 1.39049\n",
                        "[184]\tvalid_0's multi_logloss: 1.38986\n",
                        "[185]\tvalid_0's multi_logloss: 1.38925\n",
                        "[186]\tvalid_0's multi_logloss: 1.3886\n",
                        "[187]\tvalid_0's multi_logloss: 1.3879\n",
                        "[188]\tvalid_0's multi_logloss: 1.38728\n",
                        "[189]\tvalid_0's multi_logloss: 1.38665\n",
                        "[190]\tvalid_0's multi_logloss: 1.38606\n",
                        "[191]\tvalid_0's multi_logloss: 1.3854\n",
                        "[192]\tvalid_0's multi_logloss: 1.38477\n",
                        "[193]\tvalid_0's multi_logloss: 1.38414\n",
                        "[194]\tvalid_0's multi_logloss: 1.38351\n",
                        "[195]\tvalid_0's multi_logloss: 1.38293\n",
                        "[196]\tvalid_0's multi_logloss: 1.38231\n",
                        "[197]\tvalid_0's multi_logloss: 1.38177\n",
                        "[198]\tvalid_0's multi_logloss: 1.38123\n",
                        "[199]\tvalid_0's multi_logloss: 1.38069\n",
                        "[200]\tvalid_0's multi_logloss: 1.38021\n",
                        "[201]\tvalid_0's multi_logloss: 1.37969\n",
                        "[202]\tvalid_0's multi_logloss: 1.37915\n",
                        "[203]\tvalid_0's multi_logloss: 1.37868\n",
                        "[204]\tvalid_0's multi_logloss: 1.37817\n",
                        "[205]\tvalid_0's multi_logloss: 1.37765\n",
                        "[206]\tvalid_0's multi_logloss: 1.37713\n",
                        "[207]\tvalid_0's multi_logloss: 1.37665\n",
                        "[208]\tvalid_0's multi_logloss: 1.37614\n",
                        "[209]\tvalid_0's multi_logloss: 1.37556\n",
                        "[210]\tvalid_0's multi_logloss: 1.37503\n",
                        "[211]\tvalid_0's multi_logloss: 1.37447\n",
                        "[212]\tvalid_0's multi_logloss: 1.37403\n",
                        "[213]\tvalid_0's multi_logloss: 1.37353\n",
                        "[214]\tvalid_0's multi_logloss: 1.37303\n",
                        "[215]\tvalid_0's multi_logloss: 1.37253\n",
                        "[216]\tvalid_0's multi_logloss: 1.37204\n",
                        "[217]\tvalid_0's multi_logloss: 1.37158\n",
                        "[218]\tvalid_0's multi_logloss: 1.37114\n",
                        "[219]\tvalid_0's multi_logloss: 1.3707\n",
                        "[220]\tvalid_0's multi_logloss: 1.37025\n",
                        "[221]\tvalid_0's multi_logloss: 1.36981\n",
                        "[222]\tvalid_0's multi_logloss: 1.36937\n",
                        "[223]\tvalid_0's multi_logloss: 1.36895\n",
                        "[224]\tvalid_0's multi_logloss: 1.36845\n",
                        "[225]\tvalid_0's multi_logloss: 1.36805\n",
                        "[226]\tvalid_0's multi_logloss: 1.36764\n",
                        "[227]\tvalid_0's multi_logloss: 1.36724\n",
                        "[228]\tvalid_0's multi_logloss: 1.36686\n",
                        "[229]\tvalid_0's multi_logloss: 1.36641\n",
                        "[230]\tvalid_0's multi_logloss: 1.36608\n",
                        "[231]\tvalid_0's multi_logloss: 1.36568\n",
                        "[232]\tvalid_0's multi_logloss: 1.36522\n",
                        "[233]\tvalid_0's multi_logloss: 1.36481\n",
                        "[234]\tvalid_0's multi_logloss: 1.36442\n",
                        "[235]\tvalid_0's multi_logloss: 1.36401\n",
                        "[236]\tvalid_0's multi_logloss: 1.36359\n",
                        "[237]\tvalid_0's multi_logloss: 1.36325\n",
                        "[238]\tvalid_0's multi_logloss: 1.36283\n",
                        "[239]\tvalid_0's multi_logloss: 1.36245\n",
                        "[240]\tvalid_0's multi_logloss: 1.36207\n",
                        "[241]\tvalid_0's multi_logloss: 1.3617\n",
                        "[242]\tvalid_0's multi_logloss: 1.36141\n",
                        "[243]\tvalid_0's multi_logloss: 1.36108\n",
                        "[244]\tvalid_0's multi_logloss: 1.36075\n",
                        "[245]\tvalid_0's multi_logloss: 1.36041\n",
                        "[246]\tvalid_0's multi_logloss: 1.36008\n",
                        "[247]\tvalid_0's multi_logloss: 1.35967\n",
                        "[248]\tvalid_0's multi_logloss: 1.35936\n",
                        "[249]\tvalid_0's multi_logloss: 1.35898\n",
                        "[250]\tvalid_0's multi_logloss: 1.35859\n",
                        "[251]\tvalid_0's multi_logloss: 1.35826\n",
                        "[252]\tvalid_0's multi_logloss: 1.35792\n",
                        "[253]\tvalid_0's multi_logloss: 1.35756\n",
                        "[254]\tvalid_0's multi_logloss: 1.35719\n",
                        "[255]\tvalid_0's multi_logloss: 1.35683\n",
                        "[256]\tvalid_0's multi_logloss: 1.3565\n",
                        "[257]\tvalid_0's multi_logloss: 1.35617\n",
                        "[258]\tvalid_0's multi_logloss: 1.35579\n",
                        "[259]\tvalid_0's multi_logloss: 1.35549\n",
                        "[260]\tvalid_0's multi_logloss: 1.35516\n",
                        "[261]\tvalid_0's multi_logloss: 1.35485\n",
                        "[262]\tvalid_0's multi_logloss: 1.35452\n",
                        "[263]\tvalid_0's multi_logloss: 1.3542\n",
                        "[264]\tvalid_0's multi_logloss: 1.35391\n",
                        "[265]\tvalid_0's multi_logloss: 1.35364\n",
                        "[266]\tvalid_0's multi_logloss: 1.35335\n",
                        "[267]\tvalid_0's multi_logloss: 1.35306\n",
                        "[268]\tvalid_0's multi_logloss: 1.35275\n",
                        "[269]\tvalid_0's multi_logloss: 1.35243\n",
                        "[270]\tvalid_0's multi_logloss: 1.35214\n",
                        "[271]\tvalid_0's multi_logloss: 1.35185\n",
                        "[272]\tvalid_0's multi_logloss: 1.35155\n",
                        "[273]\tvalid_0's multi_logloss: 1.35124\n",
                        "[274]\tvalid_0's multi_logloss: 1.35096\n",
                        "[275]\tvalid_0's multi_logloss: 1.35067\n",
                        "[276]\tvalid_0's multi_logloss: 1.35035\n",
                        "[277]\tvalid_0's multi_logloss: 1.35008\n",
                        "[278]\tvalid_0's multi_logloss: 1.34984\n",
                        "[279]\tvalid_0's multi_logloss: 1.34955\n",
                        "[280]\tvalid_0's multi_logloss: 1.34928\n",
                        "[281]\tvalid_0's multi_logloss: 1.34899\n",
                        "[282]\tvalid_0's multi_logloss: 1.34866\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[283]\tvalid_0's multi_logloss: 1.34841\n",
                        "[284]\tvalid_0's multi_logloss: 1.34816\n",
                        "[285]\tvalid_0's multi_logloss: 1.34785\n",
                        "[286]\tvalid_0's multi_logloss: 1.34758\n",
                        "[287]\tvalid_0's multi_logloss: 1.34728\n",
                        "[288]\tvalid_0's multi_logloss: 1.347\n",
                        "[289]\tvalid_0's multi_logloss: 1.34665\n",
                        "[290]\tvalid_0's multi_logloss: 1.34641\n",
                        "[291]\tvalid_0's multi_logloss: 1.34617\n",
                        "[292]\tvalid_0's multi_logloss: 1.34591\n",
                        "[293]\tvalid_0's multi_logloss: 1.34563\n",
                        "[294]\tvalid_0's multi_logloss: 1.34542\n",
                        "[295]\tvalid_0's multi_logloss: 1.3452\n",
                        "[296]\tvalid_0's multi_logloss: 1.34493\n",
                        "[297]\tvalid_0's multi_logloss: 1.34468\n",
                        "[298]\tvalid_0's multi_logloss: 1.34451\n",
                        "[299]\tvalid_0's multi_logloss: 1.34423\n",
                        "[300]\tvalid_0's multi_logloss: 1.34401\n",
                        "[301]\tvalid_0's multi_logloss: 1.34375\n",
                        "[302]\tvalid_0's multi_logloss: 1.34354\n",
                        "[303]\tvalid_0's multi_logloss: 1.3433\n",
                        "[304]\tvalid_0's multi_logloss: 1.34303\n",
                        "[305]\tvalid_0's multi_logloss: 1.34277\n",
                        "[306]\tvalid_0's multi_logloss: 1.34255\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[307]\tvalid_0's multi_logloss: 1.34233\n",
                        "[308]\tvalid_0's multi_logloss: 1.34205\n",
                        "[309]\tvalid_0's multi_logloss: 1.34184\n",
                        "[310]\tvalid_0's multi_logloss: 1.34162\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[311]\tvalid_0's multi_logloss: 1.3414\n",
                        "[312]\tvalid_0's multi_logloss: 1.34118\n",
                        "[313]\tvalid_0's multi_logloss: 1.34093\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[314]\tvalid_0's multi_logloss: 1.3407\n",
                        "[315]\tvalid_0's multi_logloss: 1.34046\n",
                        "[316]\tvalid_0's multi_logloss: 1.34024\n",
                        "[317]\tvalid_0's multi_logloss: 1.34004\n",
                        "[318]\tvalid_0's multi_logloss: 1.33981\n",
                        "[319]\tvalid_0's multi_logloss: 1.3396\n",
                        "[320]\tvalid_0's multi_logloss: 1.33938\n",
                        "[321]\tvalid_0's multi_logloss: 1.33918\n",
                        "[322]\tvalid_0's multi_logloss: 1.33896\n",
                        "[323]\tvalid_0's multi_logloss: 1.3387\n",
                        "[324]\tvalid_0's multi_logloss: 1.33848\n",
                        "[325]\tvalid_0's multi_logloss: 1.33828\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[326]\tvalid_0's multi_logloss: 1.33807\n",
                        "[327]\tvalid_0's multi_logloss: 1.33788\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[328]\tvalid_0's multi_logloss: 1.33765\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[329]\tvalid_0's multi_logloss: 1.33743\n",
                        "[330]\tvalid_0's multi_logloss: 1.3372\n",
                        "[331]\tvalid_0's multi_logloss: 1.33701\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[332]\tvalid_0's multi_logloss: 1.33679\n",
                        "[333]\tvalid_0's multi_logloss: 1.33662\n",
                        "[334]\tvalid_0's multi_logloss: 1.33645\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[335]\tvalid_0's multi_logloss: 1.33629\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[336]\tvalid_0's multi_logloss: 1.33612\n",
                        "[337]\tvalid_0's multi_logloss: 1.33593\n",
                        "[338]\tvalid_0's multi_logloss: 1.33574\n",
                        "[339]\tvalid_0's multi_logloss: 1.33551\n",
                        "[340]\tvalid_0's multi_logloss: 1.33533\n",
                        "[341]\tvalid_0's multi_logloss: 1.33515\n",
                        "[342]\tvalid_0's multi_logloss: 1.33499\n",
                        "[343]\tvalid_0's multi_logloss: 1.33477\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[344]\tvalid_0's multi_logloss: 1.3346\n",
                        "[345]\tvalid_0's multi_logloss: 1.33436\n",
                        "[346]\tvalid_0's multi_logloss: 1.33418\n",
                        "[347]\tvalid_0's multi_logloss: 1.33395\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[348]\tvalid_0's multi_logloss: 1.33377\n",
                        "[349]\tvalid_0's multi_logloss: 1.33363\n",
                        "[350]\tvalid_0's multi_logloss: 1.33347\n",
                        "[351]\tvalid_0's multi_logloss: 1.33329\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[352]\tvalid_0's multi_logloss: 1.33311\n",
                        "[353]\tvalid_0's multi_logloss: 1.33293\n",
                        "[354]\tvalid_0's multi_logloss: 1.33274\n",
                        "[355]\tvalid_0's multi_logloss: 1.33257\n",
                        "[356]\tvalid_0's multi_logloss: 1.3324\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[357]\tvalid_0's multi_logloss: 1.33223\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[358]\tvalid_0's multi_logloss: 1.33207\n",
                        "[359]\tvalid_0's multi_logloss: 1.33189\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[360]\tvalid_0's multi_logloss: 1.33174\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[361]\tvalid_0's multi_logloss: 1.33158\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[362]\tvalid_0's multi_logloss: 1.33143\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[363]\tvalid_0's multi_logloss: 1.3313\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[364]\tvalid_0's multi_logloss: 1.33116\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[365]\tvalid_0's multi_logloss: 1.33102\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[366]\tvalid_0's multi_logloss: 1.33085\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[367]\tvalid_0's multi_logloss: 1.33069\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[368]\tvalid_0's multi_logloss: 1.33049\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[369]\tvalid_0's multi_logloss: 1.33034\n",
                        "[370]\tvalid_0's multi_logloss: 1.33014\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[371]\tvalid_0's multi_logloss: 1.32997\n",
                        "[372]\tvalid_0's multi_logloss: 1.32981\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[373]\tvalid_0's multi_logloss: 1.32964\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[374]\tvalid_0's multi_logloss: 1.32947\n",
                        "[375]\tvalid_0's multi_logloss: 1.32934\n",
                        "[376]\tvalid_0's multi_logloss: 1.32919\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[377]\tvalid_0's multi_logloss: 1.32899\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[378]\tvalid_0's multi_logloss: 1.32884\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[379]\tvalid_0's multi_logloss: 1.32867\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[380]\tvalid_0's multi_logloss: 1.3285\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[381]\tvalid_0's multi_logloss: 1.32828\n",
                        "[382]\tvalid_0's multi_logloss: 1.32811\n",
                        "[383]\tvalid_0's multi_logloss: 1.32792\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[384]\tvalid_0's multi_logloss: 1.32774\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[385]\tvalid_0's multi_logloss: 1.32757\n",
                        "[386]\tvalid_0's multi_logloss: 1.32742\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[387]\tvalid_0's multi_logloss: 1.32727\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[388]\tvalid_0's multi_logloss: 1.32708\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[389]\tvalid_0's multi_logloss: 1.32692\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[390]\tvalid_0's multi_logloss: 1.32677\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[391]\tvalid_0's multi_logloss: 1.32663\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[392]\tvalid_0's multi_logloss: 1.3265\n",
                        "[393]\tvalid_0's multi_logloss: 1.32636\n",
                        "[394]\tvalid_0's multi_logloss: 1.32621\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[395]\tvalid_0's multi_logloss: 1.32606\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[396]\tvalid_0's multi_logloss: 1.32594\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[397]\tvalid_0's multi_logloss: 1.32581\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[398]\tvalid_0's multi_logloss: 1.32568\n",
                        "[399]\tvalid_0's multi_logloss: 1.32551\n",
                        "[400]\tvalid_0's multi_logloss: 1.32539\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[401]\tvalid_0's multi_logloss: 1.32525\n",
                        "[402]\tvalid_0's multi_logloss: 1.3251\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[403]\tvalid_0's multi_logloss: 1.32499\n",
                        "[404]\tvalid_0's multi_logloss: 1.32484\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[405]\tvalid_0's multi_logloss: 1.32467\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[406]\tvalid_0's multi_logloss: 1.32453\n",
                        "[407]\tvalid_0's multi_logloss: 1.32435\n",
                        "[408]\tvalid_0's multi_logloss: 1.3242\n",
                        "[409]\tvalid_0's multi_logloss: 1.32406\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[410]\tvalid_0's multi_logloss: 1.32392\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[411]\tvalid_0's multi_logloss: 1.32377\n",
                        "[412]\tvalid_0's multi_logloss: 1.32366\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[413]\tvalid_0's multi_logloss: 1.3235\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[414]\tvalid_0's multi_logloss: 1.32336\n",
                        "[415]\tvalid_0's multi_logloss: 1.32322\n",
                        "[416]\tvalid_0's multi_logloss: 1.3231\n",
                        "[417]\tvalid_0's multi_logloss: 1.32297\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[418]\tvalid_0's multi_logloss: 1.3228\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[419]\tvalid_0's multi_logloss: 1.32265\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[420]\tvalid_0's multi_logloss: 1.32252\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[421]\tvalid_0's multi_logloss: 1.3224\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[422]\tvalid_0's multi_logloss: 1.32224\n",
                        "[423]\tvalid_0's multi_logloss: 1.32212\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[424]\tvalid_0's multi_logloss: 1.32201\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[425]\tvalid_0's multi_logloss: 1.32186\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[426]\tvalid_0's multi_logloss: 1.32173\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[427]\tvalid_0's multi_logloss: 1.32158\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[428]\tvalid_0's multi_logloss: 1.32147\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[429]\tvalid_0's multi_logloss: 1.32135\n",
                        "[430]\tvalid_0's multi_logloss: 1.32125\n",
                        "[431]\tvalid_0's multi_logloss: 1.32111\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[432]\tvalid_0's multi_logloss: 1.32101\n",
                        "[433]\tvalid_0's multi_logloss: 1.32089\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[434]\tvalid_0's multi_logloss: 1.32077\n",
                        "[435]\tvalid_0's multi_logloss: 1.32064\n",
                        "[436]\tvalid_0's multi_logloss: 1.3205\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[437]\tvalid_0's multi_logloss: 1.32041\n",
                        "[438]\tvalid_0's multi_logloss: 1.32028\n",
                        "[439]\tvalid_0's multi_logloss: 1.32016\n",
                        "[440]\tvalid_0's multi_logloss: 1.32006\n",
                        "[441]\tvalid_0's multi_logloss: 1.31994\n",
                        "[442]\tvalid_0's multi_logloss: 1.31981\n",
                        "[443]\tvalid_0's multi_logloss: 1.31968\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[444]\tvalid_0's multi_logloss: 1.31955\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[445]\tvalid_0's multi_logloss: 1.31943\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[446]\tvalid_0's multi_logloss: 1.31929\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[447]\tvalid_0's multi_logloss: 1.3192\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[448]\tvalid_0's multi_logloss: 1.31907\n",
                        "[449]\tvalid_0's multi_logloss: 1.31895\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[450]\tvalid_0's multi_logloss: 1.31882\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[451]\tvalid_0's multi_logloss: 1.3187\n",
                        "[452]\tvalid_0's multi_logloss: 1.31858\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[453]\tvalid_0's multi_logloss: 1.31845\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[454]\tvalid_0's multi_logloss: 1.31832\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[455]\tvalid_0's multi_logloss: 1.31818\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[456]\tvalid_0's multi_logloss: 1.3181\n",
                        "[457]\tvalid_0's multi_logloss: 1.31796\n",
                        "[458]\tvalid_0's multi_logloss: 1.31782\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[459]\tvalid_0's multi_logloss: 1.31772\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[460]\tvalid_0's multi_logloss: 1.31761\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[461]\tvalid_0's multi_logloss: 1.31748\n",
                        "[462]\tvalid_0's multi_logloss: 1.31737\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[463]\tvalid_0's multi_logloss: 1.31722\n",
                        "[464]\tvalid_0's multi_logloss: 1.31708\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[465]\tvalid_0's multi_logloss: 1.31695\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[466]\tvalid_0's multi_logloss: 1.31681\n",
                        "[467]\tvalid_0's multi_logloss: 1.3167\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[468]\tvalid_0's multi_logloss: 1.31663\n",
                        "[469]\tvalid_0's multi_logloss: 1.31647\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[470]\tvalid_0's multi_logloss: 1.31634\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[471]\tvalid_0's multi_logloss: 1.3162\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[472]\tvalid_0's multi_logloss: 1.31609\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[473]\tvalid_0's multi_logloss: 1.31599\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[474]\tvalid_0's multi_logloss: 1.31586\n",
                        "[475]\tvalid_0's multi_logloss: 1.31574\n",
                        "[476]\tvalid_0's multi_logloss: 1.31563\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[477]\tvalid_0's multi_logloss: 1.31551\n",
                        "[478]\tvalid_0's multi_logloss: 1.31543\n",
                        "[479]\tvalid_0's multi_logloss: 1.31532\n",
                        "[480]\tvalid_0's multi_logloss: 1.31523\n",
                        "[481]\tvalid_0's multi_logloss: 1.31511\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[482]\tvalid_0's multi_logloss: 1.31499\n",
                        "[483]\tvalid_0's multi_logloss: 1.3149\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[484]\tvalid_0's multi_logloss: 1.31479\n",
                        "[485]\tvalid_0's multi_logloss: 1.31469\n",
                        "[486]\tvalid_0's multi_logloss: 1.31459\n",
                        "[487]\tvalid_0's multi_logloss: 1.31448\n",
                        "[488]\tvalid_0's multi_logloss: 1.31435\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[489]\tvalid_0's multi_logloss: 1.31427\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[490]\tvalid_0's multi_logloss: 1.31412\n",
                        "[491]\tvalid_0's multi_logloss: 1.31401\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[492]\tvalid_0's multi_logloss: 1.31392\n",
                        "[493]\tvalid_0's multi_logloss: 1.31384\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[494]\tvalid_0's multi_logloss: 1.31374\n",
                        "[495]\tvalid_0's multi_logloss: 1.31363\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[496]\tvalid_0's multi_logloss: 1.31349\n",
                        "[497]\tvalid_0's multi_logloss: 1.31336\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[498]\tvalid_0's multi_logloss: 1.31329\n",
                        "[499]\tvalid_0's multi_logloss: 1.3132\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[500]\tvalid_0's multi_logloss: 1.31311\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[501]\tvalid_0's multi_logloss: 1.31302\n",
                        "[502]\tvalid_0's multi_logloss: 1.31289\n",
                        "[503]\tvalid_0's multi_logloss: 1.31278\n",
                        "[504]\tvalid_0's multi_logloss: 1.31265\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[505]\tvalid_0's multi_logloss: 1.31256\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[506]\tvalid_0's multi_logloss: 1.31248\n",
                        "[507]\tvalid_0's multi_logloss: 1.31237\n",
                        "[508]\tvalid_0's multi_logloss: 1.31227\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[509]\tvalid_0's multi_logloss: 1.31217\n",
                        "[510]\tvalid_0's multi_logloss: 1.31207\n",
                        "[511]\tvalid_0's multi_logloss: 1.31199\n",
                        "[512]\tvalid_0's multi_logloss: 1.31191\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[513]\tvalid_0's multi_logloss: 1.31183\n",
                        "[514]\tvalid_0's multi_logloss: 1.31172\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[515]\tvalid_0's multi_logloss: 1.31163\n",
                        "[516]\tvalid_0's multi_logloss: 1.31156\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[517]\tvalid_0's multi_logloss: 1.31144\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[518]\tvalid_0's multi_logloss: 1.31132\n",
                        "[519]\tvalid_0's multi_logloss: 1.31123\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[520]\tvalid_0's multi_logloss: 1.31114\n",
                        "[521]\tvalid_0's multi_logloss: 1.31104\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[522]\tvalid_0's multi_logloss: 1.31091\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[523]\tvalid_0's multi_logloss: 1.31082\n",
                        "[524]\tvalid_0's multi_logloss: 1.31071\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[525]\tvalid_0's multi_logloss: 1.31062\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[526]\tvalid_0's multi_logloss: 1.31051\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[527]\tvalid_0's multi_logloss: 1.31044\n",
                        "[528]\tvalid_0's multi_logloss: 1.31036\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[529]\tvalid_0's multi_logloss: 1.31024\n",
                        "[530]\tvalid_0's multi_logloss: 1.31017\n",
                        "[531]\tvalid_0's multi_logloss: 1.31009\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[532]\tvalid_0's multi_logloss: 1.31\n",
                        "[533]\tvalid_0's multi_logloss: 1.3099\n",
                        "[534]\tvalid_0's multi_logloss: 1.30979\n",
                        "[535]\tvalid_0's multi_logloss: 1.30969\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[536]\tvalid_0's multi_logloss: 1.30957\n",
                        "[537]\tvalid_0's multi_logloss: 1.30951\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[538]\tvalid_0's multi_logloss: 1.30943\n",
                        "[539]\tvalid_0's multi_logloss: 1.30935\n",
                        "[540]\tvalid_0's multi_logloss: 1.30926\n",
                        "[541]\tvalid_0's multi_logloss: 1.30917\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[542]\tvalid_0's multi_logloss: 1.30907\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[543]\tvalid_0's multi_logloss: 1.30899\n",
                        "[544]\tvalid_0's multi_logloss: 1.3089\n",
                        "[545]\tvalid_0's multi_logloss: 1.30884\n",
                        "[546]\tvalid_0's multi_logloss: 1.30874\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[547]\tvalid_0's multi_logloss: 1.30867\n",
                        "[548]\tvalid_0's multi_logloss: 1.30859\n",
                        "[549]\tvalid_0's multi_logloss: 1.30847\n",
                        "[550]\tvalid_0's multi_logloss: 1.30837\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[551]\tvalid_0's multi_logloss: 1.30828\n",
                        "[552]\tvalid_0's multi_logloss: 1.30822\n",
                        "[553]\tvalid_0's multi_logloss: 1.30812\n",
                        "[554]\tvalid_0's multi_logloss: 1.30801\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[555]\tvalid_0's multi_logloss: 1.30794\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[556]\tvalid_0's multi_logloss: 1.30786\n",
                        "[557]\tvalid_0's multi_logloss: 1.30775\n",
                        "[558]\tvalid_0's multi_logloss: 1.30766\n",
                        "[559]\tvalid_0's multi_logloss: 1.30756\n",
                        "[560]\tvalid_0's multi_logloss: 1.30746\n",
                        "[561]\tvalid_0's multi_logloss: 1.30737\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[562]\tvalid_0's multi_logloss: 1.30727\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[563]\tvalid_0's multi_logloss: 1.30719\n",
                        "[564]\tvalid_0's multi_logloss: 1.3071\n",
                        "[565]\tvalid_0's multi_logloss: 1.307\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[566]\tvalid_0's multi_logloss: 1.3069\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[567]\tvalid_0's multi_logloss: 1.30682\n",
                        "[568]\tvalid_0's multi_logloss: 1.30671\n",
                        "[569]\tvalid_0's multi_logloss: 1.30664\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[570]\tvalid_0's multi_logloss: 1.30654\n",
                        "[571]\tvalid_0's multi_logloss: 1.30644\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[572]\tvalid_0's multi_logloss: 1.30634\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[573]\tvalid_0's multi_logloss: 1.30625\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[574]\tvalid_0's multi_logloss: 1.30615\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[575]\tvalid_0's multi_logloss: 1.30609\n",
                        "[576]\tvalid_0's multi_logloss: 1.30598\n",
                        "[577]\tvalid_0's multi_logloss: 1.30589\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[578]\tvalid_0's multi_logloss: 1.3058\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[579]\tvalid_0's multi_logloss: 1.30571\n",
                        "[580]\tvalid_0's multi_logloss: 1.30564\n",
                        "[581]\tvalid_0's multi_logloss: 1.30554\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[582]\tvalid_0's multi_logloss: 1.30548\n",
                        "[583]\tvalid_0's multi_logloss: 1.30537\n",
                        "[584]\tvalid_0's multi_logloss: 1.3053\n",
                        "[585]\tvalid_0's multi_logloss: 1.30523\n",
                        "[586]\tvalid_0's multi_logloss: 1.30514\n",
                        "[587]\tvalid_0's multi_logloss: 1.30504\n",
                        "[588]\tvalid_0's multi_logloss: 1.30495\n",
                        "[589]\tvalid_0's multi_logloss: 1.30486\n",
                        "[590]\tvalid_0's multi_logloss: 1.30478\n",
                        "[591]\tvalid_0's multi_logloss: 1.30467\n",
                        "[592]\tvalid_0's multi_logloss: 1.30461\n",
                        "[593]\tvalid_0's multi_logloss: 1.30455\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[594]\tvalid_0's multi_logloss: 1.30445\n",
                        "[595]\tvalid_0's multi_logloss: 1.30434\n",
                        "[596]\tvalid_0's multi_logloss: 1.30425\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[597]\tvalid_0's multi_logloss: 1.30418\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[598]\tvalid_0's multi_logloss: 1.30413\n",
                        "[599]\tvalid_0's multi_logloss: 1.304\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[600]\tvalid_0's multi_logloss: 1.30392\n",
                        "[601]\tvalid_0's multi_logloss: 1.30383\n",
                        "[602]\tvalid_0's multi_logloss: 1.30377\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[603]\tvalid_0's multi_logloss: 1.3037\n",
                        "[604]\tvalid_0's multi_logloss: 1.30366\n",
                        "[605]\tvalid_0's multi_logloss: 1.3036\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[606]\tvalid_0's multi_logloss: 1.30352\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[607]\tvalid_0's multi_logloss: 1.30343\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[608]\tvalid_0's multi_logloss: 1.30333\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[609]\tvalid_0's multi_logloss: 1.30326\n",
                        "[610]\tvalid_0's multi_logloss: 1.30319\n",
                        "[611]\tvalid_0's multi_logloss: 1.3031\n",
                        "[612]\tvalid_0's multi_logloss: 1.30302\n",
                        "[613]\tvalid_0's multi_logloss: 1.30295\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[614]\tvalid_0's multi_logloss: 1.30286\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[615]\tvalid_0's multi_logloss: 1.30277\n",
                        "[616]\tvalid_0's multi_logloss: 1.3027\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[617]\tvalid_0's multi_logloss: 1.30262\n",
                        "[618]\tvalid_0's multi_logloss: 1.30253\n",
                        "[619]\tvalid_0's multi_logloss: 1.30244\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[620]\tvalid_0's multi_logloss: 1.30238\n",
                        "[621]\tvalid_0's multi_logloss: 1.30229\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[622]\tvalid_0's multi_logloss: 1.30221\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[623]\tvalid_0's multi_logloss: 1.30214\n",
                        "[624]\tvalid_0's multi_logloss: 1.30207\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[625]\tvalid_0's multi_logloss: 1.30197\n",
                        "[626]\tvalid_0's multi_logloss: 1.30191\n",
                        "[627]\tvalid_0's multi_logloss: 1.30183\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[628]\tvalid_0's multi_logloss: 1.30175\n",
                        "[629]\tvalid_0's multi_logloss: 1.30166\n",
                        "[630]\tvalid_0's multi_logloss: 1.3016\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[631]\tvalid_0's multi_logloss: 1.30153\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[632]\tvalid_0's multi_logloss: 1.30144\n",
                        "[633]\tvalid_0's multi_logloss: 1.30137\n",
                        "[634]\tvalid_0's multi_logloss: 1.3013\n",
                        "[635]\tvalid_0's multi_logloss: 1.30124\n",
                        "[636]\tvalid_0's multi_logloss: 1.30116\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[637]\tvalid_0's multi_logloss: 1.3011\n",
                        "[638]\tvalid_0's multi_logloss: 1.30101\n",
                        "[639]\tvalid_0's multi_logloss: 1.30096\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[640]\tvalid_0's multi_logloss: 1.30089\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[641]\tvalid_0's multi_logloss: 1.30082\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[642]\tvalid_0's multi_logloss: 1.30074\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[643]\tvalid_0's multi_logloss: 1.30067\n",
                        "[644]\tvalid_0's multi_logloss: 1.30062\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[645]\tvalid_0's multi_logloss: 1.30057\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[646]\tvalid_0's multi_logloss: 1.30048\n",
                        "[647]\tvalid_0's multi_logloss: 1.30038\n",
                        "[648]\tvalid_0's multi_logloss: 1.30034\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[649]\tvalid_0's multi_logloss: 1.30028\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[650]\tvalid_0's multi_logloss: 1.30022\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[651]\tvalid_0's multi_logloss: 1.30015\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[652]\tvalid_0's multi_logloss: 1.30006\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[653]\tvalid_0's multi_logloss: 1.29994\n",
                        "[654]\tvalid_0's multi_logloss: 1.29986\n",
                        "[655]\tvalid_0's multi_logloss: 1.29978\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[656]\tvalid_0's multi_logloss: 1.29971\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[657]\tvalid_0's multi_logloss: 1.29963\n",
                        "[658]\tvalid_0's multi_logloss: 1.29956\n",
                        "[659]\tvalid_0's multi_logloss: 1.29949\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[660]\tvalid_0's multi_logloss: 1.2994\n",
                        "[661]\tvalid_0's multi_logloss: 1.2993\n",
                        "[662]\tvalid_0's multi_logloss: 1.29924\n",
                        "[663]\tvalid_0's multi_logloss: 1.29919\n",
                        "[664]\tvalid_0's multi_logloss: 1.29911\n",
                        "[665]\tvalid_0's multi_logloss: 1.29903\n",
                        "[666]\tvalid_0's multi_logloss: 1.29895\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[667]\tvalid_0's multi_logloss: 1.29888\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[668]\tvalid_0's multi_logloss: 1.29881\n",
                        "[669]\tvalid_0's multi_logloss: 1.29873\n",
                        "[670]\tvalid_0's multi_logloss: 1.29866\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[671]\tvalid_0's multi_logloss: 1.2986\n",
                        "[672]\tvalid_0's multi_logloss: 1.29854\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[673]\tvalid_0's multi_logloss: 1.29845\n",
                        "[674]\tvalid_0's multi_logloss: 1.29841\n",
                        "[675]\tvalid_0's multi_logloss: 1.29834\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[676]\tvalid_0's multi_logloss: 1.29829\n",
                        "[677]\tvalid_0's multi_logloss: 1.29823\n",
                        "[678]\tvalid_0's multi_logloss: 1.29817\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[679]\tvalid_0's multi_logloss: 1.29809\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[680]\tvalid_0's multi_logloss: 1.29803\n",
                        "[681]\tvalid_0's multi_logloss: 1.29794\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[682]\tvalid_0's multi_logloss: 1.29788\n",
                        "[683]\tvalid_0's multi_logloss: 1.29781\n",
                        "[684]\tvalid_0's multi_logloss: 1.29775\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[685]\tvalid_0's multi_logloss: 1.29768\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[686]\tvalid_0's multi_logloss: 1.29762\n",
                        "[687]\tvalid_0's multi_logloss: 1.29757\n",
                        "[688]\tvalid_0's multi_logloss: 1.29749\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[689]\tvalid_0's multi_logloss: 1.29742\n",
                        "[690]\tvalid_0's multi_logloss: 1.29736\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[691]\tvalid_0's multi_logloss: 1.29729\n",
                        "[692]\tvalid_0's multi_logloss: 1.29723\n",
                        "[693]\tvalid_0's multi_logloss: 1.29715\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[694]\tvalid_0's multi_logloss: 1.29709\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[695]\tvalid_0's multi_logloss: 1.29702\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[696]\tvalid_0's multi_logloss: 1.29693\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[697]\tvalid_0's multi_logloss: 1.29688\n",
                        "[698]\tvalid_0's multi_logloss: 1.29684\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[699]\tvalid_0's multi_logloss: 1.29679\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[700]\tvalid_0's multi_logloss: 1.29672\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[701]\tvalid_0's multi_logloss: 1.29666\n",
                        "[702]\tvalid_0's multi_logloss: 1.29659\n",
                        "[703]\tvalid_0's multi_logloss: 1.29653\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[704]\tvalid_0's multi_logloss: 1.29648\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[705]\tvalid_0's multi_logloss: 1.2964\n",
                        "[706]\tvalid_0's multi_logloss: 1.29636\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[707]\tvalid_0's multi_logloss: 1.29629\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[708]\tvalid_0's multi_logloss: 1.29623\n",
                        "[709]\tvalid_0's multi_logloss: 1.29616\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[710]\tvalid_0's multi_logloss: 1.29609\n",
                        "[711]\tvalid_0's multi_logloss: 1.29602\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[712]\tvalid_0's multi_logloss: 1.29595\n",
                        "[713]\tvalid_0's multi_logloss: 1.29587\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[714]\tvalid_0's multi_logloss: 1.29581\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[715]\tvalid_0's multi_logloss: 1.29575\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[716]\tvalid_0's multi_logloss: 1.29568\n",
                        "[717]\tvalid_0's multi_logloss: 1.29563\n",
                        "[718]\tvalid_0's multi_logloss: 1.29557\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[719]\tvalid_0's multi_logloss: 1.29548\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[720]\tvalid_0's multi_logloss: 1.29543\n",
                        "[721]\tvalid_0's multi_logloss: 1.29535\n",
                        "[722]\tvalid_0's multi_logloss: 1.29531\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[723]\tvalid_0's multi_logloss: 1.29524\n",
                        "[724]\tvalid_0's multi_logloss: 1.29517\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[725]\tvalid_0's multi_logloss: 1.29512\n",
                        "[726]\tvalid_0's multi_logloss: 1.29505\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[727]\tvalid_0's multi_logloss: 1.29498\n",
                        "[728]\tvalid_0's multi_logloss: 1.29493\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[729]\tvalid_0's multi_logloss: 1.29486\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[730]\tvalid_0's multi_logloss: 1.29481\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[731]\tvalid_0's multi_logloss: 1.29475\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[732]\tvalid_0's multi_logloss: 1.29469\n",
                        "[733]\tvalid_0's multi_logloss: 1.29462\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[734]\tvalid_0's multi_logloss: 1.29456\n",
                        "[735]\tvalid_0's multi_logloss: 1.29449\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[736]\tvalid_0's multi_logloss: 1.29442\n",
                        "[737]\tvalid_0's multi_logloss: 1.29434\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[738]\tvalid_0's multi_logloss: 1.29427\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[739]\tvalid_0's multi_logloss: 1.29421\n",
                        "[740]\tvalid_0's multi_logloss: 1.29417\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[741]\tvalid_0's multi_logloss: 1.2941\n",
                        "[742]\tvalid_0's multi_logloss: 1.29407\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[743]\tvalid_0's multi_logloss: 1.29402\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[744]\tvalid_0's multi_logloss: 1.29393\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[745]\tvalid_0's multi_logloss: 1.29389\n",
                        "[746]\tvalid_0's multi_logloss: 1.29382\n",
                        "[747]\tvalid_0's multi_logloss: 1.29376\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[748]\tvalid_0's multi_logloss: 1.2937\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[749]\tvalid_0's multi_logloss: 1.29362\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[750]\tvalid_0's multi_logloss: 1.29357\n",
                        "[751]\tvalid_0's multi_logloss: 1.29349\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[752]\tvalid_0's multi_logloss: 1.29344\n",
                        "[753]\tvalid_0's multi_logloss: 1.2934\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[754]\tvalid_0's multi_logloss: 1.29333\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[755]\tvalid_0's multi_logloss: 1.29328\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[756]\tvalid_0's multi_logloss: 1.29322\n",
                        "[757]\tvalid_0's multi_logloss: 1.29318\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[758]\tvalid_0's multi_logloss: 1.29312\n",
                        "[759]\tvalid_0's multi_logloss: 1.29305\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[760]\tvalid_0's multi_logloss: 1.29298\n",
                        "[761]\tvalid_0's multi_logloss: 1.29292\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[762]\tvalid_0's multi_logloss: 1.29287\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[763]\tvalid_0's multi_logloss: 1.29282\n",
                        "[764]\tvalid_0's multi_logloss: 1.29274\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[765]\tvalid_0's multi_logloss: 1.29268\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[766]\tvalid_0's multi_logloss: 1.29262\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[767]\tvalid_0's multi_logloss: 1.29258\n",
                        "[768]\tvalid_0's multi_logloss: 1.29254\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[769]\tvalid_0's multi_logloss: 1.29249\n",
                        "[770]\tvalid_0's multi_logloss: 1.29243\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[771]\tvalid_0's multi_logloss: 1.29238\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[772]\tvalid_0's multi_logloss: 1.29233\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[773]\tvalid_0's multi_logloss: 1.29228\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[774]\tvalid_0's multi_logloss: 1.29221\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[775]\tvalid_0's multi_logloss: 1.29218\n",
                        "[776]\tvalid_0's multi_logloss: 1.29214\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[777]\tvalid_0's multi_logloss: 1.29209\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[778]\tvalid_0's multi_logloss: 1.29204\n",
                        "[779]\tvalid_0's multi_logloss: 1.29199\n",
                        "[780]\tvalid_0's multi_logloss: 1.29195\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[781]\tvalid_0's multi_logloss: 1.29188\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[782]\tvalid_0's multi_logloss: 1.29181\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[783]\tvalid_0's multi_logloss: 1.29175\n",
                        "[784]\tvalid_0's multi_logloss: 1.29168\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[785]\tvalid_0's multi_logloss: 1.29165\n",
                        "[786]\tvalid_0's multi_logloss: 1.29159\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[787]\tvalid_0's multi_logloss: 1.29151\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[788]\tvalid_0's multi_logloss: 1.29144\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[789]\tvalid_0's multi_logloss: 1.2914\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[790]\tvalid_0's multi_logloss: 1.29136\n",
                        "[791]\tvalid_0's multi_logloss: 1.29129\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[792]\tvalid_0's multi_logloss: 1.29125\n",
                        "[793]\tvalid_0's multi_logloss: 1.29122\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[794]\tvalid_0's multi_logloss: 1.29115\n",
                        "[795]\tvalid_0's multi_logloss: 1.2911\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[796]\tvalid_0's multi_logloss: 1.29103\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[797]\tvalid_0's multi_logloss: 1.29098\n",
                        "[798]\tvalid_0's multi_logloss: 1.29096\n",
                        "[799]\tvalid_0's multi_logloss: 1.2909\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[800]\tvalid_0's multi_logloss: 1.29084\n",
                        "[801]\tvalid_0's multi_logloss: 1.2908\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[802]\tvalid_0's multi_logloss: 1.29073\n",
                        "[803]\tvalid_0's multi_logloss: 1.29067\n",
                        "[804]\tvalid_0's multi_logloss: 1.29061\n",
                        "[805]\tvalid_0's multi_logloss: 1.29054\n",
                        "[806]\tvalid_0's multi_logloss: 1.29047\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[807]\tvalid_0's multi_logloss: 1.29042\n",
                        "[808]\tvalid_0's multi_logloss: 1.29034\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[809]\tvalid_0's multi_logloss: 1.2903\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[810]\tvalid_0's multi_logloss: 1.29023\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[811]\tvalid_0's multi_logloss: 1.2902\n",
                        "[812]\tvalid_0's multi_logloss: 1.29014\n",
                        "[813]\tvalid_0's multi_logloss: 1.29007\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[814]\tvalid_0's multi_logloss: 1.29001\n",
                        "[815]\tvalid_0's multi_logloss: 1.28995\n",
                        "[816]\tvalid_0's multi_logloss: 1.2899\n",
                        "[817]\tvalid_0's multi_logloss: 1.28982\n",
                        "[818]\tvalid_0's multi_logloss: 1.28977\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[819]\tvalid_0's multi_logloss: 1.28971\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[820]\tvalid_0's multi_logloss: 1.28965\n",
                        "[821]\tvalid_0's multi_logloss: 1.28962\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[822]\tvalid_0's multi_logloss: 1.28959\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[823]\tvalid_0's multi_logloss: 1.28954\n",
                        "[824]\tvalid_0's multi_logloss: 1.28949\n",
                        "[825]\tvalid_0's multi_logloss: 1.28946\n",
                        "[826]\tvalid_0's multi_logloss: 1.28939\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[827]\tvalid_0's multi_logloss: 1.28933\n",
                        "[828]\tvalid_0's multi_logloss: 1.28927\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[829]\tvalid_0's multi_logloss: 1.28923\n",
                        "[830]\tvalid_0's multi_logloss: 1.28916\n",
                        "[831]\tvalid_0's multi_logloss: 1.28911\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[832]\tvalid_0's multi_logloss: 1.28905\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[833]\tvalid_0's multi_logloss: 1.289\n",
                        "[834]\tvalid_0's multi_logloss: 1.28893\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[835]\tvalid_0's multi_logloss: 1.28886\n",
                        "[836]\tvalid_0's multi_logloss: 1.28883\n",
                        "[837]\tvalid_0's multi_logloss: 1.28878\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[838]\tvalid_0's multi_logloss: 1.28873\n",
                        "[839]\tvalid_0's multi_logloss: 1.28867\n",
                        "[840]\tvalid_0's multi_logloss: 1.28863\n",
                        "[841]\tvalid_0's multi_logloss: 1.28858\n",
                        "[842]\tvalid_0's multi_logloss: 1.28853\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[843]\tvalid_0's multi_logloss: 1.28849\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[844]\tvalid_0's multi_logloss: 1.28843\n",
                        "[845]\tvalid_0's multi_logloss: 1.28836\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[846]\tvalid_0's multi_logloss: 1.28829\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[847]\tvalid_0's multi_logloss: 1.28822\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[848]\tvalid_0's multi_logloss: 1.2882\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[849]\tvalid_0's multi_logloss: 1.28815\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[850]\tvalid_0's multi_logloss: 1.28811\n",
                        "[851]\tvalid_0's multi_logloss: 1.28807\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[852]\tvalid_0's multi_logloss: 1.28802\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[853]\tvalid_0's multi_logloss: 1.28797\n",
                        "[854]\tvalid_0's multi_logloss: 1.28793\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[855]\tvalid_0's multi_logloss: 1.28788\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[856]\tvalid_0's multi_logloss: 1.28782\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[857]\tvalid_0's multi_logloss: 1.28774\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[858]\tvalid_0's multi_logloss: 1.28771\n",
                        "[859]\tvalid_0's multi_logloss: 1.28767\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[860]\tvalid_0's multi_logloss: 1.28762\n",
                        "[861]\tvalid_0's multi_logloss: 1.28757\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[862]\tvalid_0's multi_logloss: 1.28754\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[863]\tvalid_0's multi_logloss: 1.28751\n",
                        "[864]\tvalid_0's multi_logloss: 1.28748\n",
                        "[865]\tvalid_0's multi_logloss: 1.28741\n",
                        "[866]\tvalid_0's multi_logloss: 1.28734\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[867]\tvalid_0's multi_logloss: 1.2873\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[868]\tvalid_0's multi_logloss: 1.28726\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[869]\tvalid_0's multi_logloss: 1.28722\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[870]\tvalid_0's multi_logloss: 1.28718\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[871]\tvalid_0's multi_logloss: 1.28712\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[872]\tvalid_0's multi_logloss: 1.28707\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[873]\tvalid_0's multi_logloss: 1.28701\n",
                        "[874]\tvalid_0's multi_logloss: 1.28697\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[875]\tvalid_0's multi_logloss: 1.28694\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[876]\tvalid_0's multi_logloss: 1.28688\n",
                        "[877]\tvalid_0's multi_logloss: 1.28682\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[878]\tvalid_0's multi_logloss: 1.28678\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[879]\tvalid_0's multi_logloss: 1.28672\n",
                        "[880]\tvalid_0's multi_logloss: 1.28668\n",
                        "[881]\tvalid_0's multi_logloss: 1.28664\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[882]\tvalid_0's multi_logloss: 1.28657\n",
                        "[883]\tvalid_0's multi_logloss: 1.28653\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[884]\tvalid_0's multi_logloss: 1.28649\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[885]\tvalid_0's multi_logloss: 1.28645\n",
                        "[886]\tvalid_0's multi_logloss: 1.28641\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[887]\tvalid_0's multi_logloss: 1.28635\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[888]\tvalid_0's multi_logloss: 1.28632\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[889]\tvalid_0's multi_logloss: 1.28626\n",
                        "[890]\tvalid_0's multi_logloss: 1.28621\n",
                        "[891]\tvalid_0's multi_logloss: 1.28616\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[892]\tvalid_0's multi_logloss: 1.2861\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[893]\tvalid_0's multi_logloss: 1.28605\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[894]\tvalid_0's multi_logloss: 1.286\n",
                        "[895]\tvalid_0's multi_logloss: 1.28596\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[896]\tvalid_0's multi_logloss: 1.28591\n",
                        "[897]\tvalid_0's multi_logloss: 1.28587\n",
                        "[898]\tvalid_0's multi_logloss: 1.28581\n",
                        "[899]\tvalid_0's multi_logloss: 1.28576\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[900]\tvalid_0's multi_logloss: 1.28572\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[901]\tvalid_0's multi_logloss: 1.28568\n",
                        "[902]\tvalid_0's multi_logloss: 1.28562\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[903]\tvalid_0's multi_logloss: 1.28558\n",
                        "[904]\tvalid_0's multi_logloss: 1.28554\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[905]\tvalid_0's multi_logloss: 1.28549\n",
                        "[906]\tvalid_0's multi_logloss: 1.28545\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[907]\tvalid_0's multi_logloss: 1.28537\n",
                        "[908]\tvalid_0's multi_logloss: 1.28528\n",
                        "[909]\tvalid_0's multi_logloss: 1.28523\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[910]\tvalid_0's multi_logloss: 1.28518\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[911]\tvalid_0's multi_logloss: 1.28511\n",
                        "[912]\tvalid_0's multi_logloss: 1.28506\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[913]\tvalid_0's multi_logloss: 1.28504\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[914]\tvalid_0's multi_logloss: 1.28499\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[915]\tvalid_0's multi_logloss: 1.28496\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[916]\tvalid_0's multi_logloss: 1.28491\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[917]\tvalid_0's multi_logloss: 1.28487\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[918]\tvalid_0's multi_logloss: 1.28484\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[919]\tvalid_0's multi_logloss: 1.2848\n",
                        "[920]\tvalid_0's multi_logloss: 1.28475\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[921]\tvalid_0's multi_logloss: 1.2847\n",
                        "[922]\tvalid_0's multi_logloss: 1.28466\n",
                        "[923]\tvalid_0's multi_logloss: 1.2846\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[924]\tvalid_0's multi_logloss: 1.28455\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[925]\tvalid_0's multi_logloss: 1.28449\n",
                        "[926]\tvalid_0's multi_logloss: 1.28442\n",
                        "[927]\tvalid_0's multi_logloss: 1.28438\n",
                        "[928]\tvalid_0's multi_logloss: 1.28435\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[929]\tvalid_0's multi_logloss: 1.28432\n",
                        "[930]\tvalid_0's multi_logloss: 1.28426\n",
                        "[931]\tvalid_0's multi_logloss: 1.28417\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[932]\tvalid_0's multi_logloss: 1.28413\n",
                        "[933]\tvalid_0's multi_logloss: 1.28407\n",
                        "[934]\tvalid_0's multi_logloss: 1.28404\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[935]\tvalid_0's multi_logloss: 1.28399\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[936]\tvalid_0's multi_logloss: 1.28395\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[937]\tvalid_0's multi_logloss: 1.28389\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[938]\tvalid_0's multi_logloss: 1.28385\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[939]\tvalid_0's multi_logloss: 1.28383\n",
                        "[940]\tvalid_0's multi_logloss: 1.28379\n",
                        "[941]\tvalid_0's multi_logloss: 1.28374\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[942]\tvalid_0's multi_logloss: 1.28368\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[943]\tvalid_0's multi_logloss: 1.28364\n",
                        "[944]\tvalid_0's multi_logloss: 1.28359\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[945]\tvalid_0's multi_logloss: 1.28354\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[946]\tvalid_0's multi_logloss: 1.28349\n",
                        "[947]\tvalid_0's multi_logloss: 1.28344\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[948]\tvalid_0's multi_logloss: 1.28337\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[949]\tvalid_0's multi_logloss: 1.28333\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[950]\tvalid_0's multi_logloss: 1.28329\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[951]\tvalid_0's multi_logloss: 1.28323\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[952]\tvalid_0's multi_logloss: 1.28321\n",
                        "[953]\tvalid_0's multi_logloss: 1.28317\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[954]\tvalid_0's multi_logloss: 1.28313\n",
                        "[955]\tvalid_0's multi_logloss: 1.28309\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[956]\tvalid_0's multi_logloss: 1.28307\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[957]\tvalid_0's multi_logloss: 1.28304\n",
                        "[958]\tvalid_0's multi_logloss: 1.28297\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[959]\tvalid_0's multi_logloss: 1.28292\n",
                        "[960]\tvalid_0's multi_logloss: 1.28287\n",
                        "[961]\tvalid_0's multi_logloss: 1.28283\n",
                        "[962]\tvalid_0's multi_logloss: 1.28279\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[963]\tvalid_0's multi_logloss: 1.28276\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[964]\tvalid_0's multi_logloss: 1.28269\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[965]\tvalid_0's multi_logloss: 1.28265\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[966]\tvalid_0's multi_logloss: 1.28262\n",
                        "[967]\tvalid_0's multi_logloss: 1.28258\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[968]\tvalid_0's multi_logloss: 1.28256\n",
                        "[969]\tvalid_0's multi_logloss: 1.28252\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[970]\tvalid_0's multi_logloss: 1.28247\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[971]\tvalid_0's multi_logloss: 1.28241\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[972]\tvalid_0's multi_logloss: 1.28235\n",
                        "[973]\tvalid_0's multi_logloss: 1.28231\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[974]\tvalid_0's multi_logloss: 1.28227\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[975]\tvalid_0's multi_logloss: 1.2822\n",
                        "[976]\tvalid_0's multi_logloss: 1.28216\n",
                        "[977]\tvalid_0's multi_logloss: 1.28214\n",
                        "[978]\tvalid_0's multi_logloss: 1.2821\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[979]\tvalid_0's multi_logloss: 1.28205\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[980]\tvalid_0's multi_logloss: 1.28203\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[981]\tvalid_0's multi_logloss: 1.28201\n",
                        "[982]\tvalid_0's multi_logloss: 1.28196\n",
                        "[983]\tvalid_0's multi_logloss: 1.28189\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[984]\tvalid_0's multi_logloss: 1.28183\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[985]\tvalid_0's multi_logloss: 1.2818\n",
                        "[986]\tvalid_0's multi_logloss: 1.28176\n",
                        "[987]\tvalid_0's multi_logloss: 1.28171\n",
                        "[988]\tvalid_0's multi_logloss: 1.28168\n",
                        "[989]\tvalid_0's multi_logloss: 1.28165\n",
                        "[990]\tvalid_0's multi_logloss: 1.28161\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[991]\tvalid_0's multi_logloss: 1.28158\n",
                        "[992]\tvalid_0's multi_logloss: 1.28155\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[993]\tvalid_0's multi_logloss: 1.2815\n",
                        "[994]\tvalid_0's multi_logloss: 1.28146\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[995]\tvalid_0's multi_logloss: 1.28143\n",
                        "[996]\tvalid_0's multi_logloss: 1.28139\n",
                        "[997]\tvalid_0's multi_logloss: 1.28134\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[998]\tvalid_0's multi_logloss: 1.2813\n",
                        "[999]\tvalid_0's multi_logloss: 1.28126\n",
                        "[1000]\tvalid_0's multi_logloss: 1.28121\n",
                        "[1001]\tvalid_0's multi_logloss: 1.28119\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1002]\tvalid_0's multi_logloss: 1.28114\n",
                        "[1003]\tvalid_0's multi_logloss: 1.28111\n",
                        "[1004]\tvalid_0's multi_logloss: 1.28108\n",
                        "[1005]\tvalid_0's multi_logloss: 1.28105\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1006]\tvalid_0's multi_logloss: 1.28103\n",
                        "[1007]\tvalid_0's multi_logloss: 1.28099\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1008]\tvalid_0's multi_logloss: 1.28094\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1009]\tvalid_0's multi_logloss: 1.28088\n",
                        "[1010]\tvalid_0's multi_logloss: 1.28085\n",
                        "[1011]\tvalid_0's multi_logloss: 1.28081\n",
                        "[1012]\tvalid_0's multi_logloss: 1.28076\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1013]\tvalid_0's multi_logloss: 1.28074\n",
                        "[1014]\tvalid_0's multi_logloss: 1.28073\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1015]\tvalid_0's multi_logloss: 1.28067\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1016]\tvalid_0's multi_logloss: 1.28063\n",
                        "[1017]\tvalid_0's multi_logloss: 1.28057\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1018]\tvalid_0's multi_logloss: 1.28054\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1019]\tvalid_0's multi_logloss: 1.28049\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1020]\tvalid_0's multi_logloss: 1.28045\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1021]\tvalid_0's multi_logloss: 1.2804\n",
                        "[1022]\tvalid_0's multi_logloss: 1.28035\n",
                        "[1023]\tvalid_0's multi_logloss: 1.28031\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1024]\tvalid_0's multi_logloss: 1.28025\n",
                        "[1025]\tvalid_0's multi_logloss: 1.28022\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1026]\tvalid_0's multi_logloss: 1.28018\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1027]\tvalid_0's multi_logloss: 1.28015\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1028]\tvalid_0's multi_logloss: 1.28011\n",
                        "[1029]\tvalid_0's multi_logloss: 1.28006\n",
                        "[1030]\tvalid_0's multi_logloss: 1.28003\n",
                        "[1031]\tvalid_0's multi_logloss: 1.28\n",
                        "[1032]\tvalid_0's multi_logloss: 1.27994\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1033]\tvalid_0's multi_logloss: 1.27987\n",
                        "[1034]\tvalid_0's multi_logloss: 1.27985\n",
                        "[1035]\tvalid_0's multi_logloss: 1.2798\n",
                        "[1036]\tvalid_0's multi_logloss: 1.27976\n",
                        "[1037]\tvalid_0's multi_logloss: 1.27971\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1038]\tvalid_0's multi_logloss: 1.27967\n",
                        "[1039]\tvalid_0's multi_logloss: 1.27963\n",
                        "[1040]\tvalid_0's multi_logloss: 1.27958\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1041]\tvalid_0's multi_logloss: 1.27955\n",
                        "[1042]\tvalid_0's multi_logloss: 1.2795\n",
                        "[1043]\tvalid_0's multi_logloss: 1.27945\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1044]\tvalid_0's multi_logloss: 1.27941\n",
                        "[1045]\tvalid_0's multi_logloss: 1.27936\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1046]\tvalid_0's multi_logloss: 1.27934\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1047]\tvalid_0's multi_logloss: 1.27927\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1048]\tvalid_0's multi_logloss: 1.27919\n",
                        "[1049]\tvalid_0's multi_logloss: 1.27917\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1050]\tvalid_0's multi_logloss: 1.27912\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1051]\tvalid_0's multi_logloss: 1.27908\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1052]\tvalid_0's multi_logloss: 1.27903\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1053]\tvalid_0's multi_logloss: 1.27899\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1054]\tvalid_0's multi_logloss: 1.27894\n",
                        "[1055]\tvalid_0's multi_logloss: 1.27892\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1056]\tvalid_0's multi_logloss: 1.27888\n",
                        "[1057]\tvalid_0's multi_logloss: 1.27884\n",
                        "[1058]\tvalid_0's multi_logloss: 1.2788\n",
                        "[1059]\tvalid_0's multi_logloss: 1.27877\n",
                        "[1060]\tvalid_0's multi_logloss: 1.27874\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1061]\tvalid_0's multi_logloss: 1.27869\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1062]\tvalid_0's multi_logloss: 1.27865\n",
                        "[1063]\tvalid_0's multi_logloss: 1.27863\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1064]\tvalid_0's multi_logloss: 1.27859\n",
                        "[1065]\tvalid_0's multi_logloss: 1.27852\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1066]\tvalid_0's multi_logloss: 1.27849\n",
                        "[1067]\tvalid_0's multi_logloss: 1.27846\n",
                        "[1068]\tvalid_0's multi_logloss: 1.2784\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1069]\tvalid_0's multi_logloss: 1.27838\n",
                        "[1070]\tvalid_0's multi_logloss: 1.27834\n",
                        "[1071]\tvalid_0's multi_logloss: 1.2783\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1072]\tvalid_0's multi_logloss: 1.27828\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1073]\tvalid_0's multi_logloss: 1.27823\n",
                        "[1074]\tvalid_0's multi_logloss: 1.27819\n",
                        "[1075]\tvalid_0's multi_logloss: 1.27816\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1076]\tvalid_0's multi_logloss: 1.27812\n",
                        "[1077]\tvalid_0's multi_logloss: 1.27809\n",
                        "[1078]\tvalid_0's multi_logloss: 1.27805\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1079]\tvalid_0's multi_logloss: 1.27802\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1080]\tvalid_0's multi_logloss: 1.27798\n",
                        "[1081]\tvalid_0's multi_logloss: 1.27793\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1082]\tvalid_0's multi_logloss: 1.27789\n",
                        "[1083]\tvalid_0's multi_logloss: 1.27785\n",
                        "[1084]\tvalid_0's multi_logloss: 1.2778\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1085]\tvalid_0's multi_logloss: 1.27777\n",
                        "[1086]\tvalid_0's multi_logloss: 1.27773\n",
                        "[1087]\tvalid_0's multi_logloss: 1.2777\n",
                        "[1088]\tvalid_0's multi_logloss: 1.27767\n",
                        "[1089]\tvalid_0's multi_logloss: 1.27764\n",
                        "[1090]\tvalid_0's multi_logloss: 1.27761\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1091]\tvalid_0's multi_logloss: 1.27758\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1092]\tvalid_0's multi_logloss: 1.27753\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1093]\tvalid_0's multi_logloss: 1.2775\n",
                        "[1094]\tvalid_0's multi_logloss: 1.27746\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1095]\tvalid_0's multi_logloss: 1.27741\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1096]\tvalid_0's multi_logloss: 1.27739\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1097]\tvalid_0's multi_logloss: 1.27736\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1098]\tvalid_0's multi_logloss: 1.27732\n",
                        "[1099]\tvalid_0's multi_logloss: 1.27729\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
                        "[1100]\tvalid_0's multi_logloss: 1.27727\n"
                    ]
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[16], line 57\u001b[0m\n\u001b[0;32m     53\u001b[0m y_train_fold, y_val_fold \u001b[38;5;241m=\u001b[39m y_train\u001b[38;5;241m.\u001b[39miloc[train_idx], y_train\u001b[38;5;241m.\u001b[39miloc[val_idx]\n\u001b[0;32m     55\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m [lgb\u001b[38;5;241m.\u001b[39mlog_evaluation(period\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), lgb\u001b[38;5;241m.\u001b[39mearly_stopping(stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)]\n\u001b[1;32m---> 57\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_fold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train_fold)\n\u001b[0;32m     61\u001b[0m y_val_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val_fold)\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\lightgbm\\sklearn.py:1284\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1281\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1282\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[1;32m-> 1284\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m   1285\u001b[0m     X,\n\u001b[0;32m   1286\u001b[0m     _y,\n\u001b[0;32m   1287\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[0;32m   1288\u001b[0m     init_score\u001b[38;5;241m=\u001b[39minit_score,\n\u001b[0;32m   1289\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[0;32m   1290\u001b[0m     eval_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[0;32m   1291\u001b[0m     eval_sample_weight\u001b[38;5;241m=\u001b[39meval_sample_weight,\n\u001b[0;32m   1292\u001b[0m     eval_class_weight\u001b[38;5;241m=\u001b[39meval_class_weight,\n\u001b[0;32m   1293\u001b[0m     eval_init_score\u001b[38;5;241m=\u001b[39meval_init_score,\n\u001b[0;32m   1294\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39meval_metric,\n\u001b[0;32m   1295\u001b[0m     feature_name\u001b[38;5;241m=\u001b[39mfeature_name,\n\u001b[0;32m   1296\u001b[0m     categorical_feature\u001b[38;5;241m=\u001b[39mcategorical_feature,\n\u001b[0;32m   1297\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m   1298\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[0;32m   1299\u001b[0m )\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\lightgbm\\sklearn.py:955\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    952\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    953\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\lightgbm\\engine.py:307\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    296\u001b[0m     cb(\n\u001b[0;32m    297\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[0;32m    298\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m         )\n\u001b[0;32m    305\u001b[0m     )\n\u001b[1;32m--> 307\u001b[0m booster\u001b[38;5;241m.\u001b[39mupdate(fobj\u001b[38;5;241m=\u001b[39mfobj)\n\u001b[0;32m    309\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\lightgbm\\basic.py:4136\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   4134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4135\u001b[0m _safe_call(\n\u001b[1;32m-> 4136\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4137\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4140\u001b[0m )\n\u001b[0;32m   4141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
                        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "import re\n",
                "\n",
                "def clean_feature_names(X):\n",
                "    # 函数用于清理特征名称\n",
                "    def clean_name(name):\n",
                "        # 移除或替换特殊字符\n",
                "        name = re.sub(r'[^\\w\\s-]', '_', name)\n",
                "        # 确保名称不以数字开头\n",
                "        if name[0].isdigit():\n",
                "            name = 'f_' + name\n",
                "        return name\n",
                "\n",
                "    X.columns = [clean_name(col) for col in X.columns]\n",
                "    return X\n",
                "\n",
                "# 清理特征名称\n",
                "X_train = clean_feature_names(X_train)\n",
                "\n",
                "\n",
                "from lightgbm import LGBMClassifier\n",
                "import lightgbm as lgb\n",
                "model = LGBMClassifier(\n",
                "    n_estimators=2000,\n",
                "    learning_rate=0.03,\n",
                "    max_depth=6,\n",
                "    num_leaves=29,\n",
                "    min_child_samples=20,\n",
                "    subsample=0.7,\n",
                "    colsample_bytree=0.7,\n",
                "    reg_alpha=0.1,\n",
                "    reg_lambda=0.1,\n",
                "    random_state=42,\n",
                "    n_jobs=-1,\n",
                "    class_weight='balanced',\n",
                "    device='gpu',\n",
                "    gpu_platform_id=1,\n",
                "    gpu_device_id=0,\n",
                ")\n",
                "display(model)\n",
                "\n",
                "from sklearn.model_selection import GroupKFold\n",
                "from sklearn.metrics import balanced_accuracy_score\n",
                "import numpy as np\n",
                "\n",
                "\n",
                "\n",
                "cv = GroupKFold(n_splits=4)\n",
                "train_scores = []\n",
                "val_scores = []\n",
                "\n",
                "for train_idx, val_idx in cv.split(X_train, y_train, groups=group_train):\n",
                "    X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
                "    y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
                "    \n",
                "    callbacks = [lgb.log_evaluation(period=1), lgb.early_stopping(stopping_rounds=10)]\n",
                "    \n",
                "    model.fit(X_train_fold, y_train_fold, callbacks=callbacks, eval_set=[(X_val_fold, y_val_fold)])\n",
                "\n",
                "    \n",
                "    y_train_pred = model.predict(X_train_fold)\n",
                "    y_val_pred = model.predict(X_val_fold)\n",
                "    \n",
                "    train_score = balanced_accuracy_score(y_train_fold, y_train_pred)\n",
                "    val_score = balanced_accuracy_score(y_val_fold, y_val_pred)\n",
                "    \n",
                "    train_scores.append(train_score)\n",
                "    val_scores.append(val_score)\n",
                "    \n",
                "    print(f\"Fold train balanced accuracy: {train_score:.4f}\")\n",
                "    print(f\"Fold validation balanced accuracy: {val_score:.4f}\")\n",
                "    print(\"---\")\n",
                "\n",
                "print(f\"Average train balanced accuracy: {np.mean(train_scores):.4f} ± {np.std(train_scores):.4f}\")\n",
                "print(f\"Average validation balanced accuracy: {np.mean(val_scores):.4f} ± {np.std(val_scores):.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Uncomment what you need!\n",
                "def train(\n",
                "    X_train: typing.Dict[str, pd.DataFrame],\n",
                "    y_train: typing.Dict[str, pd.DataFrame],\n",
                "    # number_of_features: int,\n",
                "    model_directory_path: str,\n",
                "    # id_column_name: str,\n",
                "    # prediction_column_name: str,\n",
                "    # has_gpu: bool,\n",
                ") -> None:\n",
                "    # 1) Create the variable embedding:\n",
                "    return\n",
                "    X_y_group_train_pathname = \"/tmp/X_y_group_train.parquet\"\n",
                "    try:\n",
                "        print(f\"Loading {X_y_group_train_pathname}\")\n",
                "        X_y_group_train = pd.read_parquet(X_y_group_train_pathname)\n",
                "    except FileNotFoundError:\n",
                "        print(\"Creating X_y_group_train\")\n",
                "        names_datasets_train = X_train\n",
                "        names_graphs_train = y_train\n",
                "        X_y_group_train = create_all_columns(\n",
                "            {\n",
                "                pearson_correlation: names_datasets_train,\n",
                "                ttest: names_datasets_train,\n",
                "                mutual_information: names_datasets_train,  # comment this line to greatly reduce computation\n",
                "                label: names_graphs_train,\n",
                "                spearman_correlation: names_datasets_train,\n",
                "                kendall_correlation: names_datasets_train,\n",
                "                distance_correlation: names_datasets_train,\n",
                "                conditional_mutual_information: names_datasets_train,\n",
                "            },\n",
                "            n_jobs=-1,\n",
                "        )\n",
                "        X_y_group_train = remove_outliers(X_y_group_train, ['corr(v,X)', 'corr(v,Y)', 'ttest(v,X)', 'ttest(v,Y)'])\n",
                "        # 2) Massage X_y_group_train to prepare what is needed by the model:\n",
                "        print(\"Adding numeric labels y\") # sklearn wants numeric labels\n",
                "        le = LabelEncoder()\n",
                "        le.classes_ = np.array([\n",
                "            'Cause of X', 'Consequence of X', 'Confounder', 'Collider',\n",
                "            'Mediator', 'Independent', 'Cause of Y', 'Consequence of Y',\n",
                "        ])\n",
                "        X_y_group_train[\"y\"] = le.transform(X_y_group_train[\"label\"])\n",
                "\n",
                "        # reordering columns:\n",
                "        X_y_group_train = X_y_group_train[[\"dataset\", \"variable\"] + X_y_group_train.columns.drop([\"dataset\", \"variable\", \"label\", \"y\"]).tolist() + [\"label\", \"y\"]]\n",
                "        display(X_y_group_train)\n",
                "\n",
                "        print(\"Saving X_y_group_train\")\n",
                "        os.makedirs(os.path.dirname(X_y_group_train_pathname), exist_ok=True)\n",
                "        X_y_group_train.to_parquet(X_y_group_train_pathname)\n",
                "\n",
                "    print(\"Extracting X_train, y_train, and group\")\n",
                "    X_train = X_y_group_train.drop([\"variable\", \"dataset\", \"label\", \"y\"], axis=\"columns\")\n",
                "    y_train = X_y_group_train[\"y\"]\n",
                "    group_train = X_y_group_train[\"dataset\"]\n",
                "\n",
                "    # Model:\n",
                "    model = RandomForestClassifier(n_estimators=100, max_depth=11, n_jobs=-1, class_weight=\"balanced\")\n",
                "    model.fit(X_train, y_train)\n",
                "\n",
                "    joblib.dump(\n",
                "        model,\n",
                "        os.path.join(model_directory_path, \"model.joblib\")\n",
                "    )\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [],
            "source": [
                "def create_submission(X_y_pred_test):\n",
                "    \"\"\"\n",
                "    From the predicted test set, for each dataset, take predicted\n",
                "    classes of all variables, create the adjacency matrix, then create\n",
                "    the submission in the requested format.\n",
                "    \"\"\"\n",
                "\n",
                "    submission = {}\n",
                "    for name, prediction in tqdm(X_y_pred_test.groupby(\"dataset\"), delay=10):\n",
                "        variables_labels = prediction[[\"variable\", \"label_predicted\"]].set_index(\"variable\")\n",
                "        variables = variables_labels.index.tolist()\n",
                "        variables_all = [\"X\", \"Y\"] + variables\n",
                "\n",
                "        adjacency_matrix = pd.DataFrame(index=variables_all, columns=variables_all)\n",
                "        adjacency_matrix.index.name = \"parent\"\n",
                "        adjacency_matrix[:] = 0\n",
                "        adjacency_matrix.loc[\"X\", \"Y\"] = 1\n",
                "\n",
                "        for v in variables:\n",
                "            l = variables_labels.loc[v].item()\n",
                "            if l == \"Cause of X\":\n",
                "                adjacency_matrix.loc[v, \"X\"] = 1\n",
                "            elif l == \"Cause of Y\":\n",
                "                adjacency_matrix.loc[v, \"Y\"] = 1\n",
                "            elif l == \"Consequence of X\":\n",
                "                adjacency_matrix.loc[\"X\", v] = 1\n",
                "            elif l == \"Consequence of Y\":\n",
                "                adjacency_matrix.loc[\"Y\", v] = 1\n",
                "            elif l == \"Confounder\":\n",
                "                adjacency_matrix.loc[v, \"X\"] = 1\n",
                "                adjacency_matrix.loc[v, \"Y\"] = 1\n",
                "            elif l == \"Collider\":\n",
                "                adjacency_matrix.loc[\"X\", v] = 1\n",
                "                adjacency_matrix.loc[\"Y\", v] = 1\n",
                "            elif l == \"Mediator\":\n",
                "                adjacency_matrix.loc[\"X\", v] = 1\n",
                "                adjacency_matrix.loc[v, \"Y\"] = 1\n",
                "            elif l == \"Confounder\":\n",
                "                pass\n",
                "\n",
                "        for i in variables_all:\n",
                "            for j in variables_all:\n",
                "                submission[f'{name}_{i}_{j}'] = int(adjacency_matrix.loc[i, j])\n",
                "\n",
                "    return submission\n",
                "\n",
                "\n",
                "# Uncomment what you need!\n",
                "def infer(\n",
                "    X_test: typing.Dict[str, pd.DataFrame],\n",
                "    # number_of_features: int,\n",
                "    model_directory_path: str,\n",
                "    id_column_name: str,\n",
                "    prediction_column_name: str,\n",
                "    # has_gpu: bool,\n",
                "    # has_trained: bool,\n",
                ") -> pd.DataFrame:\n",
                "    model = joblib.load(os.path.join(model_directory_path, \"random_forest_model_v0.joblib\"))\n",
                "\n",
                "    names_datasets_test = X_test\n",
                "    X_group_test = create_all_columns(\n",
                "        {\n",
                "                pearson_correlation: names_datasets_train,\n",
                "                ttest: names_datasets_train,\n",
                "                mutual_information: names_datasets_train,  # comment this line to greatly reduce computation\n",
                "                label: names_graphs_train,\n",
                "                spearman_correlation: names_datasets_train,\n",
                "                kendall_correlation: names_datasets_train,\n",
                "                distance_correlation: names_datasets_train,\n",
                "                conditional_mutual_information: names_datasets_train,\n",
                "        },\n",
                "        n_jobs=-1,\n",
                "    )\n",
                "\n",
                "    X_test = X_group_test.drop(columns=[\"dataset\", \"variable\"])\n",
                "    y_predicted = model.predict(X_test)\n",
                "    X_y_pred_test = X_group_test\n",
                "    X_y_pred_test[\"y_predicted\"] = y_predicted\n",
                "\n",
                "    le = LabelEncoder()\n",
                "    le.classes_ = np.array([\n",
                "        'Cause of X', 'Consequence of X', 'Confounder', 'Collider',\n",
                "        'Mediator', 'Independent', 'Cause of Y', 'Consequence of Y',\n",
                "    ])\n",
                "\n",
                "    X_y_pred_test[\"label_predicted\"] = le.inverse_transform(y_predicted)\n",
                "\n",
                "    submission = create_submission(X_y_pred_test)\n",
                "\n",
                "    return pd.DataFrame(\n",
                "        submission.items(),\n",
                "        columns=[\n",
                "            id_column_name,\n",
                "            prediction_column_name\n",
                "        ]\n",
                "    )"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32m12:53:24\u001b[0m \u001b[33mno forbidden library found\u001b[0m\n",
                        "\u001b[32m12:53:24\u001b[0m \u001b[33m\u001b[0m\n",
                        "\u001b[32m12:53:24\u001b[0m started\n",
                        "\u001b[32m12:53:24\u001b[0m running local test\n",
                        "\u001b[32m12:53:24\u001b[0m \u001b[33minternet access isn't restricted, no check will be done\u001b[0m\n",
                        "\u001b[32m12:53:24\u001b[0m \n",
                        "\u001b[32m12:53:31\u001b[0m starting dag process...\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "download data\\X_train.pickle from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/48/X_train.pickle (1523944532 bytes)\n",
                        "already exists: file length match\n",
                        "download data\\y_train.pickle from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/48/y_train.pickle (7017735 bytes)\n",
                        "already exists: file length match\n",
                        "download data\\X_test.pickle from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/48/X_test_reduced.pickle (122341879 bytes)\n",
                        "already exists: file length match\n",
                        "download data\\y_test.pickle from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/48/y_test_reduced.pickle (562930 bytes)\n",
                        "already exists: file length match\n",
                        "download data\\example_prediction.parquet from https:crunchdao--competition--production.s3.eu-west-1.amazonaws.com/data-releases/48/example_prediction_reduced.parquet (668981 bytes)\n",
                        "already exists: file length match\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\u001b[32m12:53:42\u001b[0m \u001b[33mcall: train\u001b[0m\n",
                        "\u001b[32m12:53:42\u001b[0m \u001b[33mcall: infer\u001b[0m\n",
                        "\u001b[32m12:53:43\u001b[0m \u001b[33mduration - time=00:00:19\u001b[0m\n",
                        "\u001b[32m12:53:43\u001b[0m \u001b[33mmemory - before=\"2.54 GB\" after=\"3.52 GB\" consumed=\"1,001.20 MB\"\u001b[0m\n"
                    ]
                },
                {
                    "ename": "NameError",
                    "evalue": "name 'names_datasets_train' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcrunch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_determinism_check\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m      3\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload this notebook and submit it to the platform: https://hub.crunchdao.com/competitions/causality-discovery/submit/via/notebook\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\crunch\\inline.py:69\u001b[0m, in \u001b[0;36m_Inline.test\u001b[1;34m(self, force_first_train, train_frequency, raise_abort, round_number, no_checks, no_determinism_check, read_kwargs, write_kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     library\u001b[38;5;241m.\u001b[39mscan(module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule)\n\u001b[0;32m     67\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtester\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_first_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_frequency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mround_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompetition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mno_checks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mno_determinism_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mread_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrite_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m click\u001b[38;5;241m.\u001b[39mAbort \u001b[38;5;28;01mas\u001b[39;00m abort:\n\u001b[0;32m     83\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAborted!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\crunch\\tester.py:52\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(module, model_directory_path, force_first_train, train_frequency, round_number, competition_format, has_gpu, checks, determinism_check_enabled, read_kwargs, write_kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlocal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LocalRunner\n\u001b[0;32m     38\u001b[0m runner \u001b[38;5;241m=\u001b[39m LocalRunner(\n\u001b[0;32m     39\u001b[0m     module,\n\u001b[0;32m     40\u001b[0m     model_directory_path,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m     write_kwargs,\n\u001b[0;32m     50\u001b[0m )\n\u001b[1;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\crunch\\runner\\local.py:47\u001b[0m, in \u001b[0;36mLocalRunner.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     44\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mduration - time=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     51\u001b[0m         time\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mgmtime(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start))\n\u001b[0;32m     52\u001b[0m     )\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\crunch\\runner\\runner.py:37\u001b[0m, in \u001b[0;36mRunner.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompetition_format \u001b[38;5;241m==\u001b[39m api\u001b[38;5;241m.\u001b[39mCompetitionFormat\u001b[38;5;241m.\u001b[39mDAG:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstarting dag process...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_dag\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munsupported: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompetition_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\crunch\\runner\\runner.py:90\u001b[0m, in \u001b[0;36mRunner.start_dag\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_dag\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 90\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdag_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeterministic:\n\u001b[0;32m     93\u001b[0m         prediction2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdag_loop(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\crunch\\runner\\local.py:206\u001b[0m, in \u001b[0;36mLocalRunner.dag_loop\u001b[1;34m(self, train)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    205\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcall: infer\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 206\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    211\u001b[0m     ensure\u001b[38;5;241m.\u001b[39mreturn_infer(\n\u001b[0;32m    212\u001b[0m         prediction,\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumn_names\u001b[38;5;241m.\u001b[39mid,\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumn_names\u001b[38;5;241m.\u001b[39moutputs,\n\u001b[0;32m    216\u001b[0m     )\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction\n",
                        "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\crunch\\utils.py:231\u001b[0m, in \u001b[0;36msmart_call\u001b[1;34m(function, default_values, specific_values, log)\u001b[0m\n\u001b[0;32m    228\u001b[0m     debug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    229\u001b[0m     arguments[name] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m--> 231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39marguments)\n",
                        "Cell \u001b[1;32mIn[20], line 63\u001b[0m, in \u001b[0;36minfer\u001b[1;34m(X_test, model_directory_path, id_column_name, prediction_column_name)\u001b[0m\n\u001b[0;32m     58\u001b[0m model \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_directory_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_forest_model_v0.joblib\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m     60\u001b[0m names_datasets_test \u001b[38;5;241m=\u001b[39m X_test\n\u001b[0;32m     61\u001b[0m X_group_test \u001b[38;5;241m=\u001b[39m create_all_columns(\n\u001b[0;32m     62\u001b[0m     {\n\u001b[1;32m---> 63\u001b[0m             pearson_correlation: \u001b[43mnames_datasets_train\u001b[49m,\n\u001b[0;32m     64\u001b[0m             ttest: names_datasets_train,\n\u001b[0;32m     65\u001b[0m             mutual_information: names_datasets_train,  \u001b[38;5;66;03m# comment this line to greatly reduce computation\u001b[39;00m\n\u001b[0;32m     66\u001b[0m             label: names_graphs_train,\n\u001b[0;32m     67\u001b[0m             spearman_correlation: names_datasets_train,\n\u001b[0;32m     68\u001b[0m             kendall_correlation: names_datasets_train,\n\u001b[0;32m     69\u001b[0m             distance_correlation: names_datasets_train,\n\u001b[0;32m     70\u001b[0m             conditional_mutual_information: names_datasets_train,\n\u001b[0;32m     71\u001b[0m     },\n\u001b[0;32m     72\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     73\u001b[0m )\n\u001b[0;32m     75\u001b[0m X_test \u001b[38;5;241m=\u001b[39m X_group_test\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvariable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     76\u001b[0m y_predicted \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
                        "\u001b[1;31mNameError\u001b[0m: name 'names_datasets_train' is not defined"
                    ]
                }
            ],
            "source": [
                "crunch.test(\n",
                "    no_determinism_check=True\n",
                ")\n",
                "\n",
                "print(\"Download this notebook and submit it to the platform: https://hub.crunchdao.com/competitions/causality-discovery/submit/via/notebook\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "casual",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
