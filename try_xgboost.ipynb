{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns_with_keywords(df, keywords):\n",
    "    columns_to_drop = [col for col in df.columns if any(keyword in col for keyword in keywords)]\n",
    "    return df.drop(columns=columns_to_drop)\n",
    "\n",
    "def get_columns_with_keywords(df, keywords):\n",
    "    columns_to_get = [col for col in df.columns if any(keyword in col for keyword in keywords)]\n",
    "    return columns_to_get\n",
    "\n",
    "def recovery_dataset_id(X_y_group_train):\n",
    "    # 假设'dataset'列是需要转换的列\n",
    "    X_y_group_train['dataset'] = X_y_group_train['dataset'].apply(lambda x: f'{int(x):05}')\n",
    "    return X_y_group_train\n",
    "\n",
    "def clean_feature_names(X):\n",
    "    # 函数用于清理特征名称\n",
    "    def clean_name(name):\n",
    "        # 移除或替换特殊字符\n",
    "        name = re.sub(r'[^\\w\\s-]', '_', name)\n",
    "        # 确保名称不以数字开头\n",
    "        if name and name[0].isdigit():\n",
    "            name = 'f_' + name\n",
    "        return name\n",
    "\n",
    "    X.columns = [clean_name(col) for col in X.columns]\n",
    "    return X\n",
    "\n",
    "def process_categorical_features(df, max_unique=10):\n",
    "    \"\"\"\n",
    "    检测和处理数据框中的类别变量。\n",
    "\n",
    "    参数：\n",
    "    - df (pd.DataFrame): 输入的数据框。\n",
    "    - max_unique (int): 判定为类别变量的最大唯一值数量。\n",
    "\n",
    "    返回：\n",
    "    - cat_idxs (list of int): 类别特征的索引。\n",
    "    - cat_dims (list of int): 每个类别特征的模态数。\n",
    "    - df (pd.DataFrame): 经过编码后的数据框。\n",
    "    \"\"\"\n",
    "    cat_cols = [col for col in df.columns if df[col].nunique() <= max_unique]\n",
    "    cat_dims = []\n",
    "    cat_idxs = []\n",
    "\n",
    "    for col in cat_cols:\n",
    "        print(f\"     处理类别特征: {col}，唯一值数量: {df[col].nunique()}\")\n",
    "        # 使用 LabelEncoder\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str).fillna('NaN'))\n",
    "        cat_dims.append(len(le.classes_))\n",
    "        cat_idxs.append(df.columns.get_loc(col))\n",
    "\n",
    "    return cat_idxs, cat_dims, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Adding numeric labels y\n",
      "##### Data Preprocessing...\n",
      "     删除多余列后样本量 (142910, 207)\n",
      "##### Extracting X_train, y_train, and group\n",
      "     处理类别特征: dimension，唯一值数量: 8\n",
      "     处理类别特征: ExactSearch_v_X_，唯一值数量: 2\n",
      "     处理类别特征: ExactSearch_X_v_，唯一值数量: 2\n",
      "     处理类别特征: ExactSearch_v_Y_，唯一值数量: 2\n",
      "     处理类别特征: ExactSearch_Y_v_，唯一值数量: 2\n",
      "     处理类别特征: ExactSearch_X_Y_，唯一值数量: 2\n",
      "     处理类别特征: PC_v_X_，唯一值数量: 2\n",
      "     处理类别特征: PC_X_v_，唯一值数量: 2\n",
      "     处理类别特征: PC_v_Y_，唯一值数量: 2\n",
      "     处理类别特征: PC_Y_v_，唯一值数量: 2\n",
      "     处理类别特征: PC_X_Y_，唯一值数量: 2\n",
      "     处理类别特征: FCI_v_X_，唯一值数量: 4\n",
      "     处理类别特征: FCI_X_v_，唯一值数量: 4\n",
      "     处理类别特征: FCI_v_Y_，唯一值数量: 4\n",
      "     处理类别特征: FCI_Y_v_，唯一值数量: 4\n",
      "     处理类别特征: FCI_X_Y_，唯一值数量: 4\n",
      "     处理类别特征: GRaSP_v_X_，唯一值数量: 3\n",
      "     处理类别特征: GRaSP_X_v_，唯一值数量: 3\n",
      "     处理类别特征: GRaSP_v_Y_，唯一值数量: 3\n",
      "     处理类别特征: GRaSP_Y_v_，唯一值数量: 3\n",
      "     处理类别特征: GRaSP_X_Y_，唯一值数量: 3\n",
      "     类别特征索引 (cat_idxs): [0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 137, 138, 139, 140, 141]\n",
      "     类别特征模态数 (cat_dims): [8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3]\n",
      "     分割数据集后X_train & X_test shape: (114328, 203) (28582, 203)\n",
      "     y_train 唯一值: [0 1 2 3 4 5 6 7]\n",
      "     y_test 唯一值: [0 1 2 3 4 5 6 7]\n",
      "类别权重: [1.450715663384428, 0.6722329366386002, 3.281515499425947, 1.975532209012994, 0.9026654876200101, 2.093305990918412, 0.32411040301181593, 2.930285011277425]\n"
     ]
    }
   ],
   "source": [
    "X_y_group_train = pd.read_csv('mid_data/X_y_group_train_updated_v13.4_rolling.csv')\n",
    "\n",
    "print(\"##### Adding numeric labels y\")\n",
    "# 添加数值标签 y\n",
    "le = LabelEncoder()\n",
    "X_y_group_train[\"y\"] = le.fit_transform(X_y_group_train[\"label\"])\n",
    "# 重新排列列\n",
    "X_y_group_train = X_y_group_train[[\"dataset\", \"variable\"] + X_y_group_train.columns.drop([\"dataset\", \"variable\", \"label\", \"y\"]).tolist() + [\"label\", \"y\"]]\n",
    "\n",
    "print(\"##### Data Preprocessing...\")\n",
    "# 定义要删除的列\n",
    "blacklist = [\n",
    "    \"ttest(v,X)\", \n",
    "    \"pvalue(ttest(v,X))<=0.05\", \n",
    "    \"ttest(v,Y)\", \n",
    "    \"pvalue(ttest(v,Y))<=0.05\", \n",
    "    \"ttest(X,Y)\", \n",
    "    \"pvalue(ttest(X,Y))<=0.05\",\n",
    "    \"square_dimension\", \n",
    "    \"max(PPS(v,others))\",\n",
    "    \"TLI_Collider\",\n",
    "    \"TLI_Confounder\",\n",
    "    \"RMSEA_Collider\",\n",
    "    \"RMSEA_Confounder\",\n",
    "    # \"RMSEA_Cause of Y\",\n",
    "]\n",
    "columns_to_drop = [col for col in blacklist if col in X_y_group_train.columns]\n",
    "X_y_group_train = X_y_group_train.drop(columns=columns_to_drop)\n",
    "print('     删除多余列后样本量', X_y_group_train.shape)\n",
    "\n",
    "# 处理无穷值：转换为NaN\n",
    "X_y_group_train = X_y_group_train.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 处理数值列的缺失值\n",
    "numeric_columns = X_y_group_train.select_dtypes(include=[np.number]).columns\n",
    "X_y_group_train[numeric_columns] = X_y_group_train[numeric_columns].fillna(X_y_group_train[numeric_columns].mean())\n",
    "\n",
    "# 清理特征名称\n",
    "X_y_group_train = clean_feature_names(X_y_group_train)\n",
    "\n",
    "print(\"##### Extracting X_train, y_train, and group\")\n",
    "# 分离数据集ID、特征和标签\n",
    "group_train = X_y_group_train[\"dataset\"]\n",
    "X = X_y_group_train.drop([\"variable\", \"dataset\", \"label\", \"y\"], axis=\"columns\")\n",
    "y = X_y_group_train[\"y\"]\n",
    "\n",
    "# 处理类别特征\n",
    "cat_idxs, cat_dims, X = process_categorical_features(X)\n",
    "print(f\"     类别特征索引 (cat_idxs): {cat_idxs}\")\n",
    "print(f\"     类别特征模态数 (cat_dims): {cat_dims}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"     分割数据集后X_train & X_test shape:\", X_train.shape, X_test.shape)\n",
    "print(\"     y_train 唯一值:\", np.unique(y_train))\n",
    "print(\"     y_test 唯一值:\", np.unique(y_test))\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights = list(class_weights)  # 转换为列表\n",
    "print(f\"类别权重: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Training XGBoost model\n",
      "[0]\ttrain-mlogloss:2.01973\ttest-mlogloss:2.00699\n",
      "[100]\ttrain-mlogloss:1.05900\ttest-mlogloss:0.95913\n",
      "[200]\ttrain-mlogloss:0.91333\ttest-mlogloss:0.86587\n",
      "[300]\ttrain-mlogloss:0.83154\ttest-mlogloss:0.82299\n",
      "[400]\ttrain-mlogloss:0.77205\ttest-mlogloss:0.79654\n",
      "[500]\ttrain-mlogloss:0.72327\ttest-mlogloss:0.77691\n",
      "[600]\ttrain-mlogloss:0.68188\ttest-mlogloss:0.76221\n",
      "[700]\ttrain-mlogloss:0.64579\ttest-mlogloss:0.75060\n",
      "[800]\ttrain-mlogloss:0.61307\ttest-mlogloss:0.74007\n",
      "[900]\ttrain-mlogloss:0.58374\ttest-mlogloss:0.73147\n",
      "[1000]\ttrain-mlogloss:0.55650\ttest-mlogloss:0.72422\n",
      "[1100]\ttrain-mlogloss:0.53170\ttest-mlogloss:0.71781\n",
      "[1200]\ttrain-mlogloss:0.50895\ttest-mlogloss:0.71211\n",
      "[1300]\ttrain-mlogloss:0.48801\ttest-mlogloss:0.70729\n",
      "[1400]\ttrain-mlogloss:0.46804\ttest-mlogloss:0.70254\n",
      "[1500]\ttrain-mlogloss:0.44972\ttest-mlogloss:0.69850\n",
      "[1600]\ttrain-mlogloss:0.43220\ttest-mlogloss:0.69501\n",
      "[1700]\ttrain-mlogloss:0.41594\ttest-mlogloss:0.69138\n",
      "[1800]\ttrain-mlogloss:0.40057\ttest-mlogloss:0.68836\n",
      "[1900]\ttrain-mlogloss:0.38634\ttest-mlogloss:0.68546\n",
      "[1999]\ttrain-mlogloss:0.37299\ttest-mlogloss:0.68280\n",
      "Training set balanced accuracy: 0.922416\n",
      "Test set balanced accuracy: 0.678340\n",
      "Test set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.66      2463\n",
      "           1       0.83      0.81      0.82      5315\n",
      "           2       0.51      0.58      0.54      1089\n",
      "           3       0.60      0.61      0.61      1809\n",
      "           4       0.69      0.69      0.69      3958\n",
      "           5       0.63      0.72      0.67      1706\n",
      "           6       0.90      0.84      0.87     11023\n",
      "           7       0.43      0.47      0.45      1219\n",
      "\n",
      "    accuracy                           0.75     28582\n",
      "   macro avg       0.65      0.68      0.66     28582\n",
      "weighted avg       0.76      0.75      0.76     28582\n",
      "\n",
      "Model saved as 'xgboost_model.json'\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "print(\"##### Training XGBoost model\")\n",
    "# Create DMatrix for XGBoost\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "weight_dict = dict(zip(classes, class_weights))\n",
    "sample_weights = y_train.map(weight_dict)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, weight=sample_weights)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set up XGBoost parameters\n",
    "params = {\n",
    "    'max_depth': 5,\n",
    "    'eta': 0.05,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 8,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0.3,\n",
    "    'lambda': 10,\n",
    "    'alpha': 10,\n",
    "    'device': 'cuda',  \n",
    "    'max_delta_step': 0.5\n",
    "}\n",
    "\n",
    "# Train XGBoost model\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=2000,\n",
    "    evals=[(dtrain, 'train'), (dtest, 'test')],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=100\n",
    ")\n",
    "\n",
    "# Predict\n",
    "y_train_pred = model.predict(dtrain)\n",
    "y_test_pred = model.predict(dtest)\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "train_score = balanced_accuracy_score(y_train, y_train_pred)\n",
    "test_score = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Training set balanced accuracy: {train_score:.6f}\")\n",
    "print(f\"Test set balanced accuracy: {test_score:.6f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Test set classification report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Save the model\n",
    "model.save_model('xgboost_model.json')\n",
    "print(\"Model saved as 'xgboost_model.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
