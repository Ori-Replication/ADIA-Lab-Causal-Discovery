{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import featuretools as ft\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score\n",
    "import numpy as np\n",
    "from tpot import TPOTClassifier\n",
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import joblib  # 用于保存交互项模式和模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding numeric labels y\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>variable</th>\n",
       "      <th>dimension</th>\n",
       "      <th>corr(v,X)</th>\n",
       "      <th>corr(v,Y)</th>\n",
       "      <th>max(corr(v, others))</th>\n",
       "      <th>min(corr(v, others))</th>\n",
       "      <th>mean(corr(v, others))</th>\n",
       "      <th>std(corr(v, others))</th>\n",
       "      <th>corr(X,Y)</th>\n",
       "      <th>...</th>\n",
       "      <th>v~X_coefficient</th>\n",
       "      <th>v_squared~X_coefficient</th>\n",
       "      <th>v_cos~X_coefficient</th>\n",
       "      <th>v_sin~X_coefficient</th>\n",
       "      <th>X~Y_coefficient</th>\n",
       "      <th>v~Y_ridge_coefficient</th>\n",
       "      <th>v~X_ridge_coefficient</th>\n",
       "      <th>X~Y_ridge_coefficient</th>\n",
       "      <th>label</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0.169735</td>\n",
       "      <td>-0.113595</td>\n",
       "      <td>0.791467</td>\n",
       "      <td>0.027355</td>\n",
       "      <td>0.282376</td>\n",
       "      <td>0.298969</td>\n",
       "      <td>-0.771058</td>\n",
       "      <td>...</td>\n",
       "      <td>2.581106</td>\n",
       "      <td>0.642049</td>\n",
       "      <td>0.627756</td>\n",
       "      <td>-1.853991</td>\n",
       "      <td>-0.243933</td>\n",
       "      <td>-0.270012</td>\n",
       "      <td>0.746844</td>\n",
       "      <td>-0.210404</td>\n",
       "      <td>Consequence of Y</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.072334</td>\n",
       "      <td>0.139419</td>\n",
       "      <td>0.230139</td>\n",
       "      <td>0.003233</td>\n",
       "      <td>0.090511</td>\n",
       "      <td>0.082201</td>\n",
       "      <td>-0.771058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057149</td>\n",
       "      <td>-0.355636</td>\n",
       "      <td>-0.302878</td>\n",
       "      <td>0.029001</td>\n",
       "      <td>-0.243933</td>\n",
       "      <td>-0.004777</td>\n",
       "      <td>-0.015475</td>\n",
       "      <td>-0.210404</td>\n",
       "      <td>Independent</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0.123115</td>\n",
       "      <td>-0.238769</td>\n",
       "      <td>0.781051</td>\n",
       "      <td>0.012225</td>\n",
       "      <td>0.257037</td>\n",
       "      <td>0.288165</td>\n",
       "      <td>-0.771058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043431</td>\n",
       "      <td>-0.408441</td>\n",
       "      <td>-0.632885</td>\n",
       "      <td>-0.423769</td>\n",
       "      <td>-0.243933</td>\n",
       "      <td>0.087481</td>\n",
       "      <td>-0.235369</td>\n",
       "      <td>-0.210404</td>\n",
       "      <td>Cause of Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.001935</td>\n",
       "      <td>0.013921</td>\n",
       "      <td>0.147408</td>\n",
       "      <td>0.001935</td>\n",
       "      <td>0.052451</td>\n",
       "      <td>0.053457</td>\n",
       "      <td>-0.771058</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055143</td>\n",
       "      <td>0.381220</td>\n",
       "      <td>0.427163</td>\n",
       "      <td>0.116956</td>\n",
       "      <td>-0.243933</td>\n",
       "      <td>-0.016076</td>\n",
       "      <td>0.045268</td>\n",
       "      <td>-0.210404</td>\n",
       "      <td>Cause of Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.284323</td>\n",
       "      <td>-0.466570</td>\n",
       "      <td>0.791467</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.426306</td>\n",
       "      <td>0.250048</td>\n",
       "      <td>-0.771058</td>\n",
       "      <td>...</td>\n",
       "      <td>3.443463</td>\n",
       "      <td>-0.992699</td>\n",
       "      <td>-0.797171</td>\n",
       "      <td>-2.181048</td>\n",
       "      <td>-0.243933</td>\n",
       "      <td>-0.454817</td>\n",
       "      <td>1.085383</td>\n",
       "      <td>-0.210404</td>\n",
       "      <td>Mediator</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142905</th>\n",
       "      <td>46997</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.014740</td>\n",
       "      <td>0.697089</td>\n",
       "      <td>0.748635</td>\n",
       "      <td>0.013858</td>\n",
       "      <td>0.376630</td>\n",
       "      <td>0.352655</td>\n",
       "      <td>-0.089641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.414477</td>\n",
       "      <td>2.767481</td>\n",
       "      <td>2.688398</td>\n",
       "      <td>0.383910</td>\n",
       "      <td>-0.048813</td>\n",
       "      <td>0.046537</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>-0.049793</td>\n",
       "      <td>Cause of Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142906</th>\n",
       "      <td>46997</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.007397</td>\n",
       "      <td>-0.116481</td>\n",
       "      <td>0.998843</td>\n",
       "      <td>0.007397</td>\n",
       "      <td>0.180741</td>\n",
       "      <td>0.333308</td>\n",
       "      <td>-0.089641</td>\n",
       "      <td>...</td>\n",
       "      <td>3.145600</td>\n",
       "      <td>1.175395</td>\n",
       "      <td>-5.843335</td>\n",
       "      <td>-3.135427</td>\n",
       "      <td>-0.048813</td>\n",
       "      <td>-0.015032</td>\n",
       "      <td>-0.000532</td>\n",
       "      <td>-0.049793</td>\n",
       "      <td>Cause of Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142907</th>\n",
       "      <td>46997</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.011658</td>\n",
       "      <td>0.908029</td>\n",
       "      <td>0.970364</td>\n",
       "      <td>0.011658</td>\n",
       "      <td>0.469777</td>\n",
       "      <td>0.441105</td>\n",
       "      <td>-0.089641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553463</td>\n",
       "      <td>2.599347</td>\n",
       "      <td>2.702726</td>\n",
       "      <td>-0.380755</td>\n",
       "      <td>-0.048813</td>\n",
       "      <td>0.499969</td>\n",
       "      <td>-0.000334</td>\n",
       "      <td>-0.049793</td>\n",
       "      <td>Cause of Y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142908</th>\n",
       "      <td>46998</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.083546</td>\n",
       "      <td>-0.019665</td>\n",
       "      <td>0.083546</td>\n",
       "      <td>0.016856</td>\n",
       "      <td>0.040022</td>\n",
       "      <td>0.037719</td>\n",
       "      <td>0.036862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449761</td>\n",
       "      <td>0.398762</td>\n",
       "      <td>0.421113</td>\n",
       "      <td>-0.405605</td>\n",
       "      <td>0.109254</td>\n",
       "      <td>-0.010355</td>\n",
       "      <td>0.044703</td>\n",
       "      <td>0.120088</td>\n",
       "      <td>Consequence of X</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142909</th>\n",
       "      <td>46998</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.201922</td>\n",
       "      <td>0.666742</td>\n",
       "      <td>0.666742</td>\n",
       "      <td>0.016856</td>\n",
       "      <td>0.295173</td>\n",
       "      <td>0.334828</td>\n",
       "      <td>0.036862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350345</td>\n",
       "      <td>-0.001446</td>\n",
       "      <td>0.127014</td>\n",
       "      <td>-0.466684</td>\n",
       "      <td>0.109254</td>\n",
       "      <td>0.410578</td>\n",
       "      <td>-0.114152</td>\n",
       "      <td>0.120088</td>\n",
       "      <td>Collider</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142910 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dataset  variable  dimension  corr(v,X)  corr(v,Y)  \\\n",
       "0             0         0          8   0.169735  -0.113595   \n",
       "1             0         2          8  -0.072334   0.139419   \n",
       "2             0         3          8   0.123115  -0.238769   \n",
       "3             0         4          8  -0.001935   0.013921   \n",
       "4             0         5          8   0.284323  -0.466570   \n",
       "...         ...       ...        ...        ...        ...   \n",
       "142905    46997         6          7   0.014740   0.697089   \n",
       "142906    46997         7          7  -0.007397  -0.116481   \n",
       "142907    46997         8          7  -0.011658   0.908029   \n",
       "142908    46998         0          2   0.083546  -0.019665   \n",
       "142909    46998         3          2  -0.201922   0.666742   \n",
       "\n",
       "        max(corr(v, others))  min(corr(v, others))  mean(corr(v, others))  \\\n",
       "0                   0.791467              0.027355               0.282376   \n",
       "1                   0.230139              0.003233               0.090511   \n",
       "2                   0.781051              0.012225               0.257037   \n",
       "3                   0.147408              0.001935               0.052451   \n",
       "4                   0.791467              0.064815               0.426306   \n",
       "...                      ...                   ...                    ...   \n",
       "142905              0.748635              0.013858               0.376630   \n",
       "142906              0.998843              0.007397               0.180741   \n",
       "142907              0.970364              0.011658               0.469777   \n",
       "142908              0.083546              0.016856               0.040022   \n",
       "142909              0.666742              0.016856               0.295173   \n",
       "\n",
       "        std(corr(v, others))  corr(X,Y)  ...  v~X_coefficient  \\\n",
       "0                   0.298969  -0.771058  ...         2.581106   \n",
       "1                   0.082201  -0.771058  ...        -0.057149   \n",
       "2                   0.288165  -0.771058  ...         0.043431   \n",
       "3                   0.053457  -0.771058  ...        -0.055143   \n",
       "4                   0.250048  -0.771058  ...         3.443463   \n",
       "...                      ...        ...  ...              ...   \n",
       "142905              0.352655  -0.089641  ...        -0.414477   \n",
       "142906              0.333308  -0.089641  ...         3.145600   \n",
       "142907              0.441105  -0.089641  ...         0.553463   \n",
       "142908              0.037719   0.036862  ...         0.449761   \n",
       "142909              0.334828   0.036862  ...         0.350345   \n",
       "\n",
       "        v_squared~X_coefficient  v_cos~X_coefficient  v_sin~X_coefficient  \\\n",
       "0                      0.642049             0.627756            -1.853991   \n",
       "1                     -0.355636            -0.302878             0.029001   \n",
       "2                     -0.408441            -0.632885            -0.423769   \n",
       "3                      0.381220             0.427163             0.116956   \n",
       "4                     -0.992699            -0.797171            -2.181048   \n",
       "...                         ...                  ...                  ...   \n",
       "142905                 2.767481             2.688398             0.383910   \n",
       "142906                 1.175395            -5.843335            -3.135427   \n",
       "142907                 2.599347             2.702726            -0.380755   \n",
       "142908                 0.398762             0.421113            -0.405605   \n",
       "142909                -0.001446             0.127014            -0.466684   \n",
       "\n",
       "        X~Y_coefficient  v~Y_ridge_coefficient  v~X_ridge_coefficient  \\\n",
       "0             -0.243933              -0.270012               0.746844   \n",
       "1             -0.243933              -0.004777              -0.015475   \n",
       "2             -0.243933               0.087481              -0.235369   \n",
       "3             -0.243933              -0.016076               0.045268   \n",
       "4             -0.243933              -0.454817               1.085383   \n",
       "...                 ...                    ...                    ...   \n",
       "142905        -0.048813               0.046537               0.000815   \n",
       "142906        -0.048813              -0.015032              -0.000532   \n",
       "142907        -0.048813               0.499969              -0.000334   \n",
       "142908         0.109254              -0.010355               0.044703   \n",
       "142909         0.109254               0.410578              -0.114152   \n",
       "\n",
       "        X~Y_ridge_coefficient             label  y  \n",
       "0                   -0.210404  Consequence of Y  5  \n",
       "1                   -0.210404       Independent  6  \n",
       "2                   -0.210404        Cause of Y  1  \n",
       "3                   -0.210404        Cause of Y  1  \n",
       "4                   -0.210404          Mediator  7  \n",
       "...                       ...               ... ..  \n",
       "142905              -0.049793        Cause of Y  1  \n",
       "142906              -0.049793        Cause of Y  1  \n",
       "142907              -0.049793        Cause of Y  1  \n",
       "142908               0.120088  Consequence of X  4  \n",
       "142909               0.120088          Collider  2  \n",
       "\n",
       "[142910 rows x 58 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting X_train, y_train, and group\n"
     ]
    }
   ],
   "source": [
    "X_y_group_train = pd.read_csv('mid_data/X_y_group_train_updated_v8.7_线性回归v7&岭回归v2.csv')\n",
    "\n",
    "print(\"Adding numeric labels y\")\n",
    "le = LabelEncoder()\n",
    "X_y_group_train[\"y\"] = le.fit_transform(X_y_group_train[\"label\"])\n",
    "# reordering columns:\n",
    "X_y_group_train = X_y_group_train[[\"dataset\", \"variable\"] + X_y_group_train.columns.drop([\"dataset\", \"variable\", \"label\", \"y\"]).tolist() + [\"label\", \"y\"]]\n",
    "\n",
    "\n",
    "blacklist = [\"ttest(v,X)\", \"pvalue(ttest(v,X))<=0.05\", \"ttest(v,Y)\", \"pvalue(ttest(v,Y))<=0.05\", \"ttest(X,Y)\", \"pvalue(ttest(X,Y))<=0.05\"]\n",
    "columns_to_drop = [col for col in blacklist if col in X_y_group_train.columns]\n",
    "X_y_group_train = X_y_group_train.drop(columns=columns_to_drop)\n",
    "\n",
    "numeric_columns = X_y_group_train.select_dtypes(include=[np.number]).columns\n",
    "X_y_group_train[numeric_columns] = X_y_group_train[numeric_columns].fillna(X_y_group_train[numeric_columns].mean())\n",
    "\n",
    "display(X_y_group_train)\n",
    "\n",
    "print(\"Extracting X_train, y_train, and group\")\n",
    "X_train = X_y_group_train.drop([\"variable\", \"dataset\", \"label\", \"y\"], axis=\"columns\")\n",
    "\n",
    "y_train = X_y_group_train[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_classes 8\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:50:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "e:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:50:45] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.99383\n",
      "[1]\tvalidation_0-mlogloss:1.92045\n",
      "[2]\tvalidation_0-mlogloss:1.85680\n",
      "[3]\tvalidation_0-mlogloss:1.80156\n",
      "[4]\tvalidation_0-mlogloss:1.75217\n",
      "[5]\tvalidation_0-mlogloss:1.70531\n",
      "[6]\tvalidation_0-mlogloss:1.66351\n",
      "[7]\tvalidation_0-mlogloss:1.62594\n",
      "[8]\tvalidation_0-mlogloss:1.58973\n",
      "[9]\tvalidation_0-mlogloss:1.55552\n",
      "[10]\tvalidation_0-mlogloss:1.52346\n",
      "[11]\tvalidation_0-mlogloss:1.49377\n",
      "[12]\tvalidation_0-mlogloss:1.46547\n",
      "[13]\tvalidation_0-mlogloss:1.43988\n",
      "[14]\tvalidation_0-mlogloss:1.41509\n",
      "[15]\tvalidation_0-mlogloss:1.39172\n",
      "[16]\tvalidation_0-mlogloss:1.36976\n",
      "[17]\tvalidation_0-mlogloss:1.34957\n",
      "[18]\tvalidation_0-mlogloss:1.33019\n",
      "[19]\tvalidation_0-mlogloss:1.31227\n",
      "[20]\tvalidation_0-mlogloss:1.29512\n",
      "[21]\tvalidation_0-mlogloss:1.27884\n",
      "[22]\tvalidation_0-mlogloss:1.26419\n",
      "[23]\tvalidation_0-mlogloss:1.24896\n",
      "[24]\tvalidation_0-mlogloss:1.23522\n",
      "[25]\tvalidation_0-mlogloss:1.22142\n",
      "[26]\tvalidation_0-mlogloss:1.20865\n",
      "[27]\tvalidation_0-mlogloss:1.19661\n",
      "[28]\tvalidation_0-mlogloss:1.18516\n",
      "[29]\tvalidation_0-mlogloss:1.17421\n",
      "[30]\tvalidation_0-mlogloss:1.16394\n",
      "[31]\tvalidation_0-mlogloss:1.15415\n",
      "[32]\tvalidation_0-mlogloss:1.14461\n",
      "[33]\tvalidation_0-mlogloss:1.13544\n",
      "[34]\tvalidation_0-mlogloss:1.12655\n",
      "[35]\tvalidation_0-mlogloss:1.11808\n",
      "[36]\tvalidation_0-mlogloss:1.11033\n",
      "[37]\tvalidation_0-mlogloss:1.10259\n",
      "[38]\tvalidation_0-mlogloss:1.09527\n",
      "[39]\tvalidation_0-mlogloss:1.08818\n",
      "[40]\tvalidation_0-mlogloss:1.08196\n",
      "[41]\tvalidation_0-mlogloss:1.07541\n",
      "[42]\tvalidation_0-mlogloss:1.06918\n",
      "[43]\tvalidation_0-mlogloss:1.06310\n",
      "[44]\tvalidation_0-mlogloss:1.05759\n",
      "[45]\tvalidation_0-mlogloss:1.05204\n",
      "[46]\tvalidation_0-mlogloss:1.04689\n",
      "[47]\tvalidation_0-mlogloss:1.04162\n",
      "[48]\tvalidation_0-mlogloss:1.03694\n",
      "[49]\tvalidation_0-mlogloss:1.03205\n",
      "[50]\tvalidation_0-mlogloss:1.02737\n",
      "[51]\tvalidation_0-mlogloss:1.02308\n",
      "[52]\tvalidation_0-mlogloss:1.01899\n",
      "[53]\tvalidation_0-mlogloss:1.01508\n",
      "[54]\tvalidation_0-mlogloss:1.01128\n",
      "[55]\tvalidation_0-mlogloss:1.00762\n",
      "[56]\tvalidation_0-mlogloss:1.00401\n",
      "[57]\tvalidation_0-mlogloss:1.00033\n",
      "[58]\tvalidation_0-mlogloss:0.99705\n",
      "[59]\tvalidation_0-mlogloss:0.99370\n",
      "[60]\tvalidation_0-mlogloss:0.99064\n",
      "[61]\tvalidation_0-mlogloss:0.98762\n",
      "[62]\tvalidation_0-mlogloss:0.98473\n",
      "[63]\tvalidation_0-mlogloss:0.98179\n",
      "[64]\tvalidation_0-mlogloss:0.97916\n",
      "[65]\tvalidation_0-mlogloss:0.97657\n",
      "[66]\tvalidation_0-mlogloss:0.97398\n",
      "[67]\tvalidation_0-mlogloss:0.97156\n",
      "[68]\tvalidation_0-mlogloss:0.96911\n",
      "[69]\tvalidation_0-mlogloss:0.96676\n",
      "[70]\tvalidation_0-mlogloss:0.96451\n",
      "[71]\tvalidation_0-mlogloss:0.96238\n",
      "[72]\tvalidation_0-mlogloss:0.96034\n",
      "[73]\tvalidation_0-mlogloss:0.95843\n",
      "[74]\tvalidation_0-mlogloss:0.95642\n",
      "[75]\tvalidation_0-mlogloss:0.95448\n",
      "[76]\tvalidation_0-mlogloss:0.95256\n",
      "[77]\tvalidation_0-mlogloss:0.95070\n",
      "[78]\tvalidation_0-mlogloss:0.94915\n",
      "[79]\tvalidation_0-mlogloss:0.94744\n",
      "[80]\tvalidation_0-mlogloss:0.94584\n",
      "[81]\tvalidation_0-mlogloss:0.94414\n",
      "[82]\tvalidation_0-mlogloss:0.94266\n",
      "[83]\tvalidation_0-mlogloss:0.94119\n",
      "[84]\tvalidation_0-mlogloss:0.93965\n",
      "[85]\tvalidation_0-mlogloss:0.93819\n",
      "[86]\tvalidation_0-mlogloss:0.93660\n",
      "[87]\tvalidation_0-mlogloss:0.93512\n",
      "[88]\tvalidation_0-mlogloss:0.93366\n",
      "[89]\tvalidation_0-mlogloss:0.93226\n",
      "[90]\tvalidation_0-mlogloss:0.93103\n",
      "[91]\tvalidation_0-mlogloss:0.92981\n",
      "[92]\tvalidation_0-mlogloss:0.92854\n",
      "[93]\tvalidation_0-mlogloss:0.92737\n",
      "[94]\tvalidation_0-mlogloss:0.92635\n",
      "[95]\tvalidation_0-mlogloss:0.92524\n",
      "[96]\tvalidation_0-mlogloss:0.92422\n",
      "[97]\tvalidation_0-mlogloss:0.92306\n",
      "[98]\tvalidation_0-mlogloss:0.92204\n",
      "[99]\tvalidation_0-mlogloss:0.92093\n",
      "[100]\tvalidation_0-mlogloss:0.92004\n",
      "[101]\tvalidation_0-mlogloss:0.91904\n",
      "[102]\tvalidation_0-mlogloss:0.91799\n",
      "[103]\tvalidation_0-mlogloss:0.91685\n",
      "[104]\tvalidation_0-mlogloss:0.91582\n",
      "[105]\tvalidation_0-mlogloss:0.91484\n",
      "[106]\tvalidation_0-mlogloss:0.91388\n",
      "[107]\tvalidation_0-mlogloss:0.91306\n",
      "[108]\tvalidation_0-mlogloss:0.91217\n",
      "[109]\tvalidation_0-mlogloss:0.91131\n",
      "[110]\tvalidation_0-mlogloss:0.91052\n",
      "[111]\tvalidation_0-mlogloss:0.90965\n",
      "[112]\tvalidation_0-mlogloss:0.90883\n",
      "[113]\tvalidation_0-mlogloss:0.90815\n",
      "[114]\tvalidation_0-mlogloss:0.90746\n",
      "[115]\tvalidation_0-mlogloss:0.90652\n",
      "[116]\tvalidation_0-mlogloss:0.90575\n",
      "[117]\tvalidation_0-mlogloss:0.90501\n",
      "[118]\tvalidation_0-mlogloss:0.90443\n",
      "[119]\tvalidation_0-mlogloss:0.90377\n",
      "[120]\tvalidation_0-mlogloss:0.90316\n",
      "[121]\tvalidation_0-mlogloss:0.90244\n",
      "[122]\tvalidation_0-mlogloss:0.90184\n",
      "[123]\tvalidation_0-mlogloss:0.90122\n",
      "[124]\tvalidation_0-mlogloss:0.90049\n",
      "[125]\tvalidation_0-mlogloss:0.89976\n",
      "[126]\tvalidation_0-mlogloss:0.89927\n",
      "[127]\tvalidation_0-mlogloss:0.89868\n",
      "[128]\tvalidation_0-mlogloss:0.89811\n",
      "[129]\tvalidation_0-mlogloss:0.89746\n",
      "[130]\tvalidation_0-mlogloss:0.89684\n",
      "[131]\tvalidation_0-mlogloss:0.89614\n",
      "[132]\tvalidation_0-mlogloss:0.89567\n",
      "[133]\tvalidation_0-mlogloss:0.89516\n",
      "[134]\tvalidation_0-mlogloss:0.89465\n",
      "[135]\tvalidation_0-mlogloss:0.89404\n",
      "[136]\tvalidation_0-mlogloss:0.89357\n",
      "[137]\tvalidation_0-mlogloss:0.89295\n",
      "[138]\tvalidation_0-mlogloss:0.89245\n",
      "[139]\tvalidation_0-mlogloss:0.89194\n",
      "[140]\tvalidation_0-mlogloss:0.89142\n",
      "[141]\tvalidation_0-mlogloss:0.89097\n",
      "[142]\tvalidation_0-mlogloss:0.89049\n",
      "[143]\tvalidation_0-mlogloss:0.89005\n",
      "[144]\tvalidation_0-mlogloss:0.88949\n",
      "[145]\tvalidation_0-mlogloss:0.88907\n",
      "[146]\tvalidation_0-mlogloss:0.88871\n",
      "[147]\tvalidation_0-mlogloss:0.88835\n",
      "[148]\tvalidation_0-mlogloss:0.88789\n",
      "[149]\tvalidation_0-mlogloss:0.88745\n",
      "[150]\tvalidation_0-mlogloss:0.88712\n",
      "[151]\tvalidation_0-mlogloss:0.88672\n",
      "[152]\tvalidation_0-mlogloss:0.88633\n",
      "[153]\tvalidation_0-mlogloss:0.88591\n",
      "[154]\tvalidation_0-mlogloss:0.88535\n",
      "[155]\tvalidation_0-mlogloss:0.88506\n",
      "[156]\tvalidation_0-mlogloss:0.88460\n",
      "[157]\tvalidation_0-mlogloss:0.88417\n",
      "[158]\tvalidation_0-mlogloss:0.88382\n",
      "[159]\tvalidation_0-mlogloss:0.88345\n",
      "[160]\tvalidation_0-mlogloss:0.88314\n",
      "[161]\tvalidation_0-mlogloss:0.88284\n",
      "[162]\tvalidation_0-mlogloss:0.88258\n",
      "[163]\tvalidation_0-mlogloss:0.88228\n",
      "[164]\tvalidation_0-mlogloss:0.88193\n",
      "[165]\tvalidation_0-mlogloss:0.88155\n",
      "[166]\tvalidation_0-mlogloss:0.88121\n",
      "[167]\tvalidation_0-mlogloss:0.88080\n",
      "[168]\tvalidation_0-mlogloss:0.88036\n",
      "[169]\tvalidation_0-mlogloss:0.87998\n",
      "[170]\tvalidation_0-mlogloss:0.87966\n",
      "[171]\tvalidation_0-mlogloss:0.87932\n",
      "[172]\tvalidation_0-mlogloss:0.87894\n",
      "[173]\tvalidation_0-mlogloss:0.87861\n",
      "[174]\tvalidation_0-mlogloss:0.87836\n",
      "[175]\tvalidation_0-mlogloss:0.87800\n",
      "[176]\tvalidation_0-mlogloss:0.87777\n",
      "[177]\tvalidation_0-mlogloss:0.87756\n",
      "[178]\tvalidation_0-mlogloss:0.87733\n",
      "[179]\tvalidation_0-mlogloss:0.87707\n",
      "[180]\tvalidation_0-mlogloss:0.87680\n",
      "[181]\tvalidation_0-mlogloss:0.87654\n",
      "[182]\tvalidation_0-mlogloss:0.87622\n",
      "[183]\tvalidation_0-mlogloss:0.87604\n",
      "[184]\tvalidation_0-mlogloss:0.87585\n",
      "[185]\tvalidation_0-mlogloss:0.87559\n",
      "[186]\tvalidation_0-mlogloss:0.87539\n",
      "[187]\tvalidation_0-mlogloss:0.87518\n",
      "[188]\tvalidation_0-mlogloss:0.87496\n",
      "[189]\tvalidation_0-mlogloss:0.87471\n",
      "[190]\tvalidation_0-mlogloss:0.87446\n",
      "[191]\tvalidation_0-mlogloss:0.87426\n",
      "[192]\tvalidation_0-mlogloss:0.87405\n",
      "[193]\tvalidation_0-mlogloss:0.87386\n",
      "[194]\tvalidation_0-mlogloss:0.87368\n",
      "[195]\tvalidation_0-mlogloss:0.87345\n",
      "[196]\tvalidation_0-mlogloss:0.87327\n",
      "[197]\tvalidation_0-mlogloss:0.87314\n",
      "[198]\tvalidation_0-mlogloss:0.87294\n",
      "[199]\tvalidation_0-mlogloss:0.87271\n",
      "[200]\tvalidation_0-mlogloss:0.87247\n",
      "[201]\tvalidation_0-mlogloss:0.87229\n",
      "[202]\tvalidation_0-mlogloss:0.87204\n",
      "[203]\tvalidation_0-mlogloss:0.87185\n",
      "[204]\tvalidation_0-mlogloss:0.87168\n",
      "[205]\tvalidation_0-mlogloss:0.87141\n",
      "[206]\tvalidation_0-mlogloss:0.87121\n",
      "[207]\tvalidation_0-mlogloss:0.87093\n",
      "[208]\tvalidation_0-mlogloss:0.87074\n",
      "[209]\tvalidation_0-mlogloss:0.87056\n",
      "[210]\tvalidation_0-mlogloss:0.87034\n",
      "[211]\tvalidation_0-mlogloss:0.87014\n",
      "[212]\tvalidation_0-mlogloss:0.86993\n",
      "[213]\tvalidation_0-mlogloss:0.86968\n",
      "[214]\tvalidation_0-mlogloss:0.86949\n",
      "[215]\tvalidation_0-mlogloss:0.86929\n",
      "[216]\tvalidation_0-mlogloss:0.86905\n",
      "[217]\tvalidation_0-mlogloss:0.86894\n",
      "[218]\tvalidation_0-mlogloss:0.86882\n",
      "[219]\tvalidation_0-mlogloss:0.86871\n",
      "[220]\tvalidation_0-mlogloss:0.86854\n",
      "[221]\tvalidation_0-mlogloss:0.86830\n",
      "[222]\tvalidation_0-mlogloss:0.86807\n",
      "[223]\tvalidation_0-mlogloss:0.86796\n",
      "[224]\tvalidation_0-mlogloss:0.86780\n",
      "[225]\tvalidation_0-mlogloss:0.86764\n",
      "[226]\tvalidation_0-mlogloss:0.86756\n",
      "[227]\tvalidation_0-mlogloss:0.86741\n",
      "[228]\tvalidation_0-mlogloss:0.86728\n",
      "[229]\tvalidation_0-mlogloss:0.86709\n",
      "[230]\tvalidation_0-mlogloss:0.86702\n",
      "[231]\tvalidation_0-mlogloss:0.86683\n",
      "[232]\tvalidation_0-mlogloss:0.86667\n",
      "[233]\tvalidation_0-mlogloss:0.86653\n",
      "[234]\tvalidation_0-mlogloss:0.86636\n",
      "[235]\tvalidation_0-mlogloss:0.86623\n",
      "[236]\tvalidation_0-mlogloss:0.86607\n",
      "[237]\tvalidation_0-mlogloss:0.86596\n",
      "[238]\tvalidation_0-mlogloss:0.86584\n",
      "[239]\tvalidation_0-mlogloss:0.86575\n",
      "[240]\tvalidation_0-mlogloss:0.86559\n",
      "[241]\tvalidation_0-mlogloss:0.86548\n",
      "[242]\tvalidation_0-mlogloss:0.86534\n",
      "[243]\tvalidation_0-mlogloss:0.86516\n",
      "[244]\tvalidation_0-mlogloss:0.86501\n",
      "[245]\tvalidation_0-mlogloss:0.86488\n",
      "[246]\tvalidation_0-mlogloss:0.86477\n",
      "[247]\tvalidation_0-mlogloss:0.86469\n",
      "[248]\tvalidation_0-mlogloss:0.86461\n",
      "[249]\tvalidation_0-mlogloss:0.86445\n",
      "[250]\tvalidation_0-mlogloss:0.86435\n",
      "[251]\tvalidation_0-mlogloss:0.86423\n",
      "[252]\tvalidation_0-mlogloss:0.86417\n",
      "[253]\tvalidation_0-mlogloss:0.86402\n",
      "[254]\tvalidation_0-mlogloss:0.86396\n",
      "[255]\tvalidation_0-mlogloss:0.86386\n",
      "[256]\tvalidation_0-mlogloss:0.86375\n",
      "[257]\tvalidation_0-mlogloss:0.86365\n",
      "[258]\tvalidation_0-mlogloss:0.86354\n",
      "[259]\tvalidation_0-mlogloss:0.86342\n",
      "[260]\tvalidation_0-mlogloss:0.86328\n",
      "[261]\tvalidation_0-mlogloss:0.86316\n",
      "[262]\tvalidation_0-mlogloss:0.86303\n",
      "[263]\tvalidation_0-mlogloss:0.86293\n",
      "[264]\tvalidation_0-mlogloss:0.86277\n",
      "[265]\tvalidation_0-mlogloss:0.86265\n",
      "[266]\tvalidation_0-mlogloss:0.86251\n",
      "[267]\tvalidation_0-mlogloss:0.86239\n",
      "[268]\tvalidation_0-mlogloss:0.86223\n",
      "[269]\tvalidation_0-mlogloss:0.86219\n",
      "[270]\tvalidation_0-mlogloss:0.86212\n",
      "[271]\tvalidation_0-mlogloss:0.86205\n",
      "[272]\tvalidation_0-mlogloss:0.86193\n",
      "[273]\tvalidation_0-mlogloss:0.86178\n",
      "[274]\tvalidation_0-mlogloss:0.86171\n",
      "[275]\tvalidation_0-mlogloss:0.86159\n",
      "[276]\tvalidation_0-mlogloss:0.86151\n",
      "[277]\tvalidation_0-mlogloss:0.86147\n",
      "[278]\tvalidation_0-mlogloss:0.86141\n",
      "[279]\tvalidation_0-mlogloss:0.86135\n",
      "[280]\tvalidation_0-mlogloss:0.86128\n",
      "[281]\tvalidation_0-mlogloss:0.86104\n",
      "[282]\tvalidation_0-mlogloss:0.86095\n",
      "[283]\tvalidation_0-mlogloss:0.86082\n",
      "[284]\tvalidation_0-mlogloss:0.86081\n",
      "[285]\tvalidation_0-mlogloss:0.86069\n",
      "[286]\tvalidation_0-mlogloss:0.86065\n",
      "[287]\tvalidation_0-mlogloss:0.86061\n",
      "[288]\tvalidation_0-mlogloss:0.86055\n",
      "[289]\tvalidation_0-mlogloss:0.86051\n",
      "[290]\tvalidation_0-mlogloss:0.86036\n",
      "[291]\tvalidation_0-mlogloss:0.86023\n",
      "[292]\tvalidation_0-mlogloss:0.86013\n",
      "[293]\tvalidation_0-mlogloss:0.86005\n",
      "[294]\tvalidation_0-mlogloss:0.86002\n",
      "[295]\tvalidation_0-mlogloss:0.85995\n",
      "[296]\tvalidation_0-mlogloss:0.85991\n",
      "[297]\tvalidation_0-mlogloss:0.85977\n",
      "[298]\tvalidation_0-mlogloss:0.85970\n",
      "[299]\tvalidation_0-mlogloss:0.85966\n",
      "[300]\tvalidation_0-mlogloss:0.85954\n",
      "[301]\tvalidation_0-mlogloss:0.85950\n",
      "[302]\tvalidation_0-mlogloss:0.85942\n",
      "[303]\tvalidation_0-mlogloss:0.85934\n",
      "[304]\tvalidation_0-mlogloss:0.85931\n",
      "[305]\tvalidation_0-mlogloss:0.85925\n",
      "[306]\tvalidation_0-mlogloss:0.85922\n",
      "[307]\tvalidation_0-mlogloss:0.85911\n",
      "[308]\tvalidation_0-mlogloss:0.85907\n",
      "[309]\tvalidation_0-mlogloss:0.85905\n",
      "[310]\tvalidation_0-mlogloss:0.85895\n",
      "[311]\tvalidation_0-mlogloss:0.85889\n",
      "[312]\tvalidation_0-mlogloss:0.85881\n",
      "[313]\tvalidation_0-mlogloss:0.85873\n",
      "[314]\tvalidation_0-mlogloss:0.85864\n",
      "[315]\tvalidation_0-mlogloss:0.85857\n",
      "[316]\tvalidation_0-mlogloss:0.85852\n",
      "[317]\tvalidation_0-mlogloss:0.85850\n",
      "[318]\tvalidation_0-mlogloss:0.85849\n",
      "[319]\tvalidation_0-mlogloss:0.85845\n",
      "[320]\tvalidation_0-mlogloss:0.85835\n",
      "[321]\tvalidation_0-mlogloss:0.85828\n",
      "[322]\tvalidation_0-mlogloss:0.85819\n",
      "[323]\tvalidation_0-mlogloss:0.85811\n",
      "[324]\tvalidation_0-mlogloss:0.85799\n",
      "[325]\tvalidation_0-mlogloss:0.85796\n",
      "[326]\tvalidation_0-mlogloss:0.85788\n",
      "[327]\tvalidation_0-mlogloss:0.85792\n",
      "[328]\tvalidation_0-mlogloss:0.85787\n",
      "[329]\tvalidation_0-mlogloss:0.85781\n",
      "[330]\tvalidation_0-mlogloss:0.85771\n",
      "[331]\tvalidation_0-mlogloss:0.85767\n",
      "[332]\tvalidation_0-mlogloss:0.85764\n",
      "[333]\tvalidation_0-mlogloss:0.85756\n",
      "[334]\tvalidation_0-mlogloss:0.85754\n",
      "[335]\tvalidation_0-mlogloss:0.85747\n",
      "[336]\tvalidation_0-mlogloss:0.85739\n",
      "[337]\tvalidation_0-mlogloss:0.85734\n",
      "[338]\tvalidation_0-mlogloss:0.85726\n",
      "[339]\tvalidation_0-mlogloss:0.85724\n",
      "[340]\tvalidation_0-mlogloss:0.85724\n",
      "[341]\tvalidation_0-mlogloss:0.85721\n",
      "[342]\tvalidation_0-mlogloss:0.85715\n",
      "[343]\tvalidation_0-mlogloss:0.85714\n",
      "[344]\tvalidation_0-mlogloss:0.85709\n",
      "[345]\tvalidation_0-mlogloss:0.85704\n",
      "[346]\tvalidation_0-mlogloss:0.85702\n",
      "[347]\tvalidation_0-mlogloss:0.85698\n",
      "[348]\tvalidation_0-mlogloss:0.85694\n",
      "[349]\tvalidation_0-mlogloss:0.85692\n",
      "[350]\tvalidation_0-mlogloss:0.85683\n",
      "[351]\tvalidation_0-mlogloss:0.85680\n",
      "[352]\tvalidation_0-mlogloss:0.85672\n",
      "[353]\tvalidation_0-mlogloss:0.85669\n",
      "[354]\tvalidation_0-mlogloss:0.85665\n",
      "[355]\tvalidation_0-mlogloss:0.85663\n",
      "[356]\tvalidation_0-mlogloss:0.85654\n",
      "[357]\tvalidation_0-mlogloss:0.85656\n",
      "[358]\tvalidation_0-mlogloss:0.85653\n",
      "[359]\tvalidation_0-mlogloss:0.85654\n",
      "[360]\tvalidation_0-mlogloss:0.85638\n",
      "[361]\tvalidation_0-mlogloss:0.85628\n",
      "[362]\tvalidation_0-mlogloss:0.85625\n",
      "[363]\tvalidation_0-mlogloss:0.85622\n",
      "[364]\tvalidation_0-mlogloss:0.85617\n",
      "[365]\tvalidation_0-mlogloss:0.85611\n",
      "[366]\tvalidation_0-mlogloss:0.85610\n",
      "[367]\tvalidation_0-mlogloss:0.85603\n",
      "[368]\tvalidation_0-mlogloss:0.85605\n",
      "[369]\tvalidation_0-mlogloss:0.85605\n",
      "[370]\tvalidation_0-mlogloss:0.85596\n",
      "[371]\tvalidation_0-mlogloss:0.85591\n",
      "[372]\tvalidation_0-mlogloss:0.85584\n",
      "[373]\tvalidation_0-mlogloss:0.85578\n",
      "[374]\tvalidation_0-mlogloss:0.85576\n",
      "[375]\tvalidation_0-mlogloss:0.85570\n",
      "[376]\tvalidation_0-mlogloss:0.85567\n",
      "[377]\tvalidation_0-mlogloss:0.85578\n",
      "[378]\tvalidation_0-mlogloss:0.85574\n",
      "[379]\tvalidation_0-mlogloss:0.85571\n",
      "[380]\tvalidation_0-mlogloss:0.85565\n",
      "[381]\tvalidation_0-mlogloss:0.85555\n",
      "[382]\tvalidation_0-mlogloss:0.85555\n",
      "[383]\tvalidation_0-mlogloss:0.85546\n",
      "[384]\tvalidation_0-mlogloss:0.85546\n",
      "[385]\tvalidation_0-mlogloss:0.85545\n",
      "[386]\tvalidation_0-mlogloss:0.85546\n",
      "[387]\tvalidation_0-mlogloss:0.85550\n",
      "[388]\tvalidation_0-mlogloss:0.85544\n",
      "[389]\tvalidation_0-mlogloss:0.85548\n",
      "[390]\tvalidation_0-mlogloss:0.85550\n",
      "[391]\tvalidation_0-mlogloss:0.85548\n",
      "[392]\tvalidation_0-mlogloss:0.85558\n",
      "[393]\tvalidation_0-mlogloss:0.85554\n",
      "[394]\tvalidation_0-mlogloss:0.85554\n",
      "[395]\tvalidation_0-mlogloss:0.85555\n",
      "[396]\tvalidation_0-mlogloss:0.85558\n",
      "[397]\tvalidation_0-mlogloss:0.85554\n",
      "[398]\tvalidation_0-mlogloss:0.85554\n",
      "[399]\tvalidation_0-mlogloss:0.85547\n",
      "[400]\tvalidation_0-mlogloss:0.85549\n",
      "[401]\tvalidation_0-mlogloss:0.85549\n",
      "[402]\tvalidation_0-mlogloss:0.85539\n",
      "[403]\tvalidation_0-mlogloss:0.85536\n",
      "[404]\tvalidation_0-mlogloss:0.85533\n",
      "[405]\tvalidation_0-mlogloss:0.85530\n",
      "[406]\tvalidation_0-mlogloss:0.85523\n",
      "[407]\tvalidation_0-mlogloss:0.85520\n",
      "[408]\tvalidation_0-mlogloss:0.85519\n",
      "[409]\tvalidation_0-mlogloss:0.85520\n",
      "[410]\tvalidation_0-mlogloss:0.85516\n",
      "[411]\tvalidation_0-mlogloss:0.85518\n",
      "[412]\tvalidation_0-mlogloss:0.85519\n",
      "[413]\tvalidation_0-mlogloss:0.85515\n",
      "[414]\tvalidation_0-mlogloss:0.85514\n",
      "[415]\tvalidation_0-mlogloss:0.85514\n",
      "[416]\tvalidation_0-mlogloss:0.85517\n",
      "[417]\tvalidation_0-mlogloss:0.85517\n",
      "[418]\tvalidation_0-mlogloss:0.85513\n",
      "[419]\tvalidation_0-mlogloss:0.85515\n",
      "[420]\tvalidation_0-mlogloss:0.85513\n",
      "[421]\tvalidation_0-mlogloss:0.85510\n",
      "[422]\tvalidation_0-mlogloss:0.85513\n",
      "[423]\tvalidation_0-mlogloss:0.85514\n",
      "[424]\tvalidation_0-mlogloss:0.85516\n",
      "[425]\tvalidation_0-mlogloss:0.85516\n",
      "[426]\tvalidation_0-mlogloss:0.85510\n",
      "[427]\tvalidation_0-mlogloss:0.85510\n",
      "[428]\tvalidation_0-mlogloss:0.85503\n",
      "[429]\tvalidation_0-mlogloss:0.85497\n",
      "[430]\tvalidation_0-mlogloss:0.85497\n",
      "[431]\tvalidation_0-mlogloss:0.85494\n",
      "[432]\tvalidation_0-mlogloss:0.85492\n",
      "[433]\tvalidation_0-mlogloss:0.85497\n",
      "[434]\tvalidation_0-mlogloss:0.85502\n",
      "[435]\tvalidation_0-mlogloss:0.85501\n",
      "[436]\tvalidation_0-mlogloss:0.85504\n",
      "[437]\tvalidation_0-mlogloss:0.85499\n",
      "[438]\tvalidation_0-mlogloss:0.85498\n",
      "[439]\tvalidation_0-mlogloss:0.85494\n",
      "[440]\tvalidation_0-mlogloss:0.85501\n",
      "[441]\tvalidation_0-mlogloss:0.85508\n",
      "[442]\tvalidation_0-mlogloss:0.85509\n",
      "[443]\tvalidation_0-mlogloss:0.85506\n",
      "[444]\tvalidation_0-mlogloss:0.85508\n",
      "[445]\tvalidation_0-mlogloss:0.85507\n",
      "[446]\tvalidation_0-mlogloss:0.85509\n",
      "[447]\tvalidation_0-mlogloss:0.85507\n",
      "[448]\tvalidation_0-mlogloss:0.85503\n",
      "[449]\tvalidation_0-mlogloss:0.85503\n",
      "[450]\tvalidation_0-mlogloss:0.85505\n",
      "[451]\tvalidation_0-mlogloss:0.85503\n",
      "[452]\tvalidation_0-mlogloss:0.85503\n",
      "[453]\tvalidation_0-mlogloss:0.85508\n",
      "[454]\tvalidation_0-mlogloss:0.85505\n",
      "[455]\tvalidation_0-mlogloss:0.85501\n",
      "[456]\tvalidation_0-mlogloss:0.85504\n",
      "[457]\tvalidation_0-mlogloss:0.85499\n",
      "[458]\tvalidation_0-mlogloss:0.85495\n",
      "[459]\tvalidation_0-mlogloss:0.85502\n",
      "[460]\tvalidation_0-mlogloss:0.85498\n",
      "[461]\tvalidation_0-mlogloss:0.85498\n",
      "[462]\tvalidation_0-mlogloss:0.85498\n",
      "[463]\tvalidation_0-mlogloss:0.85494\n",
      "[464]\tvalidation_0-mlogloss:0.85498\n",
      "[465]\tvalidation_0-mlogloss:0.85496\n",
      "[466]\tvalidation_0-mlogloss:0.85501\n",
      "[467]\tvalidation_0-mlogloss:0.85506\n",
      "[468]\tvalidation_0-mlogloss:0.85508\n",
      "[469]\tvalidation_0-mlogloss:0.85507\n",
      "[470]\tvalidation_0-mlogloss:0.85506\n",
      "[471]\tvalidation_0-mlogloss:0.85507\n",
      "[472]\tvalidation_0-mlogloss:0.85504\n",
      "[473]\tvalidation_0-mlogloss:0.85504\n",
      "[474]\tvalidation_0-mlogloss:0.85508\n",
      "[475]\tvalidation_0-mlogloss:0.85511\n",
      "[476]\tvalidation_0-mlogloss:0.85509\n",
      "[477]\tvalidation_0-mlogloss:0.85507\n",
      "[478]\tvalidation_0-mlogloss:0.85507\n",
      "[479]\tvalidation_0-mlogloss:0.85506\n",
      "[480]\tvalidation_0-mlogloss:0.85504\n",
      "[481]\tvalidation_0-mlogloss:0.85509\n",
      "[482]\tvalidation_0-mlogloss:0.85515\n",
      "[483]\tvalidation_0-mlogloss:0.85516\n",
      "[484]\tvalidation_0-mlogloss:0.85522\n",
      "[485]\tvalidation_0-mlogloss:0.85519\n",
      "[486]\tvalidation_0-mlogloss:0.85514\n",
      "[487]\tvalidation_0-mlogloss:0.85515\n",
      "[488]\tvalidation_0-mlogloss:0.85518\n",
      "[489]\tvalidation_0-mlogloss:0.85511\n",
      "[490]\tvalidation_0-mlogloss:0.85512\n",
      "[491]\tvalidation_0-mlogloss:0.85516\n",
      "[492]\tvalidation_0-mlogloss:0.85512\n",
      "[493]\tvalidation_0-mlogloss:0.85516\n",
      "[494]\tvalidation_0-mlogloss:0.85515\n",
      "[495]\tvalidation_0-mlogloss:0.85518\n",
      "[496]\tvalidation_0-mlogloss:0.85520\n",
      "[497]\tvalidation_0-mlogloss:0.85522\n",
      "[498]\tvalidation_0-mlogloss:0.85526\n",
      "[499]\tvalidation_0-mlogloss:0.85533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [22:51:35] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Balanced Accuracy: 0.5141\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.47      0.52      2026\n",
      "           1       0.77      0.75      0.76      4289\n",
      "           2       0.43      0.24      0.31       845\n",
      "           3       0.48      0.44      0.46      1454\n",
      "           4       0.59      0.63      0.61      3107\n",
      "           5       0.58      0.48      0.52      1360\n",
      "           6       0.78      0.91      0.84      8808\n",
      "           7       0.35      0.19      0.24       977\n",
      "\n",
      "    accuracy                           0.69     22866\n",
      "   macro avg       0.57      0.51      0.53     22866\n",
      "weighted avg       0.67      0.69      0.68     22866\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, balanced_accuracy_score\n",
    "\n",
    "# 检查类别数量\n",
    "num_classes = y_train.nunique()\n",
    "print('num_classes', num_classes)\n",
    "# 将数据拆分为训练集和验证集\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# 初始化XGBClassifier，使用GPU加速，选择合适的超参数\n",
    "xgb_clf = XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=num_classes,\n",
    "    eval_metric='mlogloss',\n",
    "    use_label_encoder=False,\n",
    "    tree_method='gpu_hist',  # 使用GPU加速\n",
    "    n_estimators=500,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.5,\n",
    "    verbosity=1  # 设置为1，输出必要的训练信息\n",
    ")\n",
    "\n",
    "# 开始训练\n",
    "print(\"Starting training...\")\n",
    "xgb_clf.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=True)\n",
    "\n",
    "# 在验证集上评估模型\n",
    "y_pred = xgb_clf.predict(X_val)\n",
    "balanced_acc = balanced_accuracy_score(y_val, y_pred)\n",
    "print(f\"Validation Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Best:\n",
    "xgb_clf = XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=num_classes,\n",
    "    eval_metric='mlogloss',\n",
    "    use_label_encoder=False,\n",
    "    tree_method='gpu_hist',  # 使用GPU加速\n",
    "    n_estimators=500,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=0.5,\n",
    "    verbosity=1  # 设置为1，输出必要的训练信息\n",
    ")\n",
    "\n",
    "#0.5141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combination 1/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4304\n",
      "New best score: 0.4304\n",
      "--------------------\n",
      "Testing combination 2/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4306\n",
      "New best score: 0.4306\n",
      "--------------------\n",
      "Testing combination 3/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4303\n",
      "--------------------\n",
      "Testing combination 4/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.5, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4303\n",
      "--------------------\n",
      "Testing combination 5/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4304\n",
      "--------------------\n",
      "Testing combination 6/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4299\n",
      "--------------------\n",
      "Testing combination 7/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4299\n",
      "--------------------\n",
      "Testing combination 8/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4300\n",
      "--------------------\n",
      "Testing combination 9/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4301\n",
      "--------------------\n",
      "Testing combination 10/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4296\n",
      "--------------------\n",
      "Testing combination 11/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4294\n",
      "--------------------\n",
      "Testing combination 12/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4296\n",
      "--------------------\n",
      "Testing combination 13/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4298\n",
      "--------------------\n",
      "Testing combination 14/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4294\n",
      "--------------------\n",
      "Testing combination 15/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4293\n",
      "--------------------\n",
      "Testing combination 16/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4301\n",
      "--------------------\n",
      "Testing combination 17/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4295\n",
      "--------------------\n",
      "Testing combination 18/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4301\n",
      "--------------------\n",
      "Testing combination 19/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4295\n",
      "--------------------\n",
      "Testing combination 20/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4303\n",
      "--------------------\n",
      "Testing combination 21/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4296\n",
      "--------------------\n",
      "Testing combination 22/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.5, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4290\n",
      "--------------------\n",
      "Testing combination 23/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4291\n",
      "--------------------\n",
      "Testing combination 24/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4294\n",
      "--------------------\n",
      "Testing combination 25/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4291\n",
      "--------------------\n",
      "Testing combination 26/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4296\n",
      "--------------------\n",
      "Testing combination 27/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4298\n",
      "--------------------\n",
      "Testing combination 28/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4289\n",
      "--------------------\n",
      "Testing combination 29/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4286\n",
      "--------------------\n",
      "Testing combination 30/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4287\n",
      "--------------------\n",
      "Testing combination 31/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.5, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4292\n",
      "--------------------\n",
      "Testing combination 32/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4282\n",
      "--------------------\n",
      "Testing combination 33/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4290\n",
      "--------------------\n",
      "Testing combination 34/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4286\n",
      "--------------------\n",
      "Testing combination 35/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4289\n",
      "--------------------\n",
      "Testing combination 36/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4284\n",
      "--------------------\n",
      "Testing combination 37/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4284\n",
      "--------------------\n",
      "Testing combination 38/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4291\n",
      "--------------------\n",
      "Testing combination 39/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4293\n",
      "--------------------\n",
      "Testing combination 40/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4296\n",
      "--------------------\n",
      "Testing combination 41/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4295\n",
      "--------------------\n",
      "Testing combination 42/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4293\n",
      "--------------------\n",
      "Testing combination 43/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4290\n",
      "--------------------\n",
      "Testing combination 44/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4292\n",
      "--------------------\n",
      "Testing combination 45/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4292\n",
      "--------------------\n",
      "Testing combination 46/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4275\n",
      "--------------------\n",
      "Testing combination 47/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4278\n",
      "--------------------\n",
      "Testing combination 48/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4272\n",
      "--------------------\n",
      "Testing combination 49/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.5, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4271\n",
      "--------------------\n",
      "Testing combination 50/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4274\n",
      "--------------------\n",
      "Testing combination 51/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4271\n",
      "--------------------\n",
      "Testing combination 52/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4275\n",
      "--------------------\n",
      "Testing combination 53/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4279\n",
      "--------------------\n",
      "Testing combination 54/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4272\n",
      "--------------------\n",
      "Testing combination 55/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4276\n",
      "--------------------\n",
      "Testing combination 56/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4272\n",
      "--------------------\n",
      "Testing combination 57/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4275\n",
      "--------------------\n",
      "Testing combination 58/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 0.5, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4275\n",
      "--------------------\n",
      "Testing combination 59/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4275\n",
      "--------------------\n",
      "Testing combination 60/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4274\n",
      "--------------------\n",
      "Testing combination 61/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4272\n",
      "--------------------\n",
      "Testing combination 62/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4274\n",
      "--------------------\n",
      "Testing combination 63/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4272\n",
      "--------------------\n",
      "Testing combination 64/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4257\n",
      "--------------------\n",
      "Testing combination 65/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4265\n",
      "--------------------\n",
      "Testing combination 66/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4260\n",
      "--------------------\n",
      "Testing combination 67/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4260\n",
      "--------------------\n",
      "Testing combination 68/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4258\n",
      "--------------------\n",
      "Testing combination 69/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4256\n",
      "--------------------\n",
      "Testing combination 70/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4255\n",
      "--------------------\n",
      "Testing combination 71/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4265\n",
      "--------------------\n",
      "Testing combination 72/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4254\n",
      "--------------------\n",
      "Testing combination 73/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4257\n",
      "--------------------\n",
      "Testing combination 74/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4263\n",
      "--------------------\n",
      "Testing combination 75/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4257\n",
      "--------------------\n",
      "Testing combination 76/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.5, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4248\n",
      "--------------------\n",
      "Testing combination 77/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4251\n",
      "--------------------\n",
      "Testing combination 78/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4244\n",
      "--------------------\n",
      "Testing combination 79/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4244\n",
      "--------------------\n",
      "Testing combination 80/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4249\n",
      "--------------------\n",
      "Testing combination 81/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.01, 'subsample': 0.9, 'colsample_bytree': 0.9, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4250\n",
      "--------------------\n",
      "Testing combination 82/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4963\n",
      "New best score: 0.4963\n",
      "--------------------\n",
      "Testing combination 83/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4952\n",
      "--------------------\n",
      "Testing combination 84/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4975\n",
      "New best score: 0.4975\n",
      "--------------------\n",
      "Testing combination 85/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.5, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4963\n",
      "--------------------\n",
      "Testing combination 86/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4954\n",
      "--------------------\n",
      "Testing combination 87/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4983\n",
      "New best score: 0.4983\n",
      "--------------------\n",
      "Testing combination 88/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4958\n",
      "--------------------\n",
      "Testing combination 89/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4945\n",
      "--------------------\n",
      "Testing combination 90/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4957\n",
      "--------------------\n",
      "Testing combination 91/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4957\n",
      "--------------------\n",
      "Testing combination 92/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4945\n",
      "--------------------\n",
      "Testing combination 93/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4962\n",
      "--------------------\n",
      "Testing combination 94/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4978\n",
      "--------------------\n",
      "Testing combination 95/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4977\n",
      "--------------------\n",
      "Testing combination 96/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4955\n",
      "--------------------\n",
      "Testing combination 97/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4969\n",
      "--------------------\n",
      "Testing combination 98/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4945\n",
      "--------------------\n",
      "Testing combination 99/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4956\n",
      "--------------------\n",
      "Testing combination 100/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4956\n",
      "--------------------\n",
      "Testing combination 101/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4953\n",
      "--------------------\n",
      "Testing combination 102/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4988\n",
      "New best score: 0.4988\n",
      "--------------------\n",
      "Testing combination 103/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.5, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4978\n",
      "--------------------\n",
      "Testing combination 104/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4976\n",
      "--------------------\n",
      "Testing combination 105/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4963\n",
      "--------------------\n",
      "Testing combination 106/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4968\n",
      "--------------------\n",
      "Testing combination 107/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4960\n",
      "--------------------\n",
      "Testing combination 108/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.7, 'colsample_bytree': 0.9, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4954\n",
      "--------------------\n",
      "Testing combination 109/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4939\n",
      "--------------------\n",
      "Testing combination 110/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4931\n",
      "--------------------\n",
      "Testing combination 111/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4949\n",
      "--------------------\n",
      "Testing combination 112/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.5, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4947\n",
      "--------------------\n",
      "Testing combination 113/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4950\n",
      "--------------------\n",
      "Testing combination 114/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4959\n",
      "--------------------\n",
      "Testing combination 115/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4961\n",
      "--------------------\n",
      "Testing combination 116/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4964\n",
      "--------------------\n",
      "Testing combination 117/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4962\n",
      "--------------------\n",
      "Testing combination 118/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4937\n",
      "--------------------\n",
      "Testing combination 119/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4946\n",
      "--------------------\n",
      "Testing combination 120/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4937\n",
      "--------------------\n",
      "Testing combination 121/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4931\n",
      "--------------------\n",
      "Testing combination 122/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4951\n",
      "--------------------\n",
      "Testing combination 123/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4952\n",
      "--------------------\n",
      "Testing combination 124/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4972\n",
      "--------------------\n",
      "Testing combination 125/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4960\n",
      "--------------------\n",
      "Testing combination 126/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4952\n",
      "--------------------\n",
      "Testing combination 127/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4930\n",
      "--------------------\n",
      "Testing combination 128/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4949\n",
      "--------------------\n",
      "Testing combination 129/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4937\n",
      "--------------------\n",
      "Testing combination 130/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.5, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4947\n",
      "--------------------\n",
      "Testing combination 131/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.5, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4924\n",
      "--------------------\n",
      "Testing combination 132/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 0.5, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4948\n",
      "--------------------\n",
      "Testing combination 133/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4959\n",
      "--------------------\n",
      "Testing combination 134/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4955\n",
      "--------------------\n",
      "Testing combination 135/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4958\n",
      "--------------------\n",
      "Testing combination 136/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Validation Balanced Accuracy: 0.4926\n",
      "--------------------\n",
      "Testing combination 137/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 0.5}\n",
      "Validation Balanced Accuracy: 0.4947\n",
      "--------------------\n",
      "Testing combination 138/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 0.1, 'reg_lambda': 1}\n",
      "Validation Balanced Accuracy: 0.4941\n",
      "--------------------\n",
      "Testing combination 139/2187: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.05, 'subsample': 0.9, 'colsample_bytree': 0.7, 'reg_alpha': 0.5, 'reg_lambda': 0.1}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 65\u001b[0m\n\u001b[0;32m     54\u001b[0m param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m800\u001b[39m],\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m9\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreg_lambda\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     62\u001b[0m }\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# 执行网格搜索\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m best_params, best_score \u001b[38;5;241m=\u001b[39m \u001b[43mgrid_search_xgb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_params)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Validation Balanced Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 37\u001b[0m, in \u001b[0;36mgrid_search_xgb\u001b[1;34m(X_train, y_train, param_grid)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting combination \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_combinations\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcurrent_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m xgb_clf \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[0;32m     28\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmulti:softprob\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     29\u001b[0m     num_class\u001b[38;5;241m=\u001b[39mnum_classes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcurrent_params\n\u001b[0;32m     35\u001b[0m )\n\u001b[1;32m---> 37\u001b[0m \u001b[43mxgb_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m xgb_clf\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m     40\u001b[0m score \u001b[38;5;241m=\u001b[39m balanced_accuracy_score(y_val, y_pred)\n",
      "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\xgboost\\sklearn.py:1531\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1511\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m   1512\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1513\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1514\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1528\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1529\u001b[0m )\n\u001b[1;32m-> 1531\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1539\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1540\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1541\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1546\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32me:\\Softwares\\Anaconda\\CondaEnvs\\casual\\lib\\site-packages\\xgboost\\core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2100\u001b[0m     _check_call(\n\u001b[1;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2104\u001b[0m     )\n\u001b[0;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "\n",
    "# 创建训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "def grid_search_xgb(X_train, y_train, param_grid):\n",
    "    # 将训练集进一步拆分为训练集和验证集\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=0.2, random_state=42)\n",
    "    \n",
    "    num_classes = y_train.nunique()\n",
    "    best_score = 0\n",
    "    best_params = {}\n",
    "    \n",
    "    # 生成所有参数组合\n",
    "    param_combinations = list(product(*param_grid.values()))\n",
    "    total_combinations = len(param_combinations)\n",
    "    \n",
    "    for i, params in enumerate(param_combinations, 1):\n",
    "        current_params = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Testing combination {i}/{total_combinations}: {current_params}\")\n",
    "        \n",
    "        xgb_clf = XGBClassifier(\n",
    "            objective='multi:softprob',\n",
    "            num_class=num_classes,\n",
    "            eval_metric='mlogloss',\n",
    "            use_label_encoder=False,\n",
    "            tree_method='gpu_hist',\n",
    "            verbosity=0,\n",
    "            **current_params\n",
    "        )\n",
    "        \n",
    "        xgb_clf.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=False)\n",
    "        \n",
    "        y_pred = xgb_clf.predict(X_val)\n",
    "        score = balanced_accuracy_score(y_val, y_pred)\n",
    "        \n",
    "        print(f\"Validation Balanced Accuracy: {score:.4f}\")\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_params = current_params\n",
    "            print(f\"New best score: {best_score:.4f}\")\n",
    "        \n",
    "        print(\"--------------------\")\n",
    "    \n",
    "    return best_params, best_score\n",
    "\n",
    "# 定义参数网格\n",
    "param_grid = {\n",
    "    'n_estimators': [300, 500, 800],\n",
    "    'max_depth': [5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'reg_alpha': [0.1, 0.5, 1],\n",
    "    'reg_lambda': [0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "# 执行网格搜索\n",
    "best_params, best_score = grid_search_xgb(X_train, y_train, param_grid)\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(f\"Best Validation Balanced Accuracy: {best_score:.4f}\")\n",
    "\n",
    "# 使用最佳参数训练最终模型\n",
    "final_model = XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=y_train.nunique(),\n",
    "    eval_metric='mlogloss',\n",
    "    use_label_encoder=False,\n",
    "    tree_method='gpu_hist',\n",
    "    verbosity=1,\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "print(\"Training final model with best parameters...\")\n",
    "final_model.fit(X_train, y_train, verbose=True)\n",
    "\n",
    "# 在测试集上评估最终模型\n",
    "y_pred = final_model.predict(X_test)\n",
    "final_score = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"Final Test Balanced Accuracy: {final_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "casual",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
