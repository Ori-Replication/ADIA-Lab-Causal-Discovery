{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "import sys\n",
    "import typing\n",
    "import random\n",
    "import joblib\n",
    "import dcor\n",
    "import math\n",
    "from math import ceil, log, sqrt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "from copy import deepcopy\n",
    "import scipy.stats as stats\n",
    "import scipy.special as special\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import GridSearchCV, GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import Ridge, LinearRegression, LassoCV\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "from collections import Counter, defaultdict\n",
    "from econml.dml import CausalForestDML, LinearDML\n",
    "from causallearn.graph.GraphNode import GraphNode\n",
    "from causallearn.utils.PCUtils.BackgroundKnowledge import BackgroundKnowledge\n",
    "from causallearn.search.ConstraintBased.PC import pc\n",
    "from causallearn.search.ScoreBased.ExactSearch import bic_exact_search\n",
    "from causallearn.search.ConstraintBased.FCI import fci\n",
    "from causallearn.search.PermutationBased.GRaSP import grasp\n",
    "import semopy\n",
    "from semopy import Model\n",
    "from semopy.inspector import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Cloud的工具函数\"\"\"\n",
    "def log2(n):\n",
    "    return log(n or 1, 2)\n",
    "\n",
    "def C_MN(n: int, K: int):\n",
    "    \"\"\"Computes the normalizing term of NML distribution recursively. O(n+K)\n",
    "\n",
    "    For more detail, please refer to eq (19) (Theorem1) in\n",
    "    \"NML Computation Algorithms for Tree-Structured Multinomial Bayesian Networks\"\n",
    "    https://pubmed.ncbi.nlm.nih.gov/18382603/\n",
    "\n",
    "    and algorithm 2 in\n",
    "    \"Computing the Multinomial Stochastic Complexity in Sub-Linear Time\"\n",
    "    http://pgm08.cs.aau.dk/Papers/31_Paper.pdf\n",
    "\n",
    "\n",
    "    Args\n",
    "    ----------\n",
    "        n (int): sample size of a dataset\n",
    "        K (int): K-value multinomal distribution\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        float: (Approximated) Multinomal Normalizing Sum\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    total = 1\n",
    "    b = 1\n",
    "    d = 10 # 10 digit precision\n",
    "\n",
    "    #bound = int(ceil(2 + sqrt( -2 * n * np.log(2 * 10**(-d) - 100 ** (-d)))))\n",
    "    bound = int(ceil(2 + sqrt(2 * n * d * log(10))))  # using equation (38)\n",
    "\n",
    "    for k in range(1, bound + 1):\n",
    "        b = (n - k + 1) / n * b\n",
    "        total += b\n",
    "\n",
    "    log_old_sum = log2(1.0)\n",
    "    log_total = log2(total)\n",
    "    log_n = log2(n)\n",
    "    for j in range(3, K + 1):\n",
    "        log_x = log_n + log_old_sum - log_total - log2(j - 2)\n",
    "        x = 2 ** log_x\n",
    "        log_one_plus_x = log2(1 + x)\n",
    "        log_new_sum = log_total + log_one_plus_x\n",
    "        log_old_sum = log_total\n",
    "        log_total = log_new_sum\n",
    "\n",
    "    if K == 1:\n",
    "        log_total = log2(1.0)\n",
    "\n",
    "    return log_total\n",
    "\n",
    "def parametric_complexity(X, Y, model_type: str, X_ndistinct_vals=None, Y_ndistinct_vals=None):\n",
    "    \"\"\"Computes the Parametric Complexity of Multinomals.\n",
    "\n",
    "    Args\n",
    "    ----------\n",
    "        model_type (str): [\"to\", \"gets\", \"indep\", \"confounder\"]\n",
    "        X (sequence): sequence of discrete outcomes\n",
    "        Y (sequence): sequence of discrete outcomes\n",
    "        X_ndistinct_vals (int): number of distinct values of the multinomial r.v X.\n",
    "        Y_ndistinct_vals (int): number of distinct values of the multinomial r.v Y.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        float: Parametric Complexity of Multinomals\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    assert len(X)==len(Y)\n",
    "    n = len(X)\n",
    "    X_ndistinct_vals = X_ndistinct_vals or len(set(X))\n",
    "    Y_ndistinct_vals = Y_ndistinct_vals or len(set(Y))\n",
    "\n",
    "\n",
    "    if model_type == \"confounder\":\n",
    "        return  C_MN(n=n, K=X_ndistinct_vals * Y_ndistinct_vals)\n",
    "\n",
    "    else:\n",
    "        return  C_MN(n=n, K=X_ndistinct_vals) + C_MN(n=n, K=Y_ndistinct_vals)\n",
    "\n",
    "# ref: https://github.molgen.mpg.de/EDA/cisc/blob/master/formatter.py\n",
    "def stratify(X, Y):\n",
    "    \"\"\"Stratifies Y based on unique values of X.\n",
    "    Args:\n",
    "        X (sequence): sequence of discrete outcomes\n",
    "        Y (sequence): sequence of discrete outcomes\n",
    "    Returns:\n",
    "        (dict): list of Y-values for a X-value\n",
    "    \"\"\"\n",
    "    Y_grps = defaultdict(list)\n",
    "    for i, x in enumerate(X):\n",
    "        Y_grps[x].append(Y[i])\n",
    "    return Y_grps\n",
    "\n",
    "def map_to_majority(X, Y):\n",
    "    \"\"\"Creates a function that maps x to most frequent y.\n",
    "    Args:\n",
    "        X (sequence): sequence of discrete outcomes\n",
    "        Y (sequence): sequence of discrete outcomes\n",
    "    Returns:\n",
    "        (dict): map from Y-values to frequently co-occuring X-values\n",
    "    \"\"\"\n",
    "    f = dict()\n",
    "    Y_grps = stratify(X, Y)\n",
    "    for x, Ys in Y_grps.items():\n",
    "        frequent_y, _ = Counter(Ys).most_common(1)[0]\n",
    "        f[x] = frequent_y\n",
    "    return f\n",
    "\n",
    "def update_regression(C, E, f, max_niterations=1000):\n",
    "    \"\"\"Update discrete regression with C as a cause variable and Y as a effect variable\n",
    "    so that it maximize likelihood\n",
    "    Args\n",
    "    -------\n",
    "        C (sequence): sequence of discrete outcomes\n",
    "        E (sequence): sequence of discrete outcomes\n",
    "        f (dict): map from C to Y\n",
    "\n",
    "    \"\"\"\n",
    "    supp_C = list(set(C))\n",
    "    supp_E = list(set(E))\n",
    "    mod_E = len(supp_E)\n",
    "    n = len(C)\n",
    "\n",
    "    # N_E's log likelihood\n",
    "    # optimize f to minimize N_E's log likelihood\n",
    "    cur_likelihood = 0\n",
    "    res = [(e - f[c]) % mod_E for c, e in zip(C, E)]\n",
    "    for freq in Counter(res).values():\n",
    "        cur_likelihood += freq * (log2(n) - log2(freq))\n",
    "\n",
    "    j = 0\n",
    "    minimized = True\n",
    "    while j < max_niterations and minimized:\n",
    "        minimized = False\n",
    "\n",
    "        for c_to_map in supp_C:\n",
    "            best_likelihood = sys.float_info.max\n",
    "            best_e = None\n",
    "\n",
    "            for cand_e in supp_E:\n",
    "                if cand_e == f[c_to_map]:\n",
    "                    continue\n",
    "\n",
    "                f_ = f.copy()\n",
    "                f_[c_to_map] = cand_e\n",
    "\n",
    "                \"\"\"\n",
    "                if len(set(f_.values())) == 1:\n",
    "                    continue\n",
    "                \"\"\"\n",
    "\n",
    "                neglikelihood = 0\n",
    "                res = [(e - f_[c]) % mod_E for c, e in zip(C, E)]\n",
    "                for freq in Counter(res).values():\n",
    "                    neglikelihood += freq * (log2(n) - log2(freq))\n",
    "\n",
    "                if neglikelihood < best_likelihood:\n",
    "                    best_likelihood = neglikelihood\n",
    "                    best_e = cand_e\n",
    "\n",
    "            if best_likelihood < cur_likelihood:\n",
    "                cur_likelihood = best_likelihood\n",
    "                f[c_to_map] = best_e\n",
    "                minimized = True\n",
    "        j += 1\n",
    "\n",
    "    return f\n",
    "\n",
    "def cause_effect_negloglikelihood(C, E, func):\n",
    "    \"\"\"Compute negative log likelihood for cause & effect pair.\n",
    "    Model type : C→E\n",
    "\n",
    "    Args\n",
    "    -------\n",
    "        C (sequence): sequence of discrete outcomes (Cause)\n",
    "        E (sequence): sequence of discrete outcomes (Effect)\n",
    "        func (dict): map from C-value to E-value\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        (float): maximum log likelihood\n",
    "    \"\"\"\n",
    "    mod_C = len(set(C))\n",
    "    mod_E = len(set(E))\n",
    "    supp_C = list(set(C))\n",
    "    supp_E = list(set(E))\n",
    "\n",
    "    C_freqs = Counter(C)\n",
    "    n = len(C)\n",
    "\n",
    "    pair_cnt = defaultdict(lambda: defaultdict(int))\n",
    "    for c, e in zip(C, E):\n",
    "        pair_cnt[c][e] += 1\n",
    "\n",
    "    loglikelihood = 0\n",
    "\n",
    "    for freq in C_freqs.values():\n",
    "        loglikelihood += freq * (log2(n) - log2(freq))\n",
    "\n",
    "    for e_E in supp_E:\n",
    "        freq = 0\n",
    "        for e in supp_E:\n",
    "            for c in supp_C:\n",
    "                if (func[c] + e_E) % mod_E == e:\n",
    "                    freq += pair_cnt[c][e]\n",
    "        loglikelihood += freq * (log2(n) - log2(freq))\n",
    "\n",
    "    return loglikelihood\n",
    "\n",
    "def neg_log_likelihood(X, Y, model_type):\n",
    "    \"\"\"Compute negative maximum log-likelihood of the model given observations z^n.\n",
    "\n",
    "    Args\n",
    "    ------\n",
    "        X (sequence): sequence of discrete outcomes\n",
    "        Y (sequence): sequence of discrete outcomes\n",
    "        model_type (str): one of [\"to\", \"gets\", \"indep\", \"confounder\"]\n",
    "        f (dict): map from Y-values to frequently co-occuring X-values\n",
    "    Returns\n",
    "    -----------\n",
    "        (float): (negative) maximum log likelihood\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(X)\n",
    "    loglikelihood = 0\n",
    "\n",
    "    if model_type == \"to\":\n",
    "        f = map_to_majority(X, Y)\n",
    "        f = update_regression(X, Y, f)\n",
    "        loglikelihood = cause_effect_negloglikelihood(X, Y, f)\n",
    "\n",
    "    elif model_type == \"gets\":\n",
    "        g = map_to_majority(Y, X)\n",
    "        g = update_regression(Y, X, g)\n",
    "        loglikelihood = cause_effect_negloglikelihood(Y, X, g)\n",
    "\n",
    "    elif model_type == \"indep\":\n",
    "        X_freqs = Counter(X)\n",
    "        Y_freqs = Counter(Y)\n",
    "        for freq in X_freqs.values():\n",
    "            loglikelihood += freq * (log2(n) - log2(freq))\n",
    "        for freq in Y_freqs.values():\n",
    "            loglikelihood += freq * (log2(n) - log2(freq))\n",
    "\n",
    "    elif model_type == \"confounder\":\n",
    "        pair_cnt = defaultdict(lambda: defaultdict(int))\n",
    "        for x, y in zip(X, Y):\n",
    "            pair_cnt[x][y] += 1\n",
    "\n",
    "        for x in list(set(X)):\n",
    "            for y in list(set(Y)):\n",
    "                loglikelihood += pair_cnt[x][y] * (log2(n) - log2(pair_cnt[x][y]))\n",
    "\n",
    "    return loglikelihood\n",
    "\n",
    "def sc(X, Y, model_type: str, X_ndistinct_vals=None, Y_ndistinct_vals=None):\n",
    "    \"\"\"Computes the stochastic complexity of z^n(two discrete sequences).\n",
    "\n",
    "    Args\n",
    "    ------\n",
    "        X (sequence): sequence of discrete outcomes\n",
    "        Y (sequence): sequence of discrete outcomes\n",
    "        model_type (str): [\"to\", \"gets\", \"indep\", \"confounder\"]\n",
    "        X_ndistinct_vals (int): number of distinct values of the multinomial r.v X.\n",
    "        Y_ndistinct_vals (int): number of distinct values of the multinomial r.v Y.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        float: Stochastic Complexity of a given dataset\n",
    "    \"\"\"\n",
    "    assert len(X)==len(Y)\n",
    "    X_ndistinct_vals = X_ndistinct_vals or len(set(X))\n",
    "    Y_ndistinct_vals = Y_ndistinct_vals or len(set(Y))\n",
    "\n",
    "    data_cost =  neg_log_likelihood(X, Y, model_type)\n",
    "    model_cost = parametric_complexity(X, Y, model_type, X_ndistinct_vals, Y_ndistinct_vals)\n",
    "\n",
    "    stochastic_complexity = data_cost + model_cost\n",
    "\n",
    "    # add function code length\n",
    "    if model_type == \"to\":\n",
    "        stochastic_complexity += log2(Y_ndistinct_vals**(X_ndistinct_vals - 1) - 1)\n",
    "    elif model_type == \"gets\":\n",
    "        stochastic_complexity += log2(X_ndistinct_vals**(Y_ndistinct_vals - 1) - 1)\n",
    "\n",
    "    return stochastic_complexity\n",
    "\n",
    "def Cloud_print(score, llabel=\"X\", rlabel=\"Y\"):\n",
    "    score.sort(key=lambda x: x[0])\n",
    "    pred = score[0][1]\n",
    "    if pred == \"to\":\n",
    "        arrow = \"⇒\"\n",
    "    elif pred == \"gets\":\n",
    "        arrow = \"⇐\"\n",
    "    elif pred == \"indep\":\n",
    "        arrow = \"⫫\"\n",
    "    elif pred == \"confounder\":\n",
    "        arrow = \"⇐  C ⇒\"\n",
    "    conf = abs(score[0][0] - score[1][0])\n",
    "    out_str = \"Cloud Inference Result:: %s %s %s\\t Δ=%.2f\" % \\\n",
    "                          (llabel, arrow, rlabel, conf)\n",
    "    print(out_str)\n",
    "\n",
    "def Cloud(X, Y, n_candidates=4, is_print=False, X_ndistinct_vals=None, Y_ndistinct_vals=None):\n",
    "    \"\"\"main function in our study.\n",
    "    Cloud (Code Length-based method for Unobserved factor in Discrete data)\n",
    "\n",
    "    Args\n",
    "    ----------\n",
    "        X (sequence): sequence of discrete outcomes\n",
    "        Y (sequence): sequence of discrete outcomes\n",
    "        n_candidates (int): the number of model candidates\n",
    "        is_print (bool): whether or not to print inference result\n",
    "        X_ndistinct_vals (int): number of distinct values of the multinomial r.v X.\n",
    "        Y_ndistinct_vals (int): number of distinct values of the multinomial r.v Y.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "        (List) : each element is tuple that contains code length L(z^n, M) (float) and causal model' label (str)\n",
    "        \n",
    "    \"\"\"\n",
    "    if n_candidates == 4:\n",
    "        MODEL_CANDIDATES = [\"to\", \"gets\", \"indep\", \"confounder\"]\n",
    "    elif n_candidates == 2:\n",
    "        MODEL_CANDIDATES = [\"to\", \"gets\"]\n",
    "    else:\n",
    "        MODEL_CANDIDATES = [\"to\", \"gets\", \"indep\"]\n",
    "\n",
    "    # prepare data\n",
    "    le_X = LabelEncoder()\n",
    "    X = le_X.fit_transform(X)\n",
    "    le_Y = LabelEncoder()\n",
    "    Y = le_Y.fit_transform(Y)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for model_type in MODEL_CANDIDATES:\n",
    "        stochastic_complexity = sc(X, Y, model_type, X_ndistinct_vals, Y_ndistinct_vals)\n",
    "        results.append((stochastic_complexity, model_type))\n",
    "\n",
    "    if is_print:\n",
    "        Cloud_print(results)\n",
    "\n",
    "    return results\n",
    "\n",
    "def Cloud_output(score):\n",
    "    score.sort(key=lambda x: x[0])\n",
    "    pred = score[0][1]\n",
    "    conf = abs(score[0][0] - score[1][0])\n",
    "    return pred, conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def Cloud_feature(dataset):\n",
    "    variables = dataset.columns.drop([\"X\", \"Y\"])\n",
    "    X = discretize_sequence(dataset['X'].values, ffactor=10)\n",
    "    Y = discretize_sequence(dataset['Y'].values, ffactor=10)\n",
    "\n",
    "    df = []\n",
    "    for variable in variables:\n",
    "        v = discretize_sequence(dataset[variable].values, ffactor=10)\n",
    "\n",
    "        result_vX = Cloud(\n",
    "            X=v, \n",
    "            Y=X,\n",
    "            n_candidates=4, # select a set of model candidates\n",
    "            is_print=False, # print out inferred causal direction \n",
    "            X_ndistinct_vals=21,\n",
    "            Y_ndistinct_vals=21,\n",
    "        )\n",
    "        pred_vX, conf_vX = Cloud_output(result_vX)\n",
    "        result_vY = Cloud(\n",
    "            X=v, \n",
    "            Y=Y,\n",
    "            n_candidates=4, # select a set of model candidates\n",
    "            is_print=False, # print out inferred causal direction \n",
    "            X_ndistinct_vals=21,\n",
    "            Y_ndistinct_vals=21,\n",
    "        )\n",
    "        pred_vY, conf_vY = Cloud_output(result_vY)\n",
    "        df.append({\n",
    "            \"variable\": variable,\n",
    "            \"Cloud_to(v,X)\": result_vX[0][0],\n",
    "            \"Cloud_gets(v,X)\": result_vX[1][0],\n",
    "            \"Cloud_indep(v,X)\": result_vX[2][0],\n",
    "            \"Cloud_confounder(v,X)\": result_vX[3][0],\n",
    "            \"Cloud_pred(v,X)\": pred_vX,\n",
    "            \"Cloud_conf(v,X)\": conf_vX,\n",
    "            \"Cloud_to(v,Y)\": result_vY[0][0],\n",
    "            \"Cloud_gets(v,Y)\": result_vY[1][0],\n",
    "            \"Cloud_indep(v,Y)\": result_vY[2][0],\n",
    "            \"Cloud_confounder(v,Y)\": result_vY[3][0],\n",
    "            \"Cloud_pred(v,Y)\": pred_vY,\n",
    "            \"Cloud_conf(v,Y)\": conf_vY,\n",
    "        })\n",
    "\n",
    "    result_XY = Cloud(\n",
    "        X=X, \n",
    "        Y=Y,\n",
    "        n_candidates=4, # select a set of model candidates\n",
    "        is_print=False, # print out inferred causal direction \n",
    "        X_ndistinct_vals=21,\n",
    "        Y_ndistinct_vals=21,\n",
    "    )\n",
    "    pred_XY, conf_XY = Cloud_output(result_XY)\n",
    "    df[\"Cloud_to(X,Y)\"] = result_XY[0][0]\n",
    "    df[\"Cloud_gets(X,Y)\"] = result_XY[1][0]\n",
    "    df[\"Cloud_indep(X,Y)\"] = result_XY[2][0]\n",
    "    df[\"Cloud_confounder(X,Y)\"] = result_XY[3][0]\n",
    "    df[\"Cloud_pred(X,Y)\"] = pred_XY\n",
    "    df[\"Cloud_conf(X,Y)\"] = conf_XY\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    df[\"dataset\"] = dataset.name\n",
    "    \n",
    "    # Reorder columns:\n",
    "    df = df[[\"dataset\"] + [colname for colname in df.columns if colname != \"dataset\"]]\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
