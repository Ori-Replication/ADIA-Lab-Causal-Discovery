{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: gu guguoqin66@gmail.com\n",
    "Date: 2024-10-11 08:18:26\n",
    "LastEditors: gu guguoqin66@gmail.com\n",
    "LastEditTime: 2024-10-11 08:30:22\n",
    "FilePath: \\ADIA-Lab-Causal-Discovery\\try_catboost.ipynb\n",
    "Description: 这是默认设置,请设置`customMade`, 打开koroFileHeader查看配置 进行设置: https://github.com/OBKoro1/koro1FileHeader/wiki/%E9%85%8D%E7%BD%AE\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_feature_names(X):\n",
    "    # 函数用于清理特征名称\n",
    "    def clean_name(name):\n",
    "        # 移除或替换特殊字符\n",
    "        name = re.sub(r'[^\\w\\s-]', '_', name)\n",
    "        # 确保名称不以数字开头\n",
    "        if name and name[0].isdigit():\n",
    "            name = 'f_' + name\n",
    "        return name\n",
    "\n",
    "    X.columns = [clean_name(col) for col in X.columns]\n",
    "    return X\n",
    "\n",
    "def process_categorical_features(df, max_unique=10):\n",
    "    \"\"\"\n",
    "    检测和处理数据框中的类别变量。\n",
    "\n",
    "    参数：\n",
    "    - df (pd.DataFrame): 输入的数据框。\n",
    "    - max_unique (int): 判定为类别变量的最大唯一值数量。\n",
    "\n",
    "    返回：\n",
    "    - cat_idxs (list of int): 类别特征的索引。\n",
    "    - cat_dims (list of int): 每个类别特征的模态数。\n",
    "    - df (pd.DataFrame): 经过编码后的数据框。\n",
    "    \"\"\"\n",
    "    cat_cols = [col for col in df.columns if df[col].nunique() <= max_unique]\n",
    "    cat_dims = []\n",
    "    cat_idxs = []\n",
    "\n",
    "    for col in cat_cols:\n",
    "        print(f\"处理类别特征: {col}，唯一值数量: {df[col].nunique()}\")\n",
    "        # 使用 LabelEncoder\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str).fillna('NaN'))\n",
    "        cat_dims.append(len(le.classes_))\n",
    "        cat_idxs.append(df.columns.get_loc(col))\n",
    "\n",
    "    return cat_idxs, cat_dims, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding numeric labels y\n",
      "Extracting X_train, y_train, and group\n",
      "处理类别特征: dimension，唯一值数量: 8\n",
      "处理类别特征: ExactSearch_v_X_，唯一值数量: 2\n",
      "处理类别特征: ExactSearch_X_v_，唯一值数量: 2\n",
      "处理类别特征: ExactSearch_v_Y_，唯一值数量: 2\n",
      "处理类别特征: ExactSearch_Y_v_，唯一值数量: 2\n",
      "处理类别特征: ExactSearch_X_Y_，唯一值数量: 2\n",
      "处理类别特征: PC_v_X_，唯一值数量: 2\n",
      "处理类别特征: PC_X_v_，唯一值数量: 2\n",
      "处理类别特征: PC_v_Y_，唯一值数量: 2\n",
      "处理类别特征: PC_Y_v_，唯一值数量: 2\n",
      "处理类别特征: PC_X_Y_，唯一值数量: 2\n",
      "处理类别特征: FCI_v_X_，唯一值数量: 4\n",
      "处理类别特征: FCI_X_v_，唯一值数量: 4\n",
      "处理类别特征: FCI_v_Y_，唯一值数量: 4\n",
      "处理类别特征: FCI_Y_v_，唯一值数量: 4\n",
      "处理类别特征: FCI_X_Y_，唯一值数量: 4\n",
      "处理类别特征: GRaSP_v_X_，唯一值数量: 3\n",
      "处理类别特征: GRaSP_X_v_，唯一值数量: 3\n",
      "处理类别特征: GRaSP_v_Y_，唯一值数量: 3\n",
      "处理类别特征: GRaSP_Y_v_，唯一值数量: 3\n",
      "处理类别特征: GRaSP_X_Y_，唯一值数量: 3\n",
      "类别特征索引 (cat_idxs): [0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 137, 138, 139, 140, 141]\n",
      "类别特征模态数 (cat_dims): [8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3]\n",
      "y_train 唯一值: [0 1 2 3 4 5 6 7]\n",
      "y_test 唯一值: [0 1 2 3 4 5 6 7]\n",
      "类别权重: [1.450715663384428, 0.6722329366386002, 3.281515499425947, 1.975532209012994, 0.9026654876200101, 2.093305990918412, 0.32411040301181593, 2.930285011277425]\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "X_y_group_train = pd.read_csv('./mid_data/X_y_group_train_updated_v13.4_rolling.csv')\n",
    "\n",
    "print(\"Adding numeric labels y\")\n",
    "le = LabelEncoder()\n",
    "X_y_group_train[\"y\"] = le.fit_transform(X_y_group_train[\"label\"])\n",
    "# 重新排列列\n",
    "X_y_group_train = X_y_group_train[[\"dataset\", \"variable\"] + X_y_group_train.columns.drop([\"dataset\", \"variable\", \"label\", \"y\"]).tolist() + [\"label\", \"y\"]]\n",
    "\n",
    "# 定义要删除的列\n",
    "blacklist = [\n",
    "    \"ttest(v,X)\", \n",
    "    \"pvalue(ttest(v,X))<=0.05\", \n",
    "    \"ttest(v,Y)\", \n",
    "    \"pvalue(ttest(v,Y))<=0.05\", \n",
    "    \"ttest(X,Y)\", \n",
    "    \"pvalue(ttest(X,Y))<=0.05\",\n",
    "    \"square_dimension\", \n",
    "    \"max(PPS(v,others))\",\n",
    "    \"TLI_Collider\",\n",
    "    \"TLI_Confounder\",\n",
    "    \"RMSEA_Collider\",\n",
    "    \"RMSEA_Confounder\"\n",
    "]\n",
    "columns_to_drop = [col for col in blacklist if col in X_y_group_train.columns]\n",
    "X_y_group_train = X_y_group_train.drop(columns=columns_to_drop)\n",
    "\n",
    "# 处理数值列的缺失值\n",
    "numeric_columns = X_y_group_train.select_dtypes(include=[np.number]).columns\n",
    "X_y_group_train[numeric_columns] = X_y_group_train[numeric_columns].fillna(X_y_group_train[numeric_columns].mean())\n",
    "\n",
    "# 清理特征名称\n",
    "X_y_group_train = clean_feature_names(X_y_group_train)\n",
    "\n",
    "print(\"Extracting X_train, y_train, and group\")\n",
    "# 分离数据集ID、特征和标签\n",
    "group_train = X_y_group_train[\"dataset\"]\n",
    "X = X_y_group_train.drop([\"variable\", \"dataset\", \"label\", \"y\"], axis=\"columns\")\n",
    "y = X_y_group_train[\"y\"]\n",
    "\n",
    "# 处理类别特征\n",
    "cat_idxs, cat_dims, X = process_categorical_features(X)\n",
    "print(f\"类别特征索引 (cat_idxs): {cat_idxs}\")\n",
    "print(f\"类别特征模态数 (cat_dims): {cat_dims}\")\n",
    "\n",
    "# 分割数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"y_train 唯一值:\", np.unique(y_train))\n",
    "print(\"y_test 唯一值:\", np.unique(y_test))\n",
    "\n",
    "# 创建Pool对象\n",
    "train_pool = Pool(data=X_train, label=y_train, cat_features=cat_idxs)\n",
    "test_pool = Pool(data=X_test, label=y_test, cat_features=cat_idxs)\n",
    "\n",
    "# 计算类别权重（使用每个类别的逆频率）\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights = list(class_weights)  # 转换为列表\n",
    "print(f\"类别权重: {class_weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    learning_rate=0.05,\n",
    "\n",
    "    depth=5,\n",
    "\n",
    "    rsm=0.95,\n",
    "    \n",
    "    l2_leaf_reg=0.5,\n",
    "    model_size_reg=0.5,\n",
    "\n",
    "    classes_count=8,\n",
    "    class_weights=class_weights,\n",
    "    cat_features=cat_idxs,\n",
    "    random_seed=42,\n",
    "    loss_function='MultiClass',\n",
    "    eval_metric='Accuracy',\n",
    "    verbose=100,\n",
    "    early_stopping_rounds=20,\n",
    "    task_type='CPU',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.5276560\ttest: 0.5308194\tbest: 0.5308194 (0)\ttotal: 66.4ms\tremaining: 2m 12s\n",
      "100:\tlearn: 0.6031424\ttest: 0.5841631\tbest: 0.5842656 (99)\ttotal: 6.3s\tremaining: 1m 58s\n",
      "200:\tlearn: 0.6707128\ttest: 0.6293927\tbest: 0.6293927 (200)\ttotal: 12.7s\tremaining: 1m 53s\n",
      "300:\tlearn: 0.7135468\ttest: 0.6465055\tbest: 0.6472441 (298)\ttotal: 18.8s\tremaining: 1m 46s\n",
      "400:\tlearn: 0.7481693\ttest: 0.6571068\tbest: 0.6571945 (395)\ttotal: 25.1s\tremaining: 1m 40s\n",
      "500:\tlearn: 0.7748707\ttest: 0.6632151\tbest: 0.6634550 (489)\ttotal: 31.6s\tremaining: 1m 34s\n",
      "600:\tlearn: 0.7953285\ttest: 0.6670584\tbest: 0.6671641 (592)\ttotal: 37.4s\tremaining: 1m 27s\n",
      "700:\tlearn: 0.8145147\ttest: 0.6693153\tbest: 0.6700005 (693)\ttotal: 43.2s\tremaining: 1m 20s\n",
      "800:\tlearn: 0.8313484\ttest: 0.6717346\tbest: 0.6718357 (797)\ttotal: 48.1s\tremaining: 1m 12s\n",
      "900:\tlearn: 0.8464954\ttest: 0.6719383\tbest: 0.6735468 (886)\ttotal: 53.5s\tremaining: 1m 5s\n",
      "1000:\tlearn: 0.8589346\ttest: 0.6743321\tbest: 0.6744199 (990)\ttotal: 58.3s\tremaining: 58.1s\n",
      "bestTest = 0.6750162627\n",
      "bestIteration = 1033\n",
      "Shrink model to first 1034 iterations.\n",
      "训练集平衡准确率: 0.861525\n",
      "测试集平衡准确率: 0.675018\n",
      "测试集分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.71      0.65      2463\n",
      "           1       0.82      0.79      0.81      5315\n",
      "           2       0.49      0.59      0.54      1089\n",
      "           3       0.59      0.62      0.60      1809\n",
      "           4       0.70      0.67      0.68      3958\n",
      "           5       0.59      0.72      0.65      1706\n",
      "           6       0.89      0.82      0.85     11023\n",
      "           7       0.43      0.49      0.46      1219\n",
      "\n",
      "    accuracy                           0.74     28582\n",
      "   macro avg       0.64      0.68      0.65     28582\n",
      "weighted avg       0.75      0.74      0.75     28582\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = CatBoostClassifier(\n",
    "    iterations=2000,\n",
    "    learning_rate=0.05,\n",
    "    depth=7,\n",
    "    \n",
    "    l2_leaf_reg=0.1,\n",
    "    model_size_reg=0.1,\n",
    "    classes_count=8,\n",
    "    class_weights=class_weights,\n",
    "    cat_features=cat_idxs,\n",
    "    random_seed=42,\n",
    "    loss_function='MultiClass',\n",
    "    eval_metric='Accuracy',\n",
    "    verbose=100,\n",
    "    early_stopping_rounds=50,\n",
    "    task_type='GPU',\n",
    "    devices='0:1',  # 如果使用GPU,指定GPU设备\n",
    "    save_snapshot=False,\n",
    "    train_dir=\"./tmp\",\n",
    "    leaf_estimation_method='Newton',  # 默认方法\n",
    ")\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "model.fit(\n",
    "    train_pool,\n",
    "    eval_set=test_pool,\n",
    "    use_best_model=True\n",
    ")\n",
    "\n",
    "# 预测\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# 计算平衡准确率\n",
    "train_score = balanced_accuracy_score(y_train, y_train_pred)\n",
    "test_score = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"训练集平衡准确率: {train_score:.6f}\")\n",
    "print(f\"测试集平衡准确率: {test_score:.6f}\")\n",
    "\n",
    "# 打印分类报告\n",
    "print(\"测试集分类报告:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 获取特征重要性\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241m.\u001b[39mget_feature_importance()\n\u001b[0;32m      3\u001b[0m feature_names \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m      4\u001b[0m feature_importance_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_names,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimportance\u001b[39m\u001b[38;5;124m'\u001b[39m: feature_importances\n\u001b[0;32m      7\u001b[0m })\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimportance\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "# 获取特征重要性\n",
    "feature_importances = clf.get_feature_importance()\n",
    "feature_names = X_train.columns\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': feature_importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# 显示前20个重要特征\n",
    "print(feature_importance_df.head(20))\n",
    "\n",
    "# 绘制特征重要性图\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.barh(feature_importance_df['feature'][:20][::-1], feature_importance_df['importance'][:20][::-1])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 20 Feature Importances in CatBoost Model')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adia_py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
