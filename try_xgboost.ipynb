{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_columns_with_keywords(df, keywords):\n",
    "    columns_to_drop = [col for col in df.columns if any(keyword in col for keyword in keywords)]\n",
    "    return df.drop(columns=columns_to_drop)\n",
    "\n",
    "def get_columns_with_keywords(df, keywords):\n",
    "    columns_to_get = [col for col in df.columns if any(keyword in col for keyword in keywords)]\n",
    "    return columns_to_get\n",
    "\n",
    "def recovery_dataset_id(X_y_group_train):\n",
    "    # 假设'dataset'列是需要转换的列\n",
    "    X_y_group_train['dataset'] = X_y_group_train['dataset'].apply(lambda x: f'{int(x):05}')\n",
    "    return X_y_group_train\n",
    "\n",
    "def clean_feature_names(X):\n",
    "    # 函数用于清理特征名称\n",
    "    def clean_name(name):\n",
    "        # 移除或替换特殊字符\n",
    "        name = re.sub(r'[^\\w\\s-]', '_', name)\n",
    "        # 确保名称不以数字开头\n",
    "        if name and name[0].isdigit():\n",
    "            name = 'f_' + name\n",
    "        return name\n",
    "\n",
    "    X.columns = [clean_name(col) for col in X.columns]\n",
    "    return X\n",
    "\n",
    "def process_categorical_features(df, max_unique=10):\n",
    "    \"\"\"\n",
    "    检测和处理数据框中的类别变量。\n",
    "\n",
    "    参数：\n",
    "    - df (pd.DataFrame): 输入的数据框。\n",
    "    - max_unique (int): 判定为类别变量的最大唯一值数量。\n",
    "\n",
    "    返回：\n",
    "    - cat_idxs (list of int): 类别特征的索引。\n",
    "    - cat_dims (list of int): 每个类别特征的模态数。\n",
    "    - df (pd.DataFrame): 经过编码后的数据框。\n",
    "    \"\"\"\n",
    "    cat_cols = [col for col in df.columns if df[col].nunique() <= max_unique]\n",
    "    cat_dims = []\n",
    "    cat_idxs = []\n",
    "\n",
    "    for col in cat_cols:\n",
    "        print(f\"     处理类别特征: {col}，唯一值数量: {df[col].nunique()}\")\n",
    "        # 使用 LabelEncoder\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str).fillna('NaN'))\n",
    "        cat_dims.append(len(le.classes_))\n",
    "        cat_idxs.append(df.columns.get_loc(col))\n",
    "\n",
    "    return cat_idxs, cat_dims, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Adding numeric labels y\n",
      "##### Data Preprocessing...\n",
      "     删除多余列后样本量 (142910, 207)\n",
      "##### Extracting X_train, y_train, and group\n",
      "     处理类别特征: dimension，唯一值数量: 8\n",
      "     处理类别特征: ExactSearch_v_X_，唯一值数量: 2\n",
      "     处理类别特征: ExactSearch_X_v_，唯一值数量: 2\n",
      "     处理类别特征: ExactSearch_v_Y_，唯一值数量: 2\n",
      "     处理类别特征: ExactSearch_Y_v_，唯一值数量: 2\n",
      "     处理类别特征: ExactSearch_X_Y_，唯一值数量: 2\n",
      "     处理类别特征: PC_v_X_，唯一值数量: 2\n",
      "     处理类别特征: PC_X_v_，唯一值数量: 2\n",
      "     处理类别特征: PC_v_Y_，唯一值数量: 2\n",
      "     处理类别特征: PC_Y_v_，唯一值数量: 2\n",
      "     处理类别特征: PC_X_Y_，唯一值数量: 2\n",
      "     处理类别特征: FCI_v_X_，唯一值数量: 4\n",
      "     处理类别特征: FCI_X_v_，唯一值数量: 4\n",
      "     处理类别特征: FCI_v_Y_，唯一值数量: 4\n",
      "     处理类别特征: FCI_Y_v_，唯一值数量: 4\n",
      "     处理类别特征: FCI_X_Y_，唯一值数量: 4\n",
      "     处理类别特征: GRaSP_v_X_，唯一值数量: 3\n",
      "     处理类别特征: GRaSP_X_v_，唯一值数量: 3\n",
      "     处理类别特征: GRaSP_v_Y_，唯一值数量: 3\n",
      "     处理类别特征: GRaSP_Y_v_，唯一值数量: 3\n",
      "     处理类别特征: GRaSP_X_Y_，唯一值数量: 3\n",
      "     类别特征索引 (cat_idxs): [0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 137, 138, 139, 140, 141]\n",
      "     类别特征模态数 (cat_dims): [8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3]\n",
      "     分割数据集后X_train & X_test shape: (114328, 203) (28582, 203)\n",
      "     y_train 唯一值: [0 1 2 3 4 5 6 7]\n",
      "     y_test 唯一值: [0 1 2 3 4 5 6 7]\n",
      "类别权重: [1.450715663384428, 0.6722329366386002, 3.281515499425947, 1.975532209012994, 0.9026654876200101, 2.093305990918412, 0.32411040301181593, 2.930285011277425]\n"
     ]
    }
   ],
   "source": [
    "X_y_group_train = pd.read_csv('mid_data/X_y_group_train_updated_v13.4_rolling.csv')\n",
    "\n",
    "print(\"##### Adding numeric labels y\")\n",
    "# 添加数值标签 y\n",
    "le = LabelEncoder()\n",
    "X_y_group_train[\"y\"] = le.fit_transform(X_y_group_train[\"label\"])\n",
    "# 重新排列列\n",
    "X_y_group_train = X_y_group_train[[\"dataset\", \"variable\"] + X_y_group_train.columns.drop([\"dataset\", \"variable\", \"label\", \"y\"]).tolist() + [\"label\", \"y\"]]\n",
    "\n",
    "print(\"##### Data Preprocessing...\")\n",
    "# 定义要删除的列\n",
    "blacklist = [\n",
    "    \"ttest(v,X)\", \n",
    "    \"pvalue(ttest(v,X))<=0.05\", \n",
    "    \"ttest(v,Y)\", \n",
    "    \"pvalue(ttest(v,Y))<=0.05\", \n",
    "    \"ttest(X,Y)\", \n",
    "    \"pvalue(ttest(X,Y))<=0.05\",\n",
    "    \"square_dimension\", \n",
    "    \"max(PPS(v,others))\",\n",
    "    \"TLI_Collider\",\n",
    "    \"TLI_Confounder\",\n",
    "    \"RMSEA_Collider\",\n",
    "    \"RMSEA_Confounder\",\n",
    "    # \"RMSEA_Cause of Y\",\n",
    "]\n",
    "columns_to_drop = [col for col in blacklist if col in X_y_group_train.columns]\n",
    "X_y_group_train = X_y_group_train.drop(columns=columns_to_drop)\n",
    "print('     删除多余列后样本量', X_y_group_train.shape)\n",
    "\n",
    "# 处理无穷值：转换为NaN\n",
    "X_y_group_train = X_y_group_train.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# 处理数值列的缺失值\n",
    "numeric_columns = X_y_group_train.select_dtypes(include=[np.number]).columns\n",
    "X_y_group_train[numeric_columns] = X_y_group_train[numeric_columns].fillna(X_y_group_train[numeric_columns].mean())\n",
    "\n",
    "# 清理特征名称\n",
    "X_y_group_train = clean_feature_names(X_y_group_train)\n",
    "\n",
    "print(\"##### Extracting X_train, y_train, and group\")\n",
    "# 分离数据集ID、特征和标签\n",
    "group_train = X_y_group_train[\"dataset\"]\n",
    "X = X_y_group_train.drop([\"variable\", \"dataset\", \"label\", \"y\"], axis=\"columns\")\n",
    "y = X_y_group_train[\"y\"]\n",
    "\n",
    "# 处理类别特征\n",
    "cat_idxs, cat_dims, X = process_categorical_features(X)\n",
    "print(f\"     类别特征索引 (cat_idxs): {cat_idxs}\")\n",
    "print(f\"     类别特征模态数 (cat_dims): {cat_dims}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"     分割数据集后X_train & X_test shape:\", X_train.shape, X_test.shape)\n",
    "print(\"     y_train 唯一值:\", np.unique(y_train))\n",
    "print(\"     y_test 唯一值:\", np.unique(y_test))\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights = list(class_weights)  # 转换为列表\n",
    "print(f\"类别权重: {class_weights}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Training XGBoost model\n",
      "[0]\ttrain-mlogloss:2.01973\ttest-mlogloss:2.00699\n",
      "[100]\ttrain-mlogloss:1.05900\ttest-mlogloss:0.95913\n",
      "[200]\ttrain-mlogloss:0.91333\ttest-mlogloss:0.86587\n",
      "[300]\ttrain-mlogloss:0.83154\ttest-mlogloss:0.82299\n",
      "[400]\ttrain-mlogloss:0.77205\ttest-mlogloss:0.79654\n",
      "[500]\ttrain-mlogloss:0.72327\ttest-mlogloss:0.77691\n",
      "[600]\ttrain-mlogloss:0.68188\ttest-mlogloss:0.76221\n",
      "[700]\ttrain-mlogloss:0.64579\ttest-mlogloss:0.75060\n",
      "[800]\ttrain-mlogloss:0.61307\ttest-mlogloss:0.74007\n",
      "[900]\ttrain-mlogloss:0.58374\ttest-mlogloss:0.73147\n",
      "[1000]\ttrain-mlogloss:0.55650\ttest-mlogloss:0.72422\n",
      "[1100]\ttrain-mlogloss:0.53170\ttest-mlogloss:0.71781\n",
      "[1200]\ttrain-mlogloss:0.50895\ttest-mlogloss:0.71211\n",
      "[1300]\ttrain-mlogloss:0.48801\ttest-mlogloss:0.70729\n",
      "[1400]\ttrain-mlogloss:0.46804\ttest-mlogloss:0.70254\n",
      "[1500]\ttrain-mlogloss:0.44972\ttest-mlogloss:0.69850\n",
      "[1600]\ttrain-mlogloss:0.43220\ttest-mlogloss:0.69501\n",
      "[1700]\ttrain-mlogloss:0.41594\ttest-mlogloss:0.69138\n",
      "[1800]\ttrain-mlogloss:0.40057\ttest-mlogloss:0.68836\n",
      "[1900]\ttrain-mlogloss:0.38634\ttest-mlogloss:0.68546\n",
      "[1999]\ttrain-mlogloss:0.37299\ttest-mlogloss:0.68280\n",
      "Training set balanced accuracy: 0.922416\n",
      "Test set balanced accuracy: 0.678340\n",
      "Test set classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.71      0.66      2463\n",
      "           1       0.83      0.81      0.82      5315\n",
      "           2       0.51      0.58      0.54      1089\n",
      "           3       0.60      0.61      0.61      1809\n",
      "           4       0.69      0.69      0.69      3958\n",
      "           5       0.63      0.72      0.67      1706\n",
      "           6       0.90      0.84      0.87     11023\n",
      "           7       0.43      0.47      0.45      1219\n",
      "\n",
      "    accuracy                           0.75     28582\n",
      "   macro avg       0.65      0.68      0.66     28582\n",
      "weighted avg       0.76      0.75      0.76     28582\n",
      "\n",
      "Model saved as 'xgboost_model.json'\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "print(\"##### Training XGBoost model\")\n",
    "# Create DMatrix for XGBoost\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "weight_dict = dict(zip(classes, class_weights))\n",
    "sample_weights = y_train.map(weight_dict)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, weight=sample_weights)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set up XGBoost parameters\n",
    "params = {\n",
    "    'max_depth': 5,\n",
    "    'eta': 0.05,\n",
    "    'objective': 'multi:softmax',\n",
    "    'num_class': 8,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0.3,\n",
    "    'lambda': 10,\n",
    "    'alpha': 10,\n",
    "    'device': 'cuda',  \n",
    "    'max_delta_step': 0.5\n",
    "}\n",
    "\n",
    "# Train XGBoost model\n",
    "model = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_boost_round=2000,\n",
    "    evals=[(dtrain, 'train'), (dtest, 'test')],\n",
    "    early_stopping_rounds=50,\n",
    "    verbose_eval=100\n",
    ")\n",
    "\n",
    "# Predict\n",
    "y_train_pred = model.predict(dtrain)\n",
    "y_test_pred = model.predict(dtest)\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "train_score = balanced_accuracy_score(y_train, y_train_pred)\n",
    "test_score = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Training set balanced accuracy: {train_score:.6f}\")\n",
    "print(f\"Test set balanced accuracy: {test_score:.6f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Test set classification report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Save the model\n",
    "model.save_model('xgboost_model.json')\n",
    "print(\"Model saved as 'xgboost_model.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Adding numeric labels y\n",
      "##### Data Preprocessing...\n",
      "     1.删除多余列后样本量 (142910, 207)\n",
      "     2.填充缺失值后样本量 (142910, 207)\n",
      "     3.清理特征名称后样本量 (142910, 207)\n",
      "##### Extracting X_train, y_train\n",
      "     处理类别特征: dimension，唯一值数量: 8\n",
      "     处理类别特征: ExactSearch_v_X_，唯一值数量: 2\n",
      "     处理类别特征: ExactSearch_X_v_，唯一值数量: 2\n",
      "     处理类别特征: ExactSearch_v_Y_，唯一值数量: 2\n",
      "     处理类别特征: ExactSearch_Y_v_，唯一值数量: 2\n",
      "     处理类别特征: ExactSearch_X_Y_，唯一值数量: 2\n",
      "     处理类别特征: PC_v_X_，唯一值数量: 2\n",
      "     处理类别特征: PC_X_v_，唯一值数量: 2\n",
      "     处理类别特征: PC_v_Y_，唯一值数量: 2\n",
      "     处理类别特征: PC_Y_v_，唯一值数量: 2\n",
      "     处理类别特征: PC_X_Y_，唯一值数量: 2\n",
      "     处理类别特征: FCI_v_X_，唯一值数量: 4\n",
      "     处理类别特征: FCI_X_v_，唯一值数量: 4\n",
      "     处理类别特征: FCI_v_Y_，唯一值数量: 4\n",
      "     处理类别特征: FCI_Y_v_，唯一值数量: 4\n",
      "     处理类别特征: FCI_X_Y_，唯一值数量: 4\n",
      "     处理类别特征: GRaSP_v_X_，唯一值数量: 3\n",
      "     处理类别特征: GRaSP_X_v_，唯一值数量: 3\n",
      "     处理类别特征: GRaSP_v_Y_，唯一值数量: 3\n",
      "     处理类别特征: GRaSP_Y_v_，唯一值数量: 3\n",
      "     处理类别特征: GRaSP_X_Y_，唯一值数量: 3\n",
      "     ->类别特征索引 (cat_idxs): [0, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 137, 138, 139, 140, 141]\n",
      "     ->类别特征模态数 (cat_dims): [8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3]\n",
      "     4.处理类别特征后样本量 (142910, 203) (142910,)\n",
      "##### Extracting X_train, y_train, and group\n",
      "     5.分割数据集后样本量: (128619, 203) (14291, 203) (128619,) (14291,)\n",
      "     ->y_train 唯一值: [0 1 2 3 4 5 6 7]\n",
      "     ->y_test 唯一值: [0 1 2 3 4 5 6 7]\n",
      "##### Computing class weights\n",
      "     ->分类目标权重列表: [1.9753501658680428, 3.28109693877551, 2.930618847976668, 0.32411448673494075, 1.4506338536497339, 0.9026654876200101, 0.6722434771700954, 2.093408203125]\n",
      "     ->分类目标权重字典: {0: 1.9753501658680428, 1: 3.28109693877551, 2: 2.930618847976668, 3: 0.32411448673494075, 4: 1.4506338536497339, 5: 0.9026654876200101, 6: 0.6722434771700954, 7: 2.093408203125}\n"
     ]
    }
   ],
   "source": [
    "X_y_group_train = pd.read_csv('mid_data/X_y_group_train_updated_v13.4_rolling.csv')\n",
    "\n",
    "print(\"##### Adding numeric labels y\")\n",
    "# 添加数值标签 y\n",
    "le = LabelEncoder()\n",
    "le.classes_ = np.array([\n",
    "    'Confounder', 'Collider',\n",
    "    'Mediator', 'Independent',\n",
    "    'Cause of X', 'Consequence of X', \n",
    "    'Cause of Y', 'Consequence of Y',\n",
    "])\n",
    "X_y_group_train[\"y\"] = le.transform(X_y_group_train[\"label\"])\n",
    "# 重新排列列\n",
    "X_y_group_train = X_y_group_train[[\"dataset\", \"variable\"] + X_y_group_train.columns.drop([\"dataset\", \"variable\", \"label\", \"y\"]).tolist() + [\"label\", \"y\"]]\n",
    "\n",
    "print(\"##### Data Preprocessing...\")\n",
    "# 定义要删除的列\n",
    "blacklist = [\n",
    "    \"ttest(v,X)\", \n",
    "    \"pvalue(ttest(v,X))<=0.05\", \n",
    "    \"ttest(v,Y)\", \n",
    "    \"pvalue(ttest(v,Y))<=0.05\", \n",
    "    \"ttest(X,Y)\", \n",
    "    \"pvalue(ttest(X,Y))<=0.05\",\n",
    "    \"square_dimension\", \n",
    "    \"max(PPS(v,others))\",\n",
    "    \"TLI_Collider\",\n",
    "    \"TLI_Confounder\",\n",
    "    \"RMSEA_Collider\",\n",
    "    \"RMSEA_Confounder\",\n",
    "]\n",
    "columns_to_drop = [col for col in blacklist if col in X_y_group_train.columns]\n",
    "X_y_group_train = X_y_group_train.drop(columns=columns_to_drop)\n",
    "print('     1.删除多余列后样本量', X_y_group_train.shape)\n",
    "# 填充缺失值\n",
    "X_y_group_train = X_y_group_train.replace([np.inf, -np.inf], np.nan)\n",
    "numeric_columns = X_y_group_train.select_dtypes(include=[np.number]).columns\n",
    "X_y_group_train[numeric_columns] = X_y_group_train[numeric_columns].fillna(X_y_group_train[numeric_columns].mean())\n",
    "print('     2.填充缺失值后样本量', X_y_group_train.shape)\n",
    "# 清理特征名称\n",
    "X_y_group_train = clean_feature_names(X_y_group_train)\n",
    "print('     3.清理特征名称后样本量', X_y_group_train.shape)\n",
    "\n",
    "print(\"##### Extracting X_train, y_train\")\n",
    "X = X_y_group_train.drop([\"variable\", \"dataset\", \"label\", \"y\"], axis=\"columns\")\n",
    "y = X_y_group_train[\"y\"]\n",
    "\n",
    "# 处理类别特征\n",
    "cat_idxs, cat_dims, X = process_categorical_features(X)\n",
    "print(\"     ->类别特征索引 (cat_idxs):\", cat_idxs)\n",
    "print(\"     ->类别特征模态数 (cat_dims):\", cat_dims)\n",
    "print('     4.处理类别特征后样本量', X.shape, y.shape)\n",
    "\n",
    "print(\"##### Extracting X_train, y_train, and group\")\n",
    "# 分割数据集为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42, stratify=y\n",
    ")\n",
    "print(\"     5.分割数据集后样本量:\", X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "print(\"     ->y_train 唯一值:\", np.unique(y_train))\n",
    "print(\"     ->y_test 唯一值:\", np.unique(y_test))\n",
    "\n",
    "print(\"##### Computing class weights\")\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "# 类别权重列表\n",
    "class_weights = list(class_weights) \n",
    "print(\"     ->分类目标权重列表:\", class_weights)\n",
    "# 类别权重字典\n",
    "weight_dict = dict(zip(classes, class_weights))\n",
    "print(\"     ->分类目标权重字典:\", weight_dict)\n",
    "# 样本权重\n",
    "sample_weights = y_train.map(weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:32:04] ======== Monitor (0): HostSketchContainer ========\n",
      "[21:32:04] AllReduce: 0.038344s, 1 calls @ 38344us\n",
      "\n",
      "[21:32:04] MakeCuts: 0.038778s, 1 calls @ 38778us\n",
      "\n",
      "[21:32:04] DEBUG: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0b3782d1791676daf-1\\xgboost\\xgboost-ci-windows\\src\\gbm\\gbtree.cc:130: Using tree method: 3\n",
      "[0]\tvalidation_0-mlogloss:2.05365\n",
      "[1]\tvalidation_0-mlogloss:2.02799\n",
      "[2]\tvalidation_0-mlogloss:2.00282\n",
      "[3]\tvalidation_0-mlogloss:1.97827\n",
      "[4]\tvalidation_0-mlogloss:1.95315\n",
      "[5]\tvalidation_0-mlogloss:1.92883\n",
      "[6]\tvalidation_0-mlogloss:1.90458\n",
      "[7]\tvalidation_0-mlogloss:1.88071\n",
      "[8]\tvalidation_0-mlogloss:1.85750\n",
      "[9]\tvalidation_0-mlogloss:1.83395\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 37\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 定义XGBClassifier\u001b[39;00m\n\u001b[0;32m     16\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier(\n\u001b[0;32m     17\u001b[0m     max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m     18\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stop]\n\u001b[0;32m     35\u001b[0m )\n\u001b[1;32m---> 37\u001b[0m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     42\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Predict\u001b[39;00m\n\u001b[0;32m     45\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n",
      "File \u001b[1;32md:\\python3.12\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\python3.12\\Lib\\site-packages\\xgboost\\sklearn.py:1519\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1491\u001b[0m (\n\u001b[0;32m   1492\u001b[0m     model,\n\u001b[0;32m   1493\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1498\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1499\u001b[0m )\n\u001b[0;32m   1500\u001b[0m train_dmatrix, evals \u001b[38;5;241m=\u001b[39m _wrap_evaluation_matrices(\n\u001b[0;32m   1501\u001b[0m     missing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmissing,\n\u001b[0;32m   1502\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     feature_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_types,\n\u001b[0;32m   1517\u001b[0m )\n\u001b[1;32m-> 1519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1531\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n\u001b[0;32m   1534\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\python3.12\\Lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\python3.12\\Lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32md:\\python3.12\\Lib\\site-packages\\xgboost\\core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     _check_call(\n\u001b[1;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2054\u001b[0m     )\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier, callback\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "weight_dict = dict(zip(classes, class_weights))\n",
    "sample_weights = y_train.map(weight_dict)\n",
    "\n",
    "# 定义早停回调\n",
    "early_stop = callback.EarlyStopping(\n",
    "    rounds=20,\n",
    "    save_best=True,\n",
    "    maximize=False,\n",
    "    metric_name='mlogloss'\n",
    ")\n",
    "\n",
    "# 定义XGBClassifier\n",
    "xgb_model = XGBClassifier(\n",
    "    max_depth=5,\n",
    "    learning_rate=0.05,\n",
    "    objective='multi:softmax',\n",
    "    num_class=8,\n",
    "    eval_metric='mlogloss',\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.3,\n",
    "    reg_lambda=10,\n",
    "    reg_alpha=10,\n",
    "    tree_method='hist',#'gpu_hist',      # 如果没有GPU，可以使用 'hist'\n",
    "    max_delta_step=0.5,\n",
    "    n_estimators=2000,\n",
    "    verbosity=3,\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    sample_weight=sample_weights,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Predict\n",
    "y_train_pred = xgb_model.predict(X_train)\n",
    "y_test_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate balanced accuracy\n",
    "train_score = balanced_accuracy_score(y_train, y_train_pred)\n",
    "test_score = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Training set balanced accuracy: {train_score:.6f}\")\n",
    "print(f\"Test set balanced accuracy: {test_score:.6f}\")\n",
    "\n",
    "# Print classification report\n",
    "print(\"Test set classification report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Save the model\n",
    "xgb_model.save_model('xgboost_model.json')\n",
    "print(\"Model saved as 'xgboost_model.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
